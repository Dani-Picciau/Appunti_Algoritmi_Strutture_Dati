\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{graphicx}
\usepackage{charter} % Font scelto per il documento
\usepackage{microtype}  % Migliora la qualità tipografica
\usepackage{titling}    % Per personalizzare il titolo
\usepackage[a4paper, margin=2cm]{geometry} % Imposta i margini
\usepackage{setspace} % Per gestire l'interlinea
\setstretch{1.1}  % interlinea di 1.1
\usepackage{enumitem}
\setlist{nolistsep} % Rimuove lo spazio tra gli elementi della lista
\usepackage{float} % Da inserire nel preambolo
\usepackage{wrapfig} % Pacchetto per posizionare testo e immagine affiancati
\usepackage{subfig} % Pacchetto per affiancare immagini
\renewcommand{\thefigure}{\arabic{figure}}
\setcounter{figure}{6}
\usepackage[hidelinks]{hyperref}  % 'hidelinks' rimuove i bordi rossi
\usepackage{booktabs} % Per migliorare la qualità della tabella
\usepackage{array}    % Per una migliore gestione delle colonne
\usepackage{tabularx} %per mettere più tabbella su una riga
\usepackage{placeins}
\usepackage{colortbl} % Required for \rowcolor
\usepackage{tikz}
\usetikzlibrary{positioning, shapes.geometric}
\usepackage{amssymb}
\usepackage{changepage}

\usepackage[most]{tcolorbox}
\usepackage{listings}
\usepackage{xcolor}
\usepackage[utf8]{inputenc}

% Definizione colori personalizzati
\definecolor{codebg}{RGB}{245, 245, 245} % Sfondo grigio chiaro
\definecolor{codeborder}{RGB}{200, 200, 200} % Bordo grigio più scuro
\definecolor{keywordcolor}{RGB}{0, 102, 204} % Blu per le parole chiave
\definecolor{commentcolor}{RGB}{0, 153, 0} % Verde per i commenti
\definecolor{stringcolor}{RGB}{204, 51, 0} % Rosso per le stringhe
\definecolor{typenames}{RGB}{128, 0, 128} % Viola per i tipi di dato

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{codebg}, % Sfondo grigio chiaro
    frame=single, % Bordo attorno al codice
    rulecolor=\color{codeborder}, % Colore del bordo
    basicstyle=\fontfamily{pcr}\selectfont\small, % Usa il font Courier che supporta il grassetto
    keywordstyle=\color{keywordcolor}\bfseries, % Parole chiave in blu e grassetto
    commentstyle=\color{commentcolor}\itshape, % Commenti in verde e italico
    stringstyle=\color{stringcolor}, % Stringhe in rosso
    identifierstyle=\color{black}, % Identificatori normali in nero
    numberstyle=\tiny\color{gray}, % Numeri di riga in grigio
    tabsize=4, % Grandezza del tab
    showstringspaces=false, % Nasconde gli spazi nelle stringhe
    breaklines=true, % Permette di andare a capo automaticamente
    morekeywords={uint8_t, uint16_t, uint32_t, size_t}, % Aggiunta di tipi standard del C
    escapeinside={(*@}{@*)}, % Definisce i caratteri di escape per inserire comandi LaTeX
}
 
\begin{document}
    
    \begin{center}
        {\LARGE{Appunti Algoritmi e Strutture Di Dati}}\\
        \vspace{8pt}
        \textit{\large{by Picciau Daniele}}
    \end{center}

    \section*{\hspace{15cm}Indice}
    \hrulefill 
    \renewcommand{\contentsname}{} % Rimuove il titolo dell'indice
    \tableofcontents

    \newpage
    \section{Introduzione}
    La parola \textit{\textbf{algoritmo}}, un tempo utilizzata quasi esclusivamente da matematici e informatici, è oggi sempre più diffusa anche nel linguaggio comune.

    \vspace{8pt}
    \noindent
    Spesso viene impiegata in modo \textbf{vago o impreciso} per riferirsi a qualunque forma di automazione, decisione informatica o comportamento opaco dei \textbf{sistemi digitali}.\\
    Oltre a definire genericamente sistemi informatici, capita spesso che il termine algoritmo venga \textbf{usato per qualunque descrizione} di un procedimento che \textbf{risolva un problema}.
    Dunque, diamo delle definizioni che colleghino i concetti di algoritmo e problema computazionale.

    \subsection{Problemi computazionali e algoritmi}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cos'è un problema computazionale?
        ]
        Dati un dominio di input e un dominio di output, un \textbf{problema computazionale} è rappresentato dalla \textbf{relazione matematica} che associa ogni elemento del dominio in input ad uno o piu elementi del dominio di output.
    \end{tcolorbox} 
    \noindent
    \textbf{\textit{Esempio:}} Immaginiamo di dover seguire una ricetta. L'input è dato dagli ingredienti, l'output è dato dal piatto cucinato, mentre il sistema formale di calcolo è dato dal cuoco.
    
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cos'è un algoritmo?
        ]
        Dato un problema computazionale, un algoritmo è un procedimento \textbf{effettivo} (di calcolo), espresso tramite un insieme di \textbf{passi elementari ben specificati} in un sistema formale di calcolo, che risolve il problema in un \textbf{tempo finito}.
    \end{tcolorbox}
    \noindent
    L'espressione \textbf{\textit{"in un tempo finito"}} implica che l'algoritmo deve terminare dopo un numero definito di passi, mentre \textbf{\textit{"passi elementari ben specificati"}}  si riferisce a operazioni descritte con precisione, realizzabili da un esecutore automatico.

    \subsubsection{Esempi di problemi computazionali e algoritmi}
    Per comprendere al meglio la differenza tra problema computazionale e algoritmo si considerino i seguenti problemi:
    \begin{tcolorbox}
        [
            colback=green!10,  % Sfondo verde chiaro
            colframe=green!60!black,  % Bordo verde più acceso
            coltitle=black,  % Colore del testo del titolo
            fonttitle=\bfseries,  % Testo del titolo in grassetto
            title={\centering \textbf{Problema del \textit{minimo}}},  % Titolo centrato 
            enhanced,  % Miglioramenti grafici
            attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
            boxed title style={colback=white, colframe=green!60!black, rounded corners},
            breakable
        ]
        Il minimo di un insieme $S$ è l'elemento di $S$ che è minore o uguale ad ogni elemento di $S$.
        \[
            min(S) = a \Leftrightarrow \exists a \in S: \forall b \in S : a \leqslant b
        \]

    \end{tcolorbox}
    \begin{tcolorbox}
        [
            colback=green!10,  % Sfondo verde chiaro
            colframe=green!60!black,  % Bordo verde più acceso
            coltitle=black,  % Colore del testo del titolo
            fonttitle=\bfseries,  % Testo del titolo in grassetto
            title={\centering \textbf{Problema di \textit{ricerca}}},  % Titolo centrato 
            enhanced,  % Miglioramenti grafici
            attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
            boxed title style={colback=white, colframe=green!60!black, rounded corners},
            breakable
        ]
        Sia $S = S_1, S_2, ..., S_n$ una sequenza di dati ordinati e distinti, dove $S_1 \leqslant  S_2 \leqslant ... \leqslant S_n$.
        Eseguire una ricerca dalla posizione di un dato $v$ in $S$ consiste nel restituire l'indice corrispondente, se $v$ è presente, oppure $-1$ se $v$ non è presente.
        \vspace{-10pt}
        \[
            lookup(S,v)=
            \begin{cases}
                i \quad \exists i \in {0,..., n-1}: S_i=v\\
                -1 \quad altrimenti
            \end{cases}
        \]
    \end{tcolorbox}
    \noindent
    Dunque, esiste una distinzione ben precisa fra \textit{il problema computazionale} che si vuole risolvere e gli \textit{algoritmi} che lo risolvono.\\
    Mentre un problema computazionale specifica quale relazione si desideri tra l'ingresso e l'uscita (cioè il risultato), l'algoritmo descrive la sequenza di azioni da eseguire per ottenere l'uscita desiderata a partire dall'ingresso.

    \vspace{8pt}
    \noindent
    In questo caso, dei possibili algoritmi che risolvono i problemi, sono i seguenti:
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Problema del \textit{minimo}}: Per trovare il minimo di un insieme, confronta ogni elemento con tutti gli altri; l'elemento che e minore di tutti è il minimo.
        \item \textbf{Problema di \textit{ricerca}}: Per trovare un valore $v$ nella sequenza $S$, confronta $v$ con tutti gli elementi di $S$, in sequenza, e restituisci la posizione corrispondente; restituisci $-1$ se nessuno degli elementi corrisponde.
    \end{itemize}

    \vspace{8pt}
    \noindent
    Gli algoritmi che vengono scelti per la risoluzione di un problema computazionale devono presentare \textbf{passi non ambigui} ed \textbf{eseguibili}, proprio per questo un generico algoritmo è caratterizzato dalle seguenti \textbf{proprietà}:
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Atomicità}: l'algoritmo deve essere composto da passi elementari non scomponibili;
        \item \textbf{Non ambiguità}: l'algoritmo non deve generare errori;
        \item \textbf{Attualità}: l'algoritmo deve essere eseguibile;
        \item \textbf{Finitezza}: si intende che l'algoritmo deve terminare in un tempo finito;
        \item \textbf{Effettività}: l'algoritmo deve portare ad un risultato univoco.
    \end{itemize}

    \subsubsection{Come valutare l'algoritmo scelto}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Valutazione di un algoritmo
        ]
        La valutazione di un algoritmo consiste nello stabilire se quest'ultimo risolve il problema in modo \textbf{efficiente} e \textbf{corretto}.
    \end{tcolorbox}
    \noindent
    Per quanto riguarda il grado di \textbf{efficienza}:
    \begin{itemize}[leftmargin=1em]
        \item Alcuni problemi \textbf{non possono} essere risolti in modo \textbf{efficiente}, quindi non esistono algoritmi noti che risolvano il problema.
        \item Allo stesso modo, esistono soluzioni "ottime" che non possono essere portate ad un grado di efficienza maggiore proprio perché non è possibile essere più efficienti;
        \item Altri problemi presentano, banalmente, delle soluzioni che funzionano ma non sono particolarmente efficienti;
    \end{itemize}
    Invece, la \textbf{correttezza di un algoritmo} viene dimostrata tramite:
    \begin{itemize}[leftmargin=1em]
        \item Per quanto possibile, con una descrizione matematica;
        \item Oppure utilizzando una descrizione "informale".
    \end{itemize}
    \textbf{\textit{N.B}}: alcuni problemi non possono essere risolti. Proprio perché alcuni problemi non possono essere risolti in maniera efficiente e corretta, vengono risolti in maniera approssimata.

    \subsubsection{Complessità di un algoritmo}
    \label{par:Complessità di un algoritmo}
    La ricerca di un algoritmo efficiente e corretto, porta alla definizione di un ulteriore concetto, quello della \textit{"complessità di un algoritmo"}.
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Complessità di un algoritmo
        ]
        La \textbf{complessità di un algoritmo} è data dall'analisi delle risorse da esso impiegate per risolvere un problema, in funzione della dimensione e della tipologia dell'input.
    \end{tcolorbox}
    \noindent
    Quando si parla di \textit{risorse impiegate da un algoritmo}, ci si riferisce a:
    \begin{itemize}[leftmargin=1em]
        \item \textbf{\textit{Tempo}}: ovvero il tempo impiegato per completare l'algoritmo.\\
        Misurare il tempo di esecuzione di un algoritmo considerando il tempo di calcolo in senso assoluto (secondi, minuti, ecc.) rappresenta un \textbf{approccio errato} perché dipende da troppi parametri a seconda della piattaforma utilizzata per la misura:
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{1}\rule{0.6ex}{0.6ex}}]
            \item Frequenza del processore;
            \item Linguaggio di programmazione utilizzato;
            \item Ottimizzazione del compilatore utilizzato;
            \item Interazione tra memoria primaria (anche memorie cache) e secondaria;
            \item Velocità di trasmissione dati del bus;
            \item Processi attualmente in esecuzione;
            \item ecc \dots
        \end{itemize} 
        Proprio per questo motivo quando si parla di \textit{tempo impiegato dall'algoritmo} ci si riferisce al \textbf{numero di operazioni rilevanti}, ovvero il numero di operazioni che caratterizzano lo scopo dell'algoritmo, come ad esempio, contare operazioni elementari come i confronti, che rappresentano una misura più stabile e indipendente dalla piattaforma (capitolo \ref{par:Definizione di tempo e modello di calcolo}).
        \item \textbf{\textit{Spazio}}: Quantità di memoria utilizzata;
        \item \textbf{\textit{Banda}}: quantità di bit spediti.
    \end{itemize}

    \vspace{8pt}
    \noindent

    \subsection{Strutture dati}
    In un linguaggio di programmazione, un \textbf{dato} è un \textbf{valore che una variabile può assumere}.
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cos'è una struttura dati?
        ]
       
        Una \textbf{struttura dati} è un modo per organizzare e memorizzare i dati sui supporti fisici.
    \end{tcolorbox} 
    \noindent
    Le strutture dati offrono il \textbf{vantaggio} di permettere una \textbf{buona organizzazione} dei dati permettendo così di \textbf{semplificare} l'\textbf{accesso} e la \textbf{modifica} degli stessi, influendo in modo diretto sull'efficienza dell'algoritmo.\\
    Dunque, la caratteristica principale non è tanto il \textit{tipo dei dati}, contenuti all'interno della struttura, ma \textbf{il modo in cui viene organizzata la collezione}.\\
    Possiamo definire una struttura dati utilizzando \textbf{due elementi}:
    \begin{itemize}[leftmargin=1em]
        \item \textbf{\textit{Insieme di operatori}}: ovvero l'insieme di operatori che permettono di manipolare la struttura (inserimenti, eliminazioni, ricerca, ordinamento, ecc\dots) ;
        \item \textbf{\textit{Modo sistematico di organizzare i dati}}: indica il modo in cui i dati sono memorizzati e collegati tra loro (ad esempio, in modo sequenziale, a grafo o ad albero).
    \end{itemize}
    È importante notare che \textbf{non esiste una struttura dati adatta a qualsiasi compito}, quindi risulta utile considerare e conoscere i \textbf{vantaggi e svantaggi} di diverse strutture.

    \subsubsection{Tipologie di strutture dati}
    Le strutture dati possono essere classificate in base a diversi criteri:
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Lineari} e \textbf{non lineari}: nelle strutture lineari gli elementi sono \textbf{disposti in sequenza} (ad esempio, array o liste), mentre nelle strutture non lineari ogni elemento \textbf{può collegarsi a più elementi} (ad esempio alberi o grafi);
        \item \textbf{Statiche} e \textbf{dinamiche}: nelle strutture statiche la \textbf{dimensione è fissa} (come ad esempio negli array), mentre nelle  strutture dinamiche la dimensione \textbf{può variare nel tempo} (ad esempio liste collegate);
        \item \textbf{Omogenee} e \textbf{disomogenee}: le strutture omogenee presentano una collezione di \textbf{dati dello stesso tipo} (come ad esempio un array di interi), invece, le strutture disomogenee presentano collezioni di \textbf{dati di tipologie differenti}.
    \end{itemize}

    \subsubsection{Le sequenze}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cos'è una sequenza?
        ]
       
        Una \textbf{sequenza}, è una struttura dati \textbf{dinamica} e \textbf{lineare} che rappresenta una sequenza ordinata di valori, all'interno della quale uno stesso valore può \textbf{comparire} anche \textbf{più di una volta}. 
    \end{tcolorbox} 
    \noindent
    L'\textbf{ordine} della collezione di dati all'interno della sequenza è \textbf{importante}, di tipo \textbf{posizionale}.\\
    Data una generica sequenza $S = S_1, S_2, ..., S_n$ è possibile aggiungere o togliere elementi, mantenendo la struttura ordinata della sequenza: per indicare un generico elemento $S_i$ della sequenza si utilizza il parametro $pos_i$, che rappresenta una \textbf{posizione logica} nella sequenza; dunque, è possibile accedere direttamente alla testa con $pos_0$ e alla coda con $pos_n$.

    \vspace{8pt}
    \noindent
    \textbf{\textit{Alcuni esempi}}: di seguito verranno illustrate alcune operazioni effettuate sulle sequenze.
    \begin{figure}[H]
        \centering
        \vspace{-8pt}  % Riduce lo spazio sopra
        \includegraphics[width=0.8\textwidth]{figures/1_introduzione/img1.png}    
        \vspace{-5pt}     
    \end{figure}
    \begin{figure}[H]
        \centering
        \vspace{-8pt}  % Riduce lo spazio sopra
        \includegraphics[width=0.8\textwidth]{figures/1_introduzione/img2.png}    
        \vspace{-5pt}     
    \end{figure}

    \noindent
    Esempio di creazione di una sequenza il linguaggio \textit{C++}
    \begin{lstlisting}[style=mystyle, language=C++]
std::list<int> lista;
lista.push_front(2);
lista.push_front(1);
lista.push_back(3);

Result: [1, 2, 3]
    \end{lstlisting}

    \subsubsection{Gli Insiemi}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cos'è un insieme?
        ]
        Un \textbf{insieme} è una struttura dati \textbf{dinamica} e \textbf{non lineare} che memorizza una collezione \textbf{non ordinata} di elementi senza valori ripetuti.
    \end{tcolorbox}
    \noindent
    A differenza delle sequenze, per ordinare un insieme, bisogna introdurre il concetto di \textbf{relazione d'ordine}.
    Infatti, nelle sequenze (come array o liste), l'ordine degli elementi non dipende \textbf{dal loro valore}, ma dalla \textbf{posizione che occupano}.   
    Quindi non serve definire una “relazione d'ordine” tra gli elementi: la struttura stessa impone un ordine.

    \vspace{8pt}
    \noindent
    Gli insiemi, invece, sono per definizione una collezione di elementi unici ma senza un ordine posizionale.
    Quindi, in un \textbf{insieme}, l'ordinamento fra elementi è dato dall'\textbf{\textit{eventuale relazione d'ordine definita sul tipo degli elementi stessi}}. Per questo motivo, se vogliamo ordinare gli elementi, è necessario specificare in che modo come avviene il confronto.\\
    \textbf{\textit{Esempio:}} nel caso degli \textbf{interi}, il confronto è immediato, poiché esiste un ordine naturale tra i valori numerici ($1 < 2 < 3 < \dots$).  
    Per le \textbf{stringhe}, invece, l'ordinamento si basa sull'\textbf{ordine lessicografico}, ossia sul confronto dei caratteri secondo la sequenza alfabetica (ad esempio, \textit{"cane"} precede \textit{"gatto"} perché la lettera \textit{"c"} viene prima della \textit{"g"} nell'alfabeto).

    \vspace{8pt}
    \noindent
    Lavorando con gli insiemi, le operazioni ammesse sulle collezioni di dati sono le seguenti:
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Operazioni base}: inserimento, cancellazione, verifica contenimento;
        \item \textbf{Operazioni di ordinamento}: massimo e minimo;
        \item \textbf{Operazioni di insiemistiche}: unione, intersezione, differenza;
        \item \textbf{Iteratori}: \textit{foreach} $x \in S \; do$
    \end{itemize}
    \begin{figure}[H]
        \addtocounter{figure}{1}
        \centering
        \vspace{-8pt}  % Riduce lo spazio sopra
        \includegraphics[width=0.8\textwidth]{figures/1_introduzione/img3.png}    
        \vspace{-5pt}     
    \end{figure}
    \noindent
    Esempio di creazione di un insieme il linguaggio \textit{C++}
    \begin{lstlisting}[style=mystyle, language=C++]
std::set<std::string> frutta;
frutta.insert("mele");
frutta.insert("pere");
frutta.insert("banane");
frutta.insert("mele");
frutta.remove("mele");
Result: ["banane", "pere"]
    \end{lstlisting}

    \subsubsection{I dizionari}
    \label{par:I dizionari}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cos'è un dizionario?
        ]
        Un \textbf{dizionario} è una struttura dati che rappresenta il concetto matematico di relazione univoca $R: D \rightarrow C$, o associazione chiave valore, dove:
        \begin{itemize}[leftmargin=1em]
            \item L'insieme $D$ è il dominio (elementi detti chiavi);
            \item L'insieme $C$ è il codominio (elementi detti valori)
        \end{itemize}
    \end{tcolorbox}
    \noindent
    Con questa tipologia di struttura dati, sono ammesse le seguenti operazioni:
    \begin{itemize}[leftmargin=1em]
        \item Ottenere il valore associato ad una particolare chiave (se presente), o \textbf{\textit{nil} (null)} se assente;
        \item Inserire una nuova associazione chiave-valore, cancellando eventuali associazioni precedenti per la stessa chiave;
        \item Rimuovere unassociazione chiave-valore esistente;
    \end{itemize}
    \begin{figure}[H]
        \centering
        \vspace{-8pt}  % Riduce lo spazio sopra
        \includegraphics[width=0.78\textwidth]{figures/1_introduzione/img4.png}    
        \vspace{-5pt}     
    \end{figure}

    \subsection{I puntatori}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cos'è un puntatore?
        ]
        Un \textbf{puntatore} è una variabile che contiene un \textbf{indirizzo di memoria}. Spesso, l'indirizzo è la locazione di memoria di un'altra variabile.
    \end{tcolorbox}
    \noindent
    \textbf{\textit{N.B}}: un puntatore non può contenere un valore che non sia un indirizzo.\\
    Gli usi tipici dei puntatori sono la creazione di strutture dati collegate come alberi e liste, la gestione di oggetti allocati dinamicamente e come parametri di funzioni.
    
    \vspace{8pt}
    \noindent
    Ogni puntatore ha un tipo associato. La differenza non sta nella rappresentazione dei puntatori, ma nel tipo dell'oggetto puntato. Le variabili dei puntatori devono essere dichiarate come tali:
    \begin{lstlisting}[style=mystyle, language=C++]
int *p; //Puntatore a intero
float *p; //Puntatore a float
    \end{lstlisting}
    Gli operatori speciali che vengono utilizzati con i puntatori sono $\ast$ e \&:
    \begin{itemize}[leftmargin=1em]
        \item \& $\rightarrow$ è un operatore \textbf{unario} che restituisce l'\textbf{indirizzo di memoria} del suo operando;
        \begin{lstlisting}[style=mystyle, language=C++]
balptr = &balance //mette in balptr l'indirizzo di memoria di balace.
        \end{lstlisting}
        \item $\ast \rightarrow$ è un operatore \textbf{unario} che restituisce \textbf{il valore} della variabile allocata all'indirizzo specificato dal suo operando.
        \begin{lstlisting}[style=mystyle, language=C++]
value = *balptr //se balptr contiene l'indirzzo di balance, il  valore della variabile balance viene messo in value.
        \end{lstlisting}
    \end{itemize}

    \vspace{8pt}
    \noindent
    \textbf{\textit{Esempio}}: esercizio con puntatori
    
    \vspace{-15pt}
    \noindent
    \begin{minipage}[t]{0.565\textwidth}  
        \begin{lstlisting}[style=mystyle, language=C++]
#include <iostream>
int main() {
    int j = 12;
    int *ptr = &j;

    cout << *ptr << endl;

    j = 24;
    cout << *ptr << endl;
    cout << ptr << endl;
    return 0;
}
        \end{lstlisting}   
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{21pt}{  
        \begin{minipage}[t]{0.427\textwidth}
            \begin{figure}[H]
                \includegraphics[width=0.65\linewidth]{figures/1_introduzione/img7.png}          
            \end{figure}
            L'output del programma è il seguente:\\
            $12$\\
            $24$\\
            $0x7b03a928$ (indirizzo di memoria)
        \end{minipage}   
    }

    \subsubsection{Puntatori nulli}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cos'è un puntatore?
        ]
        Un puntatore può contenere il valore $0$ a indicare che non punta ad alcun oggetto.\\
        In questo caso viene detto \textbf{puntatore nullo}.
    \end{tcolorbox}

    \newpage
    \noindent
    In questo caso, provando a stampare un puntatore nullo, si ottiene un errore.

    \vspace{-12pt}
    \noindent
    \begin{minipage}[t]{0.5\textwidth}  
        \begin{lstlisting}[style=mystyle, language=C++]
#include <iostream>
    int main() {
    int j = 12;
    int *ptr = 0;
    cout << *ptr << endl; // crash !
    return 0;
}
        \end{lstlisting}   
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{20pt}{  
        \begin{minipage}[t]{0.468\textwidth}
            \begin{figure}[H]
                \includegraphics[width=\linewidth]{figures/1_introduzione/img8.png}          
            \end{figure}
        \end{minipage}   
    }
    
    \vspace{8pt}
    \noindent
    \textbf{\textit{Esempio}}: come i puntatori vengono utilizzati con gli array

    \begin{lstlisting}[style=mystyle, language=C++]
//Alcune implementazioni di array in c++
int x[] = { 1, 2, 3, 4 };
char[] t = { 'C', 'i', 'a', 'o','\0'};
char[] s = "Ciao";
int m[2][3] = { {11, 12, 13}, {21, 22, 23} };
    \end{lstlisting}

    \vspace{-15pt}
    \noindent
    \begin{minipage}[t]{0.5\textwidth}  
        \begin{lstlisting}[style=mystyle, language=C++]
int main() {
    float x[5];
    int j;
    
    for (j = 0; j < 5; j++){
        x[j] = 0;
    }
    float *ptr = x;
    *ptr = 1.5; // x[0] = 1.5
    *(ptr+1) = 2.5; // x[1] = 2.5
    *(ptr+3) = 3.5; // x[3] = 3.5
 }
        \end{lstlisting}   
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{19pt}{  
        \begin{minipage}[t]{0.468\textwidth}
            \begin{figure}[H]
                \includegraphics[width=\linewidth]{figures/1_introduzione/img9.png}          
            \end{figure}

            \vspace{-12pt}
            Utilizzando gli array, non è necessario specificare che \texttt{ptr} punti ad un indirizzo, come fatto precedentemente (\texttt{*ptr = \&j}), proprio perché \texttt{x} rappresenta di per sé l'indirizzo della prima posizione dell'array. 
        \end{minipage}   
    }





    \newpage
    \section{Iterazione, induzione e ricorsione}
    Iterazione, induzione e ricorsione sono concetti fondamentali che
    compaiono in varie forme nel modelli dei dati, nelle strutture dati e negli algoritmi.
    \subsection{Iterazione}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cosa si intende con iterazione?
        ]
        \textbf{Iterare} significa eseguire in modo ripetitivo lo stesso compito, o versioni diverse dello stesso compito, fino al verificarsi di certe condizioni logiche.
    \end{tcolorbox}
    \noindent
    Nell'informatica l'iterazione è un concetto che si trova in molte forme:
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Nei modelli di dati}: concetti come le \textbf{liste} sono definiti in modo ripetitivo.\\
        \textbf{\textit{Esempio}}: Una lista è vuota, oppure è un elemento seguito da un altro, seguito da un altro ancora...;
        \item \textbf{I programmi e gli algoritmi}: utilizzano l'iterazione per eseguire compiti ripetitivi senza speci care uno per uno un gran numero di singoli passi;
        \item \textbf{I linguaggi di programmazione}:  utilizzano, nella realizzazione di algoritmi iterativi, costrutti ciclici, come ad esempio i comandi \texttt{while} e \texttt{for} del \texttt{c++};
    \end{itemize}

    \subsection{Induzione}
    L'\textbf{induzione} è un concetto strettamente collegato alla ricorsione, ma appartiene più al \textbf{mondo matematico} che a quello della programmazione.\\
    Nell'induzione, si dimostra una proposizione per il \textbf{caso base}, e poi si mostra che, se vale per un caso generico, allora vale anche per il successivo.
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cosa si intende con induzione?
        ]
        La dimostrazione per induzione è una tecnica utile per dimostrare la verità di un \textbf{asserto}. 
    \end{tcolorbox}
    \begin{tcolorbox}
    [
        colback=green!10,  % Sfondo verde chiaro
        colframe=green!60!black,  % Bordo verde più acceso
        coltitle=black,  % Colore del testo del titolo
        fonttitle=\bfseries,  % Testo del titolo in grassetto
        title={\centering \textbf{Cos'è un \textit{asserto}?}},  % Titolo centrato 
        enhanced,  % Miglioramenti grafici
        attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
        boxed title style={colback=white, colframe=green!60!black, rounded corners},
        breakable
    ]
        Si definisce \textbf{asserto} (o proposizione) un'affermazione dotata di valore di verità (ossia può essere vera o falsa).\\
        \textbf{\textit{Esempio}}: in una dimostrazione induttiva si tenta di dimostrare che $S(n)$ vale per tutti gli interi di $n$ non negativi o, più in generale,  per tutti gli interi maggiori di un certo limite inferiore.
    \end{tcolorbox}
    \noindent
    Dimostrare la verità di un asserto permette di esprimere le proprietà di un programma.\\
    In particolare, la dimostrazione per induzione si basa sulla \textbf{definizione di una classe di oggetti (o fatti) strettamente correlati tra loro}.\\
    \textbf{\textit{Esempio}}: sia $S(n)$ un asserto arbitrario su un intero $n$. Nella sua forma più semplice (\textbf{induzione semplice}), una dimostrazione induttiva dell'asserto $S(n)$ prevede \textbf{due passi}:
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Caso base}: si occupa di costruire uno o più oggetti semplici.\\
        Nel caso dell'esempio, si dimostra che l'asserto $S(n)$ è vero per un valore particolare di $n$;
        \item \textbf{Passo induttivo}: costruisce oggetti più grandi che dipendono da quelli appena precedenti.\\
        Nel caso dell'esempio, si dimostra che per ogni $n\geqslant0,\;$ se $S(n)$ è vero, lo è anche $S(n+1)$.
    \end{itemize}
    \begin{figure}[H]
        \centering
        \vspace{-15pt}  % Riduce lo spazio sopra
        \includegraphics[width=0.85\textwidth]{figures/4_iterazione_ricorsione_induzione/img1.png}        
        \vspace{-15pt}  % Riduce lo spazio sopra
    \end{figure}
    In una dimostrazione induttiva, \textbf{ogni istanza dell'asserto $S(n)$ dipende solo dall'asserto sul valore che precede $n$}. Se l'induzione parte da $0$, per ogni intero $n$ si deve dimostrare un asserto $S(n)$:
    \begin{itemize}[leftmargin=1em]
        \item La dimostrazione di $S(1)$ utilizza $S(0)$
        \item La dimostrazione di $S(2)$ utilizza $S(1)$
        \item e così via...
    \end{itemize}
  Ogni asserto dipende dal precedente in modo uniforme, e grazie alla dimostrazione del \textbf{passo induttivo} si garantisce la verità di tutti i passi successivi.

    \subsubsection{Induzione completa}
    Un induzione nella quale si dimostra la verità di $S(n+1)$ utilizzando come ipotesi induttiva soltanto $S(n)$ viene detta \textbf{induzione semplice}.
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cosa si intende con induzione completa?
        ]
        Si parla di induzione completa (perfetta o forte)  quando per dimostrare l'asserto $S$ siamo autorizzati a utilizzare $S(i)$ per tutti i valori di $i$ dalla base fino a $n$. 
    \end{tcolorbox}
    \noindent
    Quindi a differenza dell'induzione semplice, dove, per dimostrare $S(n+1)$ si usa solo $S(n)$ (ovvero \textbf{solo ciò} che si è \textbf{ottenuto nel passo precedente}), nell'induzione completa per dimostrare che $S(n+1)$ è vera, \textbf{si possono usare tutti i casi precedenti, non solo quello immediatamente precedente}.\\
    Anche in questo caso, per ottenere una dimostrazione induttiva dell'asserto $S(n)$ si utilizzano due passi:
    \begin{itemize}[leftmargin=1em]
        \item Si dimostra prima la base, $S(0)$;
        \item In seguito, si assumono le verità  di $S(0), S(1), ..., S(n)$ e a partire da questi si dimostra $S(n+1)$.
    \end{itemize}

    \vspace{-5pt}
    \begin{tcolorbox}
    [
        colback=green!10,  % Sfondo verde chiaro
        colframe=green!60!black,  % Bordo verde più acceso
        coltitle=black,  % Colore del testo del titolo
        fonttitle=\bfseries,  % Testo del titolo in grassetto
        title={\centering \textbf{Utilità dell'induzione completa}},  % Titolo centrato 
        enhanced,  % Miglioramenti grafici
        attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
        boxed title style={colback=white, colframe=green!60!black, rounded corners},
        breakable
    ]
        L'induzione completa, torna utile perché alcuni problemi non possono essere dimostrati basandosi solo sul passo precedente.\\
        Ad esempio, se per calcolare $S(n)$ si ha bisogno sia di $S(n-1)$ che di $S(n-2)$ (come nella sequenza di fibonacci), allora serve induzione completa. 
    \end{tcolorbox}
    \begin{figure}[H]
        \centering
        \vspace{-18pt}  % Riduce lo spazio sopra
        \includegraphics[width=0.8\textwidth]{figures/4_iterazione_ricorsione_induzione/img2.png}        
        \vspace{-15pt}  % Riduce lo spazio sopra
    \end{figure}

    \subsection{Ricorsione}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cosa si intende con ricorsione?
        ]
        La \textbf{ricorsione} è una tecnica in un concetto viene definitio, direttamente o indirettamente, in termini di se stesso. 
    \end{tcolorbox}
    \noindent
    È molto simile all'iterazione, ma invece di ripetere istruzioni tramite un ciclo (\texttt{for, while}), \textbf{si ripete richiamando la stessa funzione}. Anche se all'\textbf{apparenza} possono sembrare \textbf{piu complessi} dei programmi iterativi, i programmi ricorsivi possono \textbf{risultare piu semplici} da \textbf{scrivere} e \textbf{analizzare}.\\
    Una funzione o procedura ricorsiva \texttt{P} può richiamare se stessa in due modi:
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Direttamente}: quando dentro il corpo della funzione \texttt{P} c'è una chiamata a \texttt{P};
        \begin{lstlisting}[style=mystyle, language=C++]
void P() { P(); } // chiamata diretta 
        \end{lstlisting}
        \item \textbf{Indirettamente}: quando \texttt{P} chiama un'altra funzione \texttt{Q}, e poi \texttt{Q} chiama \texttt{P}, e così via \dots
        \begin{lstlisting}[style=mystyle, language=C++]
void P() { Q(); } // P chiama Q, che chiama P
void Q() { P(); }
        \end{lstlisting}
    \end{itemize}

    \vspace{8pt}
    \noindent
    \begin{tcolorbox}
    [
        colback=green!10,  % Sfondo verde chiaro
        colframe=green!60!black,  % Bordo verde più acceso
        coltitle=black,  % Colore del testo del titolo
        fonttitle=\bfseries,  % Testo del titolo in grassetto
        title={\centering \textbf{Induttività della ricorsione}},  % Titolo centrato 
        enhanced,  % Miglioramenti grafici
        attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
        boxed title style={colback=white, colframe=green!60!black, rounded corners},
        breakable
    ]
        Utilizzando la ricorsione si costruisce, \textbf{implicitamente}, una \textbf{definizione induttiva} di come funziona l'algoritmo e di \textbf{quanto tempo impiega} per completarsi.\\
        Infatti quando un algoritmo impiega la ricorsione, si fa uso di una formula detta \textbf{equazione di ricorrenza}: il tempo che serve per risolvere un problema più grande dipende dal tempo che serve per risolvere i problemi più piccoli.\\
        \textbf{\textit{Esempio}}: si immagini di voler calcolare il fattoriale di $4$
        \begin{lstlisting}[style=mystyle, language=C++]
fatt(4)
-> fatt(3)
-> fatt(2)
-> fatt(1)
-> fatt(0)
        \end{lstlisting}
        Quindi il tempo totale per \texttt{fatt(4)} è la somma del tempo per \texttt{fatt(3)}, più un piccolo tempo extra per l'operazione \texttt{n * ...}
        
        \vspace{8pt}
        \noindent
        In generale, la ricorsione è \textbf{induttiva} perché per dimostrare una proprietà di una procedura ricorsiva, abbiamo bisogno di dimostrare un asserto sull'effetto della chiamata di questa procedura, costruendo un \textbf{caso base} e i casi successivi a partire da esso.\\
        In queste dimostrazioni si procede spesso per \textbf{induzione sulla dimensione dell'argomento}, cioè sulla grandezza del parametro su cui agisce la ricorsione, che diminuisce a ogni chiamata fino al caso base (nel caso di $n!$, il parametro è $n$).

    \end{tcolorbox}
    
    \subsection{Invarianti dei cicli}
    \label{par:Invarianti dei cicli}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cos'è un invariante?
        ]
        Un \textbf{invariante} è una condizione sempre vera in un certo punto del programma.%in un contesto generale
    \end{tcolorbox}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cos'è un invariante di ciclo (o asserzione induttiva)?
        ]
        Invece, possiamo definire \textbf{invariante di ciclo} una condizione sempre vera all'inizio dell'iterazione di un ciclo. Gli invarianti di ciclo sono importanti per dimostrare la correttezza di \textbf{algoritmi iterativi}.\\
        Piu formalmente possiamo dire che: \textit{Un \textbf{invariante di ciclo} è un asserto $S$ che è vero ogni volta che ci si trova in un particolare punto del ciclo.}
    \end{tcolorbox}
    \noindent
        L'asserto $S$ viene poi dimostrato per induzione su un \textbf{parametro} che costituisce una \textbf{misura del numero di volte che il ciclo viene intrapreso}. Questo parametro può essere:
        \begin{itemize}[leftmargin=1em]
            \item Il numero di volte che abbiamo raggiunto la guardia di un ciclo;
            \item Oppure, il valore della variabile indice utilizzata dal ciclo stesso. 
        \end{itemize}

    \vspace{8pt}
    \noindent
    La dimostrazione segue quindi gli stessi passaggi di una dimostrazione induttiva:
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Inizializzazione} (caso base): la condizione è vera alla prima iterazione di un ciclo;
        \item \textbf{Conservazione} (passo induttivo): se la condizione è vera prima di un'iterazione del ciclo, allora rimane vera al termine (quindi, prima della successiva iterazione);
        \item \textbf{Conclusione}: tutto ciò ha senso se, al termine, l'invariante rappresenta quello che voglio ottenere, qundi la "correttezza" dell'algoritmo.
    \end{itemize}

    \subsubsection{Invariante del ciclo \texttt{while} VS invariante del ciclo \texttt{for}}
    In genere le dimostrazioni di correttezza per induzione usano il numero di iterazioni del ciclo per cui l'invariante vale.
    Quando la condizione diviene falsa, possiamo quindi utilizzare contemporaneamente l'invariante del ciclo e la falsita della condizione per concludere qualcosa di interessante su ciò che vale al termine del ciclo.

    \vspace{8pt}
    \noindent
    Utilizzare una tipologia di costrutto iterativo, rispetto ad un'altra può rendere una dimostrazione di correttezza di un ciclo più complessa. Ad esempio:

    \vspace{-2pt}
    \noindent
    \begin{minipage}[t]{0.487\textwidth}
        \begin{lstlisting}[style=mystyle, language=C]
for (i = 0; i < n; i++) {
...
...
}
        \end{lstlisting}        
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{-3pt}{  
        \begin{minipage}[t]{0.485\textwidth}
            Utilizzando un ciclo \textit{for} il contatore è integrato nella struttura stessa del ciclo.\\
            Il valore iniziale, la condizione di uscita e l'aggiornamento (\texttt{i++}) sono tutti dichiarati in modo esplicito e standard. Si sa con certezza
        \end{minipage}  
    }

    \vspace{3pt}
    \noindent
    che il ciclo verrà eseguito un numero finito di volte ($n$), a meno che il corpo del ciclo non modifichi \texttt{i} in modo anomalo. Quindi, la terminazione è ovvia: quando $i = n$, il ciclo si ferma.

    \vspace{8pt}
    \noindent
    Invece, la struttura del \textit{while} è più \textbf{generale} e \textbf{felssibile}.\\
    Nel primo caso si usa un contatore $i$ come nel \textit{for}, quindi il comportamento è analogo, \textbf{ma il linguaggio non obbliga a farlo!}

    \vspace{3pt}
    \noindent
    \begin{minipage}[t]{0.487\textwidth}  
        \textit{Primo caso}
        \begin{lstlisting}[style=mystyle, language=C]
i = 0;
while (i < n) {
...
i++;
}
        \end{lstlisting}
    \end{minipage}%
    \hspace{6pt} % Spazio tra immagine e testo
    \begin{minipage}[t]{0.487\textwidth}
        \textit{Secondo caso}
        \begin{lstlisting}[style=mystyle, language=C]
x = 5;
while (x != 0) {
x = f(x);   // f potrebbe non diminuire x!
}   
        \end{lstlisting}
    \end{minipage}\\
    Nel secondo caso non c'è un contatore "ovvio" che cresce o diminuisce in modo regolare, e non è certo che il ciclo finirà (magari \texttt{f(x)} restituisce sempre un numero diverso da 0, o l'utente non scrive mai "exit").

    \vspace{8pt}
    \noindent
    Proprio per questo, \textbf{parte della dimostrazione di correttezza di un ciclo \textit{while} consiste nel dimostrarne la terminazione}. Solitamente, la dimostrazione di terminazione viene fatta determinando \textbf{un'espressione \textit{E}}, che \textbf{coinvolge le variabili del programma stesso}, tale che:
    \begin{itemize}[leftmargin=1em]
        \item Il valore di \textit{E} \textbf{diminuisce (o aumenta)} di almeno un'unità \textbf{a ogni iterazione del ciclo};
        \item Quando il ciclo si ferma (quindi la \textbf{condizione è falsa}), il valore di \textit{E} è \textbf{pari ad una costante minima (o massima) prefissata}.
    \end{itemize}
    Dunque, basandosi sulle caratteristiche appena descritte, è possibile determinare l'espressione \textit{E}, ad esempio, con la seguente dimostrazione.

    \vspace{-8pt}
    \noindent
    \subsubsection*{\textit{Esempio}: dimostrazione della terminazione di un ciclo \texttt{while}}

    \vspace{-3pt}
    \noindent
    \begin{minipage}[t]{0.357\textwidth}  
        \includegraphics[width=\linewidth]{figures/4_iterazione_ricorsione_induzione/img6.png}
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{127pt}{  
        \begin{minipage}[t]{0.620\textwidth}
            La seguente funzione "\texttt{Fattoriale}" calcola $n!$ passato da parametro, assumendo che $n\geqslant1$.
            Lo scopo è quello di dimostrare che il ciclo \texttt{while} (\textit{righe 4-6}) deve terminare.\\
            Come detto precedentemente,  per dimostrare la terminazione del ciclo bisogna determinare \textit{E}.\\
            Dunque, si cerca una grandezza che:
            \begin{itemize}[leftmargin=1em]
                \item parta positiva;
                \item diminuisca ad ogni iterazione;
                \item diventi negativa quando il ciclo finisce.
            \end{itemize}
        \end{minipage} 
    }    
    \textbf{\textit{N.B}}: Per dimostrare la terminazione \textbf{si preferisce} trovare \textbf{una funzione \textit{E} che decresce} verso un limite inferiore (è più facile da gestire nei teoremi di terminazione).\\
    Una scelta che risulta naturale è $E=n-1$, poiché:
    \begin{itemize}[leftmargin=1em]
        \item $i$ è piccolo all'inizio, e dato che deve essere $i \leqslant n \Rightarrow n-1$ è positivo;
        \item Ad ogni iterazione $i$ aumenta di $1$ $\Rightarrow$ \textit{E} diminuisce di $1$;
        \item Quando $i=n+1 \; \Rightarrow \; i>n  \; \Rightarrow \; E=n-(n+1)=-1$, cioè diventa negativo proprio quando il ciclo finisce.
    \end{itemize}

    \vspace{8pt}
    \noindent
    A questo punto, dopo aver dimostrato la terminazione del ciclo \texttt{while}, è possibile dimostrare il funzionamento del codice tramite induzione.

    \vspace{5pt}
    \noindent
    \begin{minipage}[t]{0.275\textwidth}  
        \includegraphics[width=\linewidth]{figures/4_iterazione_ricorsione_induzione/img7.png}
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{230pt}{  
        \begin{minipage}[t]{0.698\textwidth}
            Come definito in precedenza, l'invariante del ciclo è dato da un asserto, in questo caso $S(j)$.
            \begin{tcolorbox}
            [
                colback=green!10,  % Sfondo verde chiaro
                colframe=green!60!black,  % Bordo verde più acceso
                coltitle=black,  % Colore del testo del titolo
                fonttitle=\bfseries,  % Testo del titolo in grassetto
                title={\centering \textbf{Cosa afferma l'asserto?}},  % Titolo centrato 
                enhanced,  % Miglioramenti grafici
                attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
                boxed title style={colback=white, colframe=green!60!black, rounded corners},
                breakable
            ]
                Se si raggiunge il controllo del ciclo $i \leqslant n$ quando la variabile $i$ ha un certo valore $j$, allora il valore della variabile \texttt{fatt} è \texttt{(j-1)!}

                \vspace{8pt}
                In altre parole, prima di ogni iterazione, \texttt{fatt} contiene il fattoriale  del numero precedente a $i$. Quindi:
                \begin{itemize}[leftmargin=1em]
                    \item quando $i=2, fatt=1!$;
                    \item quando $i=3, fatt= 2!$;
                    \item ecc...
                \end{itemize}
            \end{tcolorbox}
            Dimostriamo che l'asserto vale sia per il caso base che per il passo induttivo:
        \end{minipage} 
    }    
    \begin{enumerate}[leftmargin=1em]
        \item \textbf{Caso base}: nel caso base, prima del ciclo, $fatt=1$ e $i$ ha un valore $j=2$. Dunque $fatt=1=(j-1)=2-1=1$ e la \textbf{base è dimostrata}.
        \item \textbf{Passo induttivo}: nel passo induttivo, assumendo che $S(j)$ sia vera per un generico valore $j \leqslant n$, è stato dimostrato che la variabile \texttt{fatt}, prima della nuova iterazione, sia $fatt=(j-1)!$; Se si vuole dimostrare che anche $S(j+1)$, bisogna dimostrare che la variabile \texttt{fatt}, prima della nuova iterazione, sia $fatt=(j+1-1)! =j!$; Si distinguono due casi:
        \begin{itemize}[leftmargin=1em]
            \item Quando $i$ ha valore $j>n$: il ciclo è già finito (la guardia non si attiva più), e dunque il valore di \texttt{fatt}, sarà il valore finale, ovvero j!;
            \item Quando $i$ ha valore $j \leqslant n$: Dopo aver verificato che per $S(j)$ vale $fatt(j-1)!$ (con $i=j$) si esegue un'altra iterazione del ciclo.\\
            Dunque, in \textit{riga 5} troviamo che $fatt=fatt \times i=(j-1)! \times j$ che equivale alla definizione di $j!$, mentre in \textit{riga 6} si ha $i=i+1=j+1$.
            Ora al prossimo controllo della prossima iterazione si avrà $fatt=(j-1)! \times j=j!$ e $i=j+1$ che confermano l'asserzione $S(j+1)$.
        \end{itemize}
    \end{enumerate} 


    \subsubsection{Invarianti dei cicli - Esempio pratico con il \texttt{selectionSort()}}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Obbiettivo del \texttt{selectionSort()}
        ]
        Il \texttt{selectionSort()} prevede l'\textbf{ordinamento di un vettore} di $n$ elementi i quali \textbf{vengono permutati} in modo che essi compaiano in un ordine non decrescente.
    \end{tcolorbox}
    \noindent
    Possiamo descrivere il funzionamento del selection sort tramite il seguente pseudocodice:

    \vspace{2pt}
    \begin{figure}[H]
        \centering
        \vspace{-10pt}  % Riduce lo spazio sopra
        \includegraphics[width=0.7\textwidth]{figures/4_iterazione_ricorsione_induzione/img5.png}        
        \vspace{-15pt}  % Riduce lo spazio sopra
    \end{figure}

    \vspace{2pt}
    \noindent
    In particolare, come si può vedere in figura \textit{(a)}, l'ordinamento avviene nel seguente modo:
    \begin{enumerate}[leftmargin=1.3em]
        \item Nella prima iterazione troviamo (selezioniamo) uno degli elementi piu piccoli tra tutti i valori in $A[1...n]$ e lo scambiamo con $A[1]$;
        \item Nella seconda iterazione troviamo uno degli elementi piu piccoli tra tutti i valori in $A[2...n]$ e lo scambiamo con $A[2]$;
        \item Dopo l'iterazione i-esima, $A[1...i]$ contiene gli $i$ elementi piu piccoli ordinati in modo non decrescente;
    \end{enumerate}

    \vspace{8pt}
    \noindent
    Come si può vedere dall'immagine \textit{(b)}, l'asserzione induttiva (o invariante di ciclo) è chiamata $T(m)$. Quest'ultima, come detto al capitolo \ref{par:Invarianti dei cicli}, è una condizione che deve essere vera immediatamente prima del controllo di terminazione del ciclo, cioè prima di controllare $i>n-1$.\\
    Quando $i$ ha un certo valore $m$, sono già stati selezionati gli $m-1$ elementi più piccoli e ordinati nella posizione iniziale dell'array. In altre parole:

    \vspace{-15pt} 
    \begin{figure}[ht]
        \centering
        \vspace{-5pt}  % Riduce lo spazio sopra
        \subfloat[]{%
            \includegraphics[width=0.4\linewidth]{figures/4_iterazione_ricorsione_induzione/img3.png}
        } 
        \hspace{1cm}
        \subfloat[]{%
            \includegraphics[width=0.3\linewidth]{figures/4_iterazione_ricorsione_induzione/img4.png}
        }
        \vspace{-15pt}  % Riduce lo spazio sotto
    \end{figure}
    \FloatBarrier
    \begin{itemize}[leftmargin=1em]
        \item La parte sinistra dell'array $A[1...(m-1)]$ è già ordinata e contiene gli elementi più piccoli;
        \item La parte destra $A[m...n]$ è ancora da ordinare.
    \end{itemize}
    Questa è la proprietà $T(m)$, che \textbf{rimane vera ad ogni iterazione del ciclo} ($i=m$), quindi è proprio l'\textbf{invariante di ciclo}.

    \vspace{-8pt}
    \noindent
    \subsubsection*{\textit{Esempio}: dimostrazione tramite induzione}

    \vspace{-8pt}
    Come detto al capitolo \ref{par:Invarianti dei cicli}, per poter dimostrare un asserto tramite induzione, possiamo utilizzare valore della variabile indice del ciclo stesso, in questo caso $m$.\\
    Dunque, si dice che: \textbf{\textit{si può dimostrare per induzione su $m$ l'asserto $T(m)$}}.
    \begin{tcolorbox}
    [
        colback=green!10,  % Sfondo verde chiaro
        colframe=green!60!black,  % Bordo verde più acceso
        coltitle=black,  % Colore del testo del titolo
        fonttitle=\bfseries,  % Testo del titolo in grassetto
        title={\centering \textbf{Cosa afferma l'asserto?}},  % Titolo centrato 
        enhanced,  % Miglioramenti grafici
        attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
        boxed title style={colback=white, colframe=green!60!black, rounded corners},
        breakable
    ]
        Se si raggiunge il controllo del ciclo $i>n-1$ alla (linea 2) con $i=m$, allora:
        \begin{itemize}[leftmargin=1em]
            \item Gli elementi $A[1...(m-1)]$ sono ordinati in senso non decrescente: \\
            $A[1] \leqslant A[2] \leqslant \ldots \leqslant A[m-1]$;
            \item Tutti gli elementi di $A[m...n]$ sono maggiori o uguali a ogni elemento di $A[1...(m-1)]$.
        \end{itemize}
    \end{tcolorbox}
    \begin{enumerate}[leftmargin=1.3em]
        \item \textbf{Caso base}: quando $i=m=1$ siamo all'inizio dell'algoritmo, e non abbiamo ancora ordinato nulla. Per vedere se $T(1)$ è vera si controlla che l'asserto sia corretto:
        \begin{itemize}[leftmargin=1em]
            \item La parte $(1)$ di $T(1)$ dice che $A[1...m-1]=A[1...0]$ è ordinato, ma $A[1...0]$ è vuoto, quindi è banalmente vero (una sequenza vuota è sempre ordinata).
            \item La parte $(2)$ di $T(2)$  dice che tutti gli elementi in $A[m...n]=A[1...n]$ sono maggiori o uguali a quelli in $A[1...m-1]=A[1...0]$, ma anche in questo caso gli elementi in $A[1...0]$ non esistono, quindi la condizione è automaticamente vera.
        \end{itemize}
        Quindi T(1) è vera $\Rightarrow$ \textbf{caso base dimostrato}.

        \vspace{8pt}
        \noindent
        \item \textbf{Passo induttivo}: in questo passaggio si assume che $T(m)$ sia vera per un generico $m \leqslant n-1$, che verifica le condizioni dell'asserto, quindi:
        \begin{itemize}[leftmargin=1em]
            \item La prima parte dell'array $A[1...(m-1)]$ è già ordinata;
            \item Tutti gli elementi compresi in $A[1...(m-1)]$ sono $\leqslant$ di ogni elemento compreso in $A[m...n]$.
        \end{itemize}

        \vspace{8pt}
        \noindent
        Ora si vuole dimostrare che anche $T(m+1)$ sia vera. Durante l'iterazione con $i=m$:
        \begin{itemize}[leftmargin=1em]
            \item il ciclo interno (righe 3-9) \textbf{cerca il minimo} tra gli elementi non ordinati $A[m...n]$;
            \item poi \textbf{scambia} quel minimo con l'elemento $A[m]$ (quindi prima di tutti gli altri elementi non ordinati).
        \end{itemize}
        Anche dopo lo scambio rimane vero che:
        \begin{itemize}[leftmargin=1em]
            \item la porzione $A[1...m]$ è ora ordinata (perché il nuovo elemento in $A[m]$ è il più piccolo tra quelli rimanenti);
            \item tutti gli elementi in $A[(m+1)...n]$ rimangono $\geqslant$ di quelli precedenti.
        \end{itemize}
        Quindi $T(m+1)$ è vera perché subito dopo lo scambio il ciclo esterno icrementa la variabile $i$ da $m$ a $m+1$: \textit{“Dato che ora il valore di $i$ è $m+1$, l'asserzione $T(m+1)$ risulta vera.”}

        \vspace{8pt}
        \noindent
        \item \textbf{Conclusione}: nell'ultima iterazione, quando $i = m = n$
        \begin{itemize}[leftmargin=1em]
            \item i primi $n-1$ elementi $A[1...(n-1)]$ sono già ordinati e al posto giusto;
            \item l'ultimo elemento $A[n]$ è automaticamente $\geqslant$ di tutti gli altri.
        \end{itemize}
        Quando il programma termina, dunque, gli elementi di A sono in ordine non decrescente, cioè ordinati.
    \end{enumerate}


    \newpage
    \section{Le liste}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cos'è una lista (linked list)?
        ]
        È una possibile implementazione per la struttura dati astratta, \textbf{sequenza}. È costituita da una \textbf{sequenza di nodi}, contenenti dati arbitrari e $1/2$ puntatori all'elemento successivo e/o precedente.
    \end{tcolorbox}
    \begin{tcolorbox}
        [
            colback=green!10,  % Sfondo verde chiaro
            colframe=green!60!black,  % Bordo verde più acceso
            coltitle=black,  % Colore del testo del titolo
            fonttitle=\bfseries,  % Testo del titolo in grassetto
            title={\centering \textbf{Contiguità delle liste}},  % Titolo centrato 
            enhanced,  % Miglioramenti grafici
            attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
            boxed title style={colback=white, colframe=green!60!black, rounded corners},
            breakable
        ]
        È importante specificare che la contiguità degli elementi in una lista \textbf{non implica} una loro contiguità nella memoria (\textit{contiguità lista} $\nRightarrow$ \textit{contiguità in memoria}).

        \vspace{8pt}
        \noindent
        Nelle liste, infatti, i nodi \textbf{non sono necessariamente salvati in celle di memoria adiacenti}, come accade invece negli array. Ogni nodo può trovarsi in una posizione qualunque della memoria, e il \textbf{collegamento logico} tra di essi è \textbf{garantito dai puntatori}, non dalla loro vicinanza fisica.

        \vspace{8pt}
        \noindent
        \textbf{\textit{Esempio}}: possiamo immaginare che la CPU debba accedere a posizioni di memoria anche molto distanti tra loro per poter percorrere l'intera lista.
    \end{tcolorbox}
    \noindent
    Nel contesto delle \textbf{linked list}, le operazioni di \textbf{inserimento} o \textbf{cancellazione}, nota la posizione, hanno \textbf{costo costante}, cioè $O(1)$.\\
    Questo perché vengono utilizzati dei \textbf{passaggi fissi}, aggiornando un numero limitato di puntatori tra i nodi, indipendentemente dalla lunghezza della lista.

    \vspace{8pt}
    \noindent
    \textbf{\textit{Esempio}}: immaginiamo la seguente lista $[a] \rightarrow [b] \rightarrow [c]$.\\
    Se volessimo inserire un nuovo nodo \texttt{x} dopo $a$, sarebbe sufficiente:
    \begin{enumerate}[leftmargin=1.3em]
        \item creare il nodo \texttt{x};
        \item impostare \texttt{x.next = b};
        \item impostare \texttt{a.next = x}.
    \end{enumerate}
    Il numero di operazioni rimane invariato anche se la lista cresce, quindi il costo resta $O(1)$.\\
    Al contrario, l’accesso a un elemento tramite il suo indice richiede di scorrere la lista dall’inizio fino al nodo desiderato, con un costo $O(n)$.

    \vspace{10pt}
    \noindent
    \begin{minipage}[t]{0.660\textwidth}  
        \includegraphics[width=\linewidth]{figures/1_introduzione/img10.png}
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{210pt}{  
        \begin{minipage}[t]{0.315\textwidth}
            Le linked list presentano \textbf{diverse possibili implementazioni}:
            \begin{itemize}[leftmargin=1em]
                \item Liste \textbf{monodirezionali} o \textbf{bidirezionali};
                \item Liste con \textbf{sentinella} e \textbf{senza sentinella};
                \item Liste \textbf{circolari} e \textbf{non circolari}.
            \end{itemize}
        \end{minipage} 
    } 

    \subsection{Liste concatenate}
    \label{par:Liste concatenate}
    \begin{tcolorbox}
        [
            colback=green!10,  % Sfondo verde chiaro
            colframe=green!60!black,  % Bordo verde più acceso
            coltitle=black,  % Colore del testo del titolo
            fonttitle=\bfseries,  % Testo del titolo in grassetto
            title={\centering \textbf{Come sono strutturate?}},  % Titolo centrato 
            enhanced,  % Miglioramenti grafici
            attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
            boxed title style={colback=white, colframe=green!60!black, rounded corners},
            breakable
        ]
        La \textbf{lista singolarmente concatenata} (monodirezionale) è la più semplice struttura dinamica basata su nodi. La lista è definita da un \textit{"root (o head) pointer"} e sfrutta un \textbf{puntatore corrente} per la sua gestione.
    \end{tcolorbox}
    \noindent
    Le liste concatenate vengono definite nel seguente modo:

    \vspace{-12pt}
    \noindent
    \begin{minipage}[t]{0.36\textwidth}  
        \begin{lstlisting}[style=mystyle, language=C++]
struct slist {
    int dato;
    struct slist *next;
};
        \end{lstlisting}   
        \begin{lstlisting}[style=mystyle, language=C++]
/* lista vuota */
struct slist *root = NULL; 
        \end{lstlisting}   
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{19pt}{  
        \begin{minipage}[t]{0.608\textwidth}
            \begin{figure}[H]
                \includegraphics[width=\linewidth]{figures/1_introduzione/img11.png}          
            \end{figure}

            \vspace{-12pt}
            Come si può vedere, quando viene inizializzato il puntatore root (la testa della lista) a \textbf{\textit{null}}, la lista è vuota.
        \end{minipage}   
    }

    \vspace{8pt}
    \noindent
    Per manipolare una lista semplicemente concatenata esistono \textbf{diverse funzioni}, tra cui:
    \begin{itemize}[leftmargin=1em]
        \item Inserimento di un nodo (prima del puntatore corrente);
        \item Cancellazione di un nodo (indicato dal puntatore corrente);
        \item Creazione nuova lista;
        \item Cancellazione lista;
        \item Attraversamento con esecuzione di funzione;
        \item Ricerca con esecuzione di funzione;
        \item Concatenazione;
        \item Conteggio;
        \item Inserimento ordinato.
    \end{itemize}

    \subsubsection{Inserimento in testa}
Tramite la seguente funzione è possibile inserire un nuovo elemento in testa alla lista.
    \begin{lstlisting}[style=mystyle, language=C++, numbers=left]
slist *insert(slist *p, int elem) {
    slist *q = malloc(sizeof(slist));

    if(!q) {
        fprintf(stderr,"Allocation error\n");
        exit(-1);
    }
    q->dato = elem;
    q->next = p;
    return q;
}
    \end{lstlisting}
    \begin{figure}[H]
        \centering
        \vspace{-5pt}  % Riduce lo spazio sopra
        \includegraphics[width=0.8\textwidth]{figures/1_introduzione/img12.png}        
        \vspace{-15pt}  % Riduce lo spazio sopra
    \end{figure}
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Tipo di ritorno}: La funzione restituisce un puntatore a \texttt{slist}. Il puntatore restituito sarà la nuova testa della lista;
        \item \textbf{Parametri}: i parametri definiti nella funzione sono (\texttt{slist *p, int elem}), rispettivamente il \textbf{puntatore corrente} alla testa della lista (che può essere \texttt{null} se la lista è vuota) e il \textbf{valore da inserire} nel nuovo nodo;
        \item \textbf{Funzionamento del codice}: per poter inserire un nuovo nodo in testa alla lista, supponiamo di possedere una struttura dati come quella definita al capitolo \ref{par:Liste concatenate}.
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{2}\rule{0.6ex}{0.6ex}}]
            \item \textit{riga 2}: creo un puntatore \texttt{*q} al nuovo nodo di grandezza \texttt{slist};
            \item \textit{riga 4-7}: eseguo un crontollo su \texttt{q} per assicurarmi che la \texttt{malloc} sia andata a buon fine;
            \item \textit{riga 8}: il campo \texttt{dato} del nuovo nodo prende il valore di \texttt{elem} passato tramite la funzione;
            \item \textit{riga 9}: Collega il nuovo nodo al resto della lista: il campo \texttt{next} del nuovo nodo punta all'elemento che era in testa (\texttt{p}).
            \begin{itemize}[leftmargin=1.4em]
                \item [$\rightarrow$] \textbf{Se la lista è vuota} (\texttt{p == null}), la nuova lista contiene solo in nuovo nodo \texttt{q}, qundi: \texttt{q -> next = null};
                \item [$\rightarrow$] \textbf{Se la lista non è vuota}, \texttt{q} è inserito prima della vecchia testa: \texttt{q -> old\_head -> ...}
            \end{itemize} 
            \item \textit{riga 10}: restituisce il puntatore al nuovo nodo: ora \texttt{q} è la testa della lista aggiornata
        \end{itemize} 
    \end{itemize}

    \vspace{8pt}
    \noindent
    \textbf{\textit{Esempio di utilizzo}}
    \begin{lstlisting}[style=mystyle, language=C++]
slist *head = NULL;      // lista vuota
head = insert(head, 10); // ora head punta al nodo con dato 10
head = insert(head, 5);  // ora head punta al nodo con dato 5; next punta al nodo 10
    \end{lstlisting}

    \subsubsection{Inserimento generico}
    \label{par:Inserimento generico}
Questa funzione è un passo avanti rispetto alla \texttt{insert()}. \texttt{insert2()} permette un inserimento generico in qualunque posizione della lista (in testa, in mezzo o in coda).
    \begin{lstlisting}[style=mystyle, language=C++, numbers=left]
slist *insert2(slist *p, slist *q, int elem) {
    slist *x;
    slist *r = malloc(sizeof(slist));
    if(!r) {
        fprintf(stderr,"Allocation error\n");
        exit(-1);
    }
    r->dato = elem;
    if(p == q){ // in testa
        r->next=p; 
        return r;
    } 
    else{ // in mezzo o in coda (se q==NULL)
        for(x= p; x && x->next != q; x = x->next);

        // prima di collegare mi assicuro che q sia valido
        if(x && x->next == q){ 
            r->next = q; 
            x->next = r; 
        }
        return p;
    }
}
    \end{lstlisting}
    \begin{figure}[H]
        \centering
        \vspace{-5pt}  % Riduce lo spazio sopra
        \includegraphics[width=0.9\textwidth]{figures/1_introduzione/img13.png}        
        \vspace{-15pt}  % Riduce lo spazio sopra
    \end{figure}
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Tipo di ritorno}: La funzione restituisce un puntatore a \texttt{slist}, ovvero il puntatore alla testa aggiornata della lista.
        \item \textbf{Parametri}: i parametri definiti nella funzione sono (\texttt{slist *p, slist *q, int elem}), rispettivamente:
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{3}\rule{0.6ex}{0.6ex}}]
            \item il \textbf{puntatore corrente} alla testa della lista (che può essere \texttt{null} se la lista è vuota);
            \item il \textbf{puntatore al nodo di riferimento} (davanti al quale inserire) oppure \texttt{null} se si vuole inserire in coda;
            \item l \textbf{valore da inserire} nel nuovo nodo.
        \end{itemize}
        \item \textbf{Funzionamento del codice}: per poter inserire un nuovo nodo in testa alla lista, supponiamo di possedere una struttura dati come quella definita al capitolo \ref{par:Liste concatenate}.
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{4}\rule{0.6ex}{0.6ex}}]
            \item \textit{riga 2}: \texttt{x} è un puntatore alla lista che serve come supporto per eseguire lo scorrimento della stessa;
            \item \textit{riga 3}: creo un puntatore \texttt{*r} al nuovo nodo di grandezza \texttt{slist};
            \item  \textit{riga 4-7}: eseguo un crontollo su \texttt{r} per assicurarmi che la \texttt{malloc} sia andata a buon fine;
            \item \textit{riga 8}: inizializzo il campo \texttt{dato} del nuovo nodo con il valore del campo \texttt{elem} passato tra i parametri;
            \item \textit{riga 9-12}: viene \textbf{gestito l'inseriemento in testa}. Infatti, se il nodo \texttt{q} coincide con \texttt{p}, mi basta semplicemente collegare il nuovo nodo alla vecchia testa (\texttt{r -> next = p}), e poi restituire il nuovo nodo (\texttt{return r});
            \item \textit{riga 13-21}: viene \textbf{gestito l'inserimento in mezzo o in coda}.\\
            Tramite il ciclo \texttt{for} si fa scorrere il puntatore di appoggio (\texttt{x}) partendo dalla testa (\texttt{p}) della lista. Lo scorrimento continua fintanto che è verificata la condizione \texttt{x->next!=q}, e \textbf{presenta due possibilità di terminazione}:
            \begin{enumerate}[leftmargin=1.3em]
                \item La condizione diventa \texttt{x->next==q} poiché \texttt{q} è un nodo interno alla lista. In altre parole quando \texttt{x} precede il nodo \texttt{q} specificato nei parametri, si esce dal ciclo;
                \item La condizione non si avvera perché il \texttt{q} passato nei parametri è \texttt{null}, e il ciclo termina le sue iterazioni.
            \end{enumerate}
            
            \vspace{8pt}
            \noindent
            Dato che lo scorrimento ha due possibili terminazioni, bisognerà effettuare un ulteriore controllo per determinare se si tratta di un inserimento \textbf{in mezzo o in coda}.\\
            La condizione dell'\texttt{if} indica che \texttt{x != null} e che \texttt{x->next==q}, dunque:
            \begin{enumerate}[leftmargin=1.3em]
                \item Si ha un \textbf{inserimento in mezzo} quando si verifica il caso $1$.\\
                In questo caso (\texttt{r->next=q}) collega il nuovo nodo al nodo di riferimento, mentre (\texttt{x->next=r}) collega il nodo precedente al nuovo nodo.
                \item Si ha un \textbf{inserimento in coda} quando si verifica il caso $2$. In questo caso \texttt{q==null}, per cui \texttt{r->next=null} diventando così l'ultimo nodo della lista, mentre il precedente ultimo nodo viene aggiornato con \texttt{x->next = r}..
            \end{enumerate}
        \end{itemize} 
    \end{itemize}

    \vspace{8pt}
    \noindent
    \textbf{\textit{Esempio di utilizzo}}
    \begin{lstlisting}[style=mystyle, language=C++]
slist *head = NULL;   // lista vuota

// Inserisco alcuni elementi in testa (uso insert2 con q == p)
head = insert2(head, head, 56);   // lista: 56
head = insert2(head, head, 45);   // lista: 45 -> 56
head = insert2(head, head, 23);   // lista: 23 -> 45 -> 56
printList(head);

// Inserimento in mezzo (prima di 56)
slist *q = head->next->next;      // q punta al nodo con dato 56
head = insert2(head, q, 8);       // inserisco 8 prima di 56
printList(head);                  // lista: 23 -> 45 -> 8 -> 56

// Inserimento in coda (q == NULL)
head = insert2(head, NULL, 12);   // inserisco 12 alla fine
printList(head);                  // lista: 23 -> 45 -> 8 -> 56 -> 12

return 0;
    \end{lstlisting}

    \subsubsection{Cancellazione elemento corrente}
    La funzione \texttt{delete()} consente di eliminare un nodo specifico (\texttt{q}) da una lista semplicemente concatenata la cui testa è puntata da \texttt{p}, assumendo che \texttt{q != null}.
    \begin{lstlisting}[style=mystyle, language=C, numbers=left]
slist *delete(slist *p, slist *q) {
    slist *r;
    if(p == q) p = p->next;
    else {
        for(r = p; r && r->next != q; r = r->next);
        if(r && r->next == q)
        r->next = r->next->next;
    }
    free(q);
    return p;
}
    \end{lstlisting}
    \begin{figure}[H]
        \centering
        \vspace{-10pt}  % Riduce lo spazio sopra
        \includegraphics[width=0.75\textwidth]{figures/1_introduzione/img14.png}        
        \vspace{-15pt}  % Riduce lo spazio sopra
    \end{figure}
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Tipo di ritorno}: la funzione restituisce un puntatore a \texttt{slist}, ovvero il puntatore alla testa aggiornata della lista dopo l'eliminazione;
        \item \textbf{Parametri}: i parametri definiti nella funzione sono (\texttt{slist *p, slist *q}), rispettivamente il \textbf{puntatore corrente} alla testa della lista  e il \textbf{puntatore al nodo di riferimento} (davanti al quale rimuovere);
        \item \textbf{Funzionamento del codice}:  per poter eliminare un nodo all'interno della lista, supponiamo di possedere una struttura dati come quella definita al capitolo \ref{par:Liste concatenate}.
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{5}\rule{0.6ex}{0.6ex}}]
            \item \textit{riga 2}: dichiarazione di un puntatore ausiliario \texttt{r}, che servirà per scorrere la lista.
            \item \textit{riga 3}: se \texttt{p == q}, significa che il nodo da eliminare è la testa della lista.       
            In questo caso basta avanzare la testa al nodo successivo: \texttt{p = p->next};
            \item \textit{riga 4-8}: se il nodo da eliminare non è quello in testa alla lista (\texttt{p!=q}), utilizzando il puntatore ausiliario, utilizzo un ciclo per scorrere tutti i nodi, \textbf{ricordando che il nodo \texttt{q}} specificato nei parametri \textbf{non è \texttt{null}}.\\
            Proprio \textbf{per questo motivo}, a differenza di quanto detto nel capitolo \ref{par:Inserimento generico}, ho \textbf{un solo caso di terminazione}, e cioé quando \texttt{r->next=q}, ovvero il nodo precedente a quello da eliminare.\\
            Trovato il predecessore di \texttt{q}, quest'ultimo si salta collegando \texttt{r->next} direttamente al nodo successivo a  \texttt{q}, ovvero \texttt{r->next=r->next->next};
            \item \textit{riga 9}: si libera la memoria allocata dal nodo eliminato \texttt{q};
            \item \textit{riga 10}: restituzione del puntatore alla testa aggiornato.
        \end{itemize}
    \end{itemize}

    \vspace{8pt}
    \noindent
    \textbf{\textit{Esempio di utilizzo}}
    \begin{lstlisting}[style=mystyle, language=C]
slist *head = NULL;

// Creo una lista: 23 -> 45 -> 56 -> 12 
head = insert2(head, head, 56);
head = insert2(head, head, 45);
head = insert2(head, head, 23);
head = insert2(head, NULL, 12);

printList(head);  // Output: 23 -> 45 -> 56 -> 12 -> NULL

// Elimino il nodo in testa
head = delete(head, head);
printList(head);  // Output: 45 -> 56 -> 12 -> NULL

// Elimino un nodo in mezzo (quello con dato 56)
slist *q = head->next; 
head = delete(head, q);
printList(head);  // Output: 45 -> 12 -> NULL

// Elimino il nodo in coda
q = head->next;
head = delete(head, q);
printList(head);  // Output: 45 -> NULL

return 0;
    \end{lstlisting}

    \subsubsection{Creazione lista}
    La funzione \texttt{createlist()} crea una lista vuota e ne restituisce il puntatore radice.
    \begin{lstlisting}[style=mystyle, language=C, numbers=left]
slist *createlist(void) {
    return NULL;
}
    \end{lstlisting}
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Tipo di ritorno}: la funzione restituisce un puntatore a \texttt{slist}, cioè al tipo di dato che rappresenta un nodo della lista;
        \item \textbf{Parametri}: il parametro è vuoto, perché non serve alcuna informazione esterna per creare una lista vuota;
        \item \textbf{Funzionamento del codice}: per poter creare una lista vuota, supponiamo di possedere una struttura dati come quella definita al capitolo \ref{par:Liste concatenate}. Il codice si occupa semplicemente di restituire \texttt{null}, che rappresenta una lista vuota (assenza di nodi).
    \end{itemize}

    \vspace{8pt}
    \noindent
    \textbf{\textit{Esempio di utilizzo}}
    \begin{lstlisting}[style=mystyle, language=C]
// Creazione di una lista vuota
slist *head = createlist();

// Inserimento di elementi
head = insert2(head, head, 10);
head = insert2(head, head, 20);
head = insert2(head, head, 30);

printList(head);  // Output: 10 -> 20 -> 30 -> NULL

return 0;
    \end{lstlisting}

    \subsubsection{Cancellazione intera lista}
    La funzione \texttt{destroylist()} distrugge una lista, assumendo che \texttt{p!=null}.
    \begin{lstlisting}[style=mystyle, language=C++, numbers=left]
void destroylist(slist *p){
    while(p = delete(p,p)); // N.B: cancello in testa
}
    \end{lstlisting}
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Tipo di ritorno}: la funzione non restituisce alcun valore, poiché il suo scopo è esclusivamente quello di deallocare la memoria della lista passata come argomento;
        \item \textbf{Parametri}: Il parametro \texttt{p} rappresenta il puntatore alla testa della lista che si vuole distruggere;
        \item \textbf{Funzionamento del codice}: all'interno del ciclo \texttt{while}, viene eseguita ripetutamente l'istruzione \texttt{p = delete(p, p)}.\\ Ad \textbf{ogni iterazione viene eliminato il primo nodo della lista}, poiché la funzione \texttt{delete()} viene chiamata passando due volte lo stesso puntatore \texttt{(p, p)}, cioè indicando che il nodo da cancellare è proprio la testa.\\
        La funzione \texttt{delete()} restituisce il nuovo puntatore alla testa della lista (che è ora il nodo successivo): il ciclo \texttt{while} continua fino a quando \texttt{delete()} restituisce \texttt{null}, cioè finché non rimangono più nodi da cancellare.
    \end{itemize}

    \noindent
    \textbf{\textit{Esempio di utilizzo}}
    \begin{lstlisting}[style=mystyle, language=C]
// Creazione di una lista
slist *head = createlist();

// Inserimento di elementi
head = insert2(head, head, 10);
head = insert2(head, head, 20);
head = insert2(head, head, 30);

printList(head);  // Output: 10 -> 20 -> 30 -> NULL

destroylist(head); // Distruzione della lista

return 0;
    \end{lstlisting}

    \subsubsection{Attraversamento con funzione}
    La funzione \texttt{traverse()} ha lo scopo di scorrere (visitare) tutti i nodi di una lista concatenata ed eseguire, su ciascuno di essi, un'operazione specificata dall'utente.
    \begin{lstlisting}[style=mystyle, language=C++, numbers=left]
void traverse(slist *p, void (*op)(slist *)){
    slist *q;
    for(q = p; q; q = q->next) (*op)(q);
}
    \end{lstlisting}
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Tipo di ritorno}: la funzione non restituisce alcun valore. Il suo scopo è \textbf{puramente esecutivo}, applicando una funzione a ogni elemento della lista;
        \item \textbf{Parametri}: i parametri definiti nella funzione sono \texttt{(slist *p, void (*op)(slist *))}, rispettivamente il \textbf{puntatore alla testa} della lista che si vuole attraversare e un \textbf{puntatore a funzione}, ovvero un parametro che rappresenta una funzione da richiamare per ogni nodo visitato. Tale funzione deve avere \texttt{la stessa firma}, cioè ricevere come parametro un puntatore a \texttt{slist} e non restituire nulla (tipo \texttt{void});
        \item \textbf{Funzionamento del codice}:  per poter scorrere una lista, supponiamo di possedere una struttura dati come quella definita al capitolo \ref{par:Liste concatenate}.
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{6}\rule{0.6ex}{0.6ex}}]
            \item \textit{riga 2}: viene dichiarato un puntatore \texttt{*q}, che servirà come puntatore di scorrimento.
            \item \textit{riga 3}: inizia il ciclo che scorre l'intera lista partendo dalla testa. Ad ogni iterazione viene chiamata la \textbf{funzione passata come parametro} \texttt{(op)}, applicandola al nodo corrente: \texttt{(*op)(q)}. Il ciclo termina quando \texttt{q} diventa \texttt{null}, cioè quando è stato raggiunto l'ultimo nodo della lista.
            \begin{lstlisting}[style=mystyle, language=C++]
/* Esempio: funzione op che stampa il contenuto del nodo */
void printelem(slist *q) {
    printf("\t-------\n\t|%5d|\n\t-------\n\t| %c |\n\t---%c---\n\t",
           q->dato,
           q->next ? '.' : 'X',
           q->next ? '|' : '-');
    if(q->next) printf(" | \n\t V\n");
}
            \end{lstlisting}
        \end{itemize}
    \end{itemize}

    \noindent
    \textbf{\textit{Esempio di utilizzo}}
    \begin{lstlisting}[style=mystyle, language=C]
// Creazione della lista
slist *head = createlist();
head = insert2(head, head, 10);
head = insert2(head, NULL, 20);
head = insert2(head, NULL, 30);

// Attraversamento della lista e stampa di ciascun elemento
printf("Contenuto della lista:\n");
traverse(head, printelem);

return 0;
    \end{lstlisting}

    \subsubsection{Ricerca elemento con funzione}

    \newpage
    \section{Alberi}
    L'albero ordinato (spesso chiamato più semplicemente “albero”) è una struttura informativa fondamentale, che si presta a rappresentare svariate situazioni, quali:
    \begin{itemize}[leftmargin=1em]
        \item Partizioni successive di un insieme in sottoinsiemi disgiunti;
        \item Organizzazioni gerarchiche di dati;
        \item Procedimenti enumerativi o decisionali.
    \end{itemize}

    \vspace{8pt}
    \noindent
    L'\textbf{implementazione} avviene, come per le liste, attraverso l'uso di \textbf{strutture autoreferenziali} e \textbf{puntatori}.
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Struttura di un albero ordinato (o radicato)
        ]
        Un \textbf{albero ordinato} è dato da un insieme finito di elementi (dunque una \textbf{struttura dati statica}) detti \textbf{nodi} e un insieme di \textbf{archi orientati} che connettono coppie di nodi.

        \vspace{8pt}
        Ogni albero presenta le seguenti proprietà:
        \begin{itemize}[leftmargin=1em]
            \item Un nodo dell'albero è designato come nodo \textbf{radice};
            \item Ogni nodo $n$, a parte la radice, ha esattamente un \textbf{arco entrante};
            \item Esiste un \textbf{cammino unico} dalla radice a ogni nodo;
            \item L'albero \textbf{è connesso}: non esistono elementi che non fanno parte dell'albero, ovvero che non sono connessi tramite il cammino di archi all'albero stesso.
        \end{itemize}
    \end{tcolorbox}
    \noindent    
    \begin{minipage}[t]{0.603\textwidth}  
        \includegraphics[width=\linewidth]{figures/3_alberi/img1.png}
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{185pt}{  
        \begin{minipage}[t]{0.373\textwidth}
            Dunque, l'albero rappresenta una struttura gerarchica nella quale a partire da un elemento
            molto grande (come in questo cao il "regno animale") si divide in sottoclassi, fino ad arrivare ai singoli elementi.

            \vspace{8pt}
            Un esempio che si avvicina maggiormente all'ambito dei sistemi operativi, come si può vedere in Figure~\ref{fig:figura23}, è un albero del file system (come quello di linux), dove si ha
        \end{minipage} 
    } 
    un'organizzazione in cartelle, partendo dalla radice, per ogni elemento dell'albero, fino ad arrivare ai singoli file.
    \begin{figure}[H]
        \centering
        \addtocounter{figure}{15}
        \vspace{-10pt}  % Riduce lo spazio sopra
        \includegraphics[width=\textwidth]{figures/3_alberi/img2.png}
        \vspace{-20pt}  % Riduce lo spazio sopra
        \caption{Albero del file system linux}
        \label{fig:figura23}
    \end{figure}

    \subsection{Terminologia}
    Sia $T$ un albero ordinato di $n$ nodi, con radice $r$.\\
    Possiamo definire $T_1, ..., T_k$ gli insiemi disgiunti e non vuoti in cui sono partizionati tutti i nodi di $T$, ognuno dei quali avrà come radice un nodo $r_1, ..., r_k$.
    \begin{itemize}[leftmargin=1em]
        \item Ciascun $T_i$ è detto \textbf{sottoalbero} di $T$, mentre ciascun $r_i$ è detto \textbf{figlio} di $r$;
        \item I nodi $r_1, ..., r_k$ sono tra loro \textbf{fratelli}, ed $r$ è il loro \textbf{padre}.
        \item Inoltre, un nodo senza figli è detto \textbf{foglia}, mentre la radice dell'abero (\textbf{root}) è l'unico \textbf{nodo senza padre}.
    \end{itemize} 

    \vspace{8pt}
    \noindent
    Oltre alla terminologia che assumono i nodi dell'albero in base alla loro posizione, l'albero in se presenta alcune caratteristiche:

    \vspace{-2pt}
    \noindent
    \begin{minipage}[t]{0.603\textwidth}  
        \includegraphics[width=\linewidth]{figures/3_alberi/img3.png}
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{127pt}{  
        \begin{minipage}[t]{0.373\textwidth}
            \begin{itemize}[leftmargin=1em]
                \item \textbf{\textit{Profondita dei nodi (depth)}}: profondità del cammino semplice dalla radice al nodo (misurata in numero di archi percorsi). Ad esempio, la radice avrà profondità $0$, i figli avranno profondità $1$, i figli dei figli avranno profondità $2$ e cosi via...
                \item \textbf{\textit{Altezza albero (height)}}: indica 
            \end{itemize} 
        \end{minipage} 
    } 
    la profondità massima delle sue foglie. Ad esempio, $T_1$ ha altezza $3$, mentre $T_2$ e $T_3$ altezza $2$; 
    \begin{itemize}[leftmargin=1em]
        \item \textbf{\textit{Livello (level)}}: si riferisce all'insieme di nodi alla stessa profondità;
    \end{itemize} 

    \subsection{Alberi binari}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cos'è un'albero binario?
        ]
        Un albero binario è un particolare albero ordinato in cui ogni nodo ha \textbf{al più due figli}, e si fa distinzione tra figlio \textbf{sinistro} e figlio \textbf{destro}.\\
        \textbf{\textit{N.B}}: in alcune implementazioni può esserci un puntatore al padre.
    \end{tcolorbox}
    \noindent
    \begin{minipage}[t]{0.600\textwidth}  
        \includegraphics[width=\linewidth]{figures/3_alberi/img4.png}
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{134pt}{  
        \begin{minipage}[t]{0.376\textwidth}
            La proprietà degli alberi binari è \textbf{molto delicata}: infatti, anche se due alberi $T_1$ e $T_2$ hanno gli stessi nodi e la stessa radice, essi risultano diversi se in $T_1$ un nodo $u$ è figlio sinistro di un nodo $v$, mentre in $T_2$ lo stesso nodo $u$ è figlio destro di $v$.

            \vspace{8pt}
            Nell'esempio mostrato, l'abero $T_1$ presenta al massimo due figli per
        \end{minipage} 
    } 

    \vspace{2pt}
    \noindent
    ogni nodo, ma la rappresentazione grafica non aiuta a comprendere se si tratta di un figlio destro o sinistro. Al contrario $T_2$ e $T_3$ sono alberi binari e distinti, poiché non hanno gli stessi figli destri e sinistri.

    \subsubsection{Creazione di un albero binario}
    \label{par:Creazione di un albero binario}
    Come per qualsiasi struttura dati (liste concatenate, doppiamente concatenate, ecc...) anche per poter utilizzare un albero è necessario definire una struttura e inizializzarla nel main:
    \begin{minipage}[t]{0.5\textwidth}  
        \textit{Struttura dell'albero}
        \begin{lstlisting}[style=mystyle, language=C++]
struct inttree {
    int data;
    struct inttree *left, *right;
};
        \end{lstlisting} 
        \textit{Inizializzazione dell'albero}
        \begin{lstlisting}[style=mystyle, language=C++]
inttree *root = NULL;
//Puntatore alla struttura
        \end{lstlisting}    
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{-15pt}{  
        \begin{minipage}[t]{0.468\textwidth}
            Per quanto riguarda la struttura dell'albero:
            \begin{itemize}[leftmargin=1em]
                \item \texttt{data}: contiene il valore del nodo;
                \item \texttt{*left}: è il puntatore al nodo sinistro;
                \item \texttt{*right}: è il puntatore al nodo destro.
            \end{itemize}

            \vspace{8pt}
            Invece, l'inizializzazione dell'albero è effettuata tramite, \texttt{root} rappresenta la radice che all'inizio è impostata a \texttt{null} per indicare l'albero vuoto.
        \end{minipage}   
    }
    \begin{tcolorbox}
        [
            colback=green!10,  % Sfondo verde chiaro
            colframe=green!60!black,  % Bordo verde più acceso
            coltitle=black,  % Colore del testo del titolo
            fonttitle=\bfseries,  % Testo del titolo in grassetto
            title={\centering \textbf{Alberi binari e definizione ricorsiva}},  % Titolo centrato 
            enhanced,  % Miglioramenti grafici
            attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
            boxed title style={colback=white, colframe=green!60!black, rounded corners},
            breakable
        ]
        Gli alberi binari ammettono una \textbf{definizione ricorsiva} come insieme finito di nodi, che può essere:
        \begin{itemize}[leftmargin=1em]
            \item Un \textbf{insieme vuoto}, cioè nessun nodo.\\ Rappresenta l'albero "vuoto" senza radice e senza figli, come quando viene inizializzato nel main e nessun è stato ancora allocato in memoria (\texttt{inttree *root = NULL;})
            \item Oppure, un nodo radice con \textbf{due sottoalberi binari disgiunti}, uno sinistro e uno destro.
        \end{itemize}
    \end{tcolorbox}
    
    \subsubsection{Costruzione di un albero binario}
    \label{par:Costruzione di un albero binario}
    Dopo aver proceduto con la creazione della struttura e l'inizializzazione dell'albero, si procede con la sua creazione, allocando i vari nodi e definendo i puntatori per il figlo destro e sinistro.
    \begin{lstlisting}[style=mystyle, language=C, numbers=left]
int main(int argc, char *argv[]) {
    //Livello 0
    inttree *root = NULL;
    root = malloc(sizeof(inttree));
    root->data = 1;

    //Livello 1
    root->left = malloc(sizeof(inttree));
    root->right = malloc(sizeof(inttree));
    root->left->data = 2;
    root->right->data = 3;
    root->right->left = NULL;
    root->right->right = NULL;

    //Livello 2
    root->left->left = malloc(sizeof(inttree));
    root->left->right = malloc(sizeof(inttree));
    root->left->left->data = 4;
    root->left->right->data = 5;
    root->left->left->left = NULL;
    root->left->left->right = NULL;
    root->left->right->left = NULL;
    root->left->right->right = NULL;
}
    \end{lstlisting}
    \noindent
    \begin{minipage}[t]{0.327\textwidth}  
        \includegraphics[width=\linewidth]{figures/3_alberi/img5.png}
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{165pt}{  
        \begin{minipage}[t]{0.650\textwidth}
            \begin{itemize}[leftmargin=1em]
                \item \textbf{Blocco 1}: vengono allocati i nodi al livello $0$ dell'albero.
                    \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{7}\rule{0.6ex}{0.6ex}}]
                        \item \textit{riga 2}: il puntatore \texttt{root} (\texttt{*root}), definito in precedenza, viene associato al nodo radice dell'albero, puntando a un'area di memoria allocata dinamicamente della dimensione della struttura \texttt{inttree};
                        \item \textit{riga 3}: inizializza il campo \texttt{data} del nodo radice a $1$
                    \end{itemize}

                \vspace{8pt}
                \item \textbf{Blocco 2}: vengono allocati i nodi al livello $1$ dell'albero.
                    \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{8}\rule{0.6ex}{0.6ex}}]
                        \item \textit{riga 6-7}: il nodo radice presenta al suo interno due puntatori, \texttt{left} e \texttt{right}, i quali punteranno a due nodi \texttt{inttree} differenti, corrispondenti rispettivamente ai figli sinistro e destro;
                    \end{itemize}
            \end{itemize}
        \end{minipage} 
    }  

    \vspace{3pt}
    \begin{itemize}[leftmargin=1.85em, label=\raisebox{0.4ex}{\phantom{8.1}\rule{0.6ex}{0.6ex}}]
        \item \textit{riga 8-9}: viene inizializzato il campo \texttt{data} dei figli della radice, assegnando $2$ al figlio sinistro e $3$ al figlio destro;
        \item \textit{riga 10-11}: come per il nodo radice, anche le strutture dei suoi nodi figli avranno dei puntatori \texttt{left} e \texttt{right}. In queste due righe i puntatori \texttt{left} e \texttt{right} del figlio destro vengono impostati a \texttt{NULL}, a indicare che esso non ha ulteriori discendenti.
    \end{itemize}

    \vspace{8pt}
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Blocco 3}: vengono allocati i nodi al livello $2$ dell'albero.
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{9}\rule{0.6ex}{0.6ex}}]
            \item \textit{riga 13-14}: i puntatori \texttt{left} e \texttt{right} del figlio sinistro della radice vengono associati a due nuovi nodi \texttt{inttree};
            \item \textit{riga 15-16}: viene inizializzato il campo \texttt{data} di questi due nodi, assegnando $4$ al figlio sinistro e $5$ al figlio destro;
            \item \textit{riga 17-20}: i puntatori \texttt{left} e \texttt{right} di entrambi questi nodi vengono impostati a \texttt{NULL}, indicando che non hanno ulteriori figli.
        \end{itemize}
    \end{itemize}

    \subsection{Le visite}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cos'è una visita?
        ]
        Una \textbf{visita} (o attraversamento) di un albero ordinato è una strategia consiste nel seguire una "rotta" di viaggio che consenta di \textbf{analizzare ogni nodo} dell'albero almeno una volta.
    \end{tcolorbox}
    \noindent
    Una visita può essere eseguita in \textbf{due modi}:
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Visita in profondità} (Deep-First Search - \textbf{DFS}): in questo caso si segue un percorso radice-foglia, ovvero per visitare un albero \textbf{si visita ricorsivamente} ognuno dei suoi \textbf{sottoalberi}, andando da sinistra verso destra. Questo tipo di visita presenta \textbf{tre varianti} (ordini):
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{10}\rule{0.6ex}{0.6ex}}]
            \item Ordine anticipato (\textbf{preorder});
            \item Ordine posticipato (\textbf{postorder});
            \item Ordine simmetrico (\textbf{inorder}).
        \end{itemize}
        Un'analisi di questo tipo \textbf{richiede uno stack}: si visita l'albero utilizzando uno stack che però viene già reso disponibile tramite il \textbf{meccanismo di ricorsione}.
        
        \item \textbf{Visita in ampiezza} (Breadth First Search - BFS): partendo dalla radice, vengono visitati i nodi livello per livello, “orizzontalmente”, fino a raggiungere il livello massimo dell'albero.\\
        Proprio per questo, un analisi di questo tipo viene anche detta \textbf{\textit{ordine per livelli}}.
    \end{itemize}

    \vspace{8pt}
    \noindent
    Sia $T$ un albero non vuoto di radice $r$. Se $r$ non è una foglia ma ha $k>0$ figli, indichiamo con $T_1, ..., T_k$ i k sottoalberi di $T$ radicati nei $k$ figli di $r$. Gli ordini di visita in profondità sono definiti ricorsivamente come segue:

    \subsubsection{Visita in preorder (DFS)}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Funzionamento della visita in preorder
        ]
        La \textbf{visita in preorder} di $T$ consiste nell'esaminare $r$ e poi nell'effettuare, nell'ordine, la previsita dei sottoalberi $T_1, ..., T_k$.
    \end{tcolorbox}
    \begin{figure}[h]
        \centering
        \vspace{-18pt}  % Riduce lo spazio sopra
        \subfloat[albero attraversato in preorder]{%
            \includegraphics[width=0.42\textwidth]{figures/3_alberi/img6.png}%
        }
        \hspace{2cm}
        \subfloat[Pseudocodice visita in preorder]{%
            \includegraphics[width=0.35\textwidth]{figures/3_alberi/img7.png}%
        }
        \vspace{-10pt}  % Riduce lo spazio sotto
    \end{figure}
    \noindent
    Per capire il funzionamento della visita in preorder, dividiamo il procedimento in alcuni passi, vedendo come evolvolvono la sequenza di stampa (attraversamento dell'albero), e lo stack di chiamate (ricorsività della funzione \texttt{dfs()}):

    \vspace{8pt}
    \begin{enumerate}[leftmargin=1.3em]
        \item In questo tipo di visita si parte sempre chiamando la funzione rispetto al nodo $A \rightarrow$ \texttt{dfs(Tree A)}. Pertanto la sequenza di stampa inizia con $A$, e la chiamata viene memorizzata nello stack delle chiamate.

        \begin{itemize}[leftmargin=1em]
            \item \textit{Sequenza di stampa}: $A$
            \item \textit{Stack chiamate}: $A$
        \end{itemize}

        \item Dopo aver stampato il nodo $A$, la funzione richiama ricorsivamente \texttt{dfs} sul figlio sinistro del nodo specificato nei parametri della funzione \texttt{dfs(Tree A)}: succede quindi che la funzione viene rieseguita dall'inizio, usando come riferimento il nodo $B$, che verrà stampato.
        \begin{itemize}[leftmargin=1em]
            \item \textit{Sequenza di stampa}: $A - B$
            \item \textit{Stack chiamate}: $A - B$
        \end{itemize}

        \item Analogamente, dopo aver stampato il nodo $B$, la funzione richiama ricorsivamente la \texttt{dfs} sul figlio sinistro del nodo specificato nei parametri della funzione \texttt{dfs(Tree B)}, rieseguendo la funzione con $C$ come riferimento.
        \begin{itemize}[leftmargin=1em]
            \item \textit{Sequenza di stampa}: $A - B - C$
            \item \textit{Stack chiamate}: $A - B - C$
        \end{itemize}

        \item A questo punto, viene chiamata \texttt{dfs(t.left())} sul nodo $C$, ma quest'ultimo è \texttt{NULL} poiché non presenta figli; la stessa cosa succede provando a chiamare \texttt{dfs(t.right())}.\\
        Quando entrambe le chiamate ai figli sinistro e destro terminano, significa che il nodo in questione ha completato la propria porzione di codice ricorsivo e può andare avanti: andare avanti significa che la chiamata \texttt{dfs(t.left())} eseguita per \texttt{dfs(Tree B)} è stata completata.
        \begin{itemize}[leftmargin=1em]
            \item \textit{Sequenza di stampa}: $A - B - C$
            \item \textit{Stack chiamate}: $A - B$
        \end{itemize}

        \item Il controllo torna al nodo $B$ che, dopo aver completato la chiamata per il figlio sinistro, eseguirà la chiamata per il figlio destro ($D$) tramite \texttt{dfs(t.right())}.
        \begin{itemize}[leftmargin=1em]
            \item \textit{Sequenza di stampa}: $A - B - C$
            \item \textit{Stack chiamate}: $A - B - D$
        \end{itemize}

        \item Con la chiamata ricorsva sul figlio destro di $B$, la funzione viene rieseguita con $D$ come riferimento \texttt{dfs(Tree D)}, e come prima operazione $D$ viene stampato.
        \begin{itemize}[leftmargin=1em]
            \item \textit{Sequenza di stampa}: $A - B - C - D$
            \item \textit{Stack chiamate}: $A - B - D$
        \end{itemize}

        \item Come nel caso del nodo $C$, anche $D$ non presenta ulteriori figli, dunque le sue chiamate falliranno (\texttt{NULL}) e di conseguenza $D$ completa la propria porzione di codice: il controllo torna nuovamente a $B$.
        \begin{itemize}[leftmargin=1em]
            \item \textit{Sequenza di stampa}: $A - B - C - D$
            \item \textit{Stack chiamate}: $A - B$
        \end{itemize}

        \item Nonostante il controllo sia tornato a $B$, esso ha completato le sue chiamate per i figli sinistro e destro, quindi ancora una volta il controllo passa al nodo superiore (in questo caso la radice $r$ ($A$)). 
        \begin{itemize}[leftmargin=1em]
            \item \textit{Sequenza di stampa}: $A - B - C - D$
            \item \textit{Stack chiamate}: $A$
        \end{itemize}

        \item Ciò che succede è che in $A$ la chiamata \texttt{dfs(t.left())} è stata completata (tutto il sottoalbero sinistro), quindi procedo con la chiama ricorsiva per il nodo destro della radice $E$: in questo modo \textbf{il procedimento si ripete in modo analogo} per tutto il sottoalbero destro.
        \begin{itemize}[leftmargin=1em]
            \item \textit{Sequenza di stampa}: $A - B - C - D - E - \dots$
            \item \textit{Stack chiamate}: $A - E - \dots$
        \end{itemize}
    \end{enumerate}

    \subsubsection{Visita in postorder (DFS)}
    \label{par:Visita in postorder (DFS)}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Funzionamento della visita in postorder
        ]
        La \textbf{visita in postorder} di $T$ consiste nell'effettuare, nell'ordine, la postvisita di $T_1, ..., T_k$ e poi nell'esaminare $r$.
    \end{tcolorbox}
    \begin{figure}[h]
        \centering
        \vspace{-18pt}  % Riduce lo spazio sopra
        \subfloat[albero attraversato in postorder]{%
            \includegraphics[width=0.43\textwidth]{figures/3_alberi/img8.png}%
        }
        \hspace{2cm}
        \subfloat[Pseudocodice visita in postorder]{%
            \includegraphics[width=0.35\textwidth]{figures/3_alberi/img9.png}%
        } 
        \vspace{-10pt}  % Riduce lo spazio sotto
    \end{figure}
    \noindent
    Per quanto riguarda la visita in postorder, anche in questo caso, dividiamo il procedimento in alcuni passi, monitorando l'evoluzione della sequenza di stampa e dello stack di chiamate:

    \vspace{8pt}
    \begin{enumerate}[leftmargin=1em]
        \item Si parte come sempre dal nodo radice $A \rightarrow$ \texttt{dfs(Tree A)}.  
        Tuttavia, in postorder la \textbf{radice non viene stampata subito}: la funzione procede prima a richiamare \texttt{dfs(t.left())}, dunque \texttt{dfs()} viene eseguita in modo ricorsivo rispetto al figlio sinistro ($B$).
        \begin{itemize}[leftmargin=1em]
            \item \textbf{Sequenza di stampa}: $-$
            \item \textbf{Stack chiamate}: $A$
        \end{itemize}

        \item Essendo nuovamente all'inizio della funzione, $B$ non viene stampato, ma ancora una volta viene richiamata \texttt{dfs(t.left())} in modo ricorsivo per il figlio sinistro di $B$ (Ovvero $C$)
        \begin{itemize}[leftmargin=1em]
            \item \textbf{Sequenza di stampa}: $-$
            \item \textbf{Stack chiamate}: $A - B$
        \end{itemize}

        \item Il figlio sinistro di $B$ è il nodo $C$, dunque verrà eseguita la funzione \texttt{dfs(Tree C)}.
        A questo punto la funzione riparte dall'inizio, ma $C$ non ha ulteriori figli, quindi \texttt{dfs(t.left())} e \texttt{dfs(t.right())} restituiscono \texttt{NULL} e si passa alla stampa del nodo ($C$).
        \begin{itemize}[leftmargin=1em]
            \item \textbf{Sequenza di stampa}: $C$
            \item \textbf{Stack chiamate}: $A - B - C$
        \end{itemize}

        \item Il nodo $C$, dopo la stampa, ha completato la propria porzione di codice, dunque il controllo ritorna al nodo $B$.
        \begin{itemize}[leftmargin=1em]
            \item \textbf{Sequenza di stampa}: $C$
            \item \textbf{Stack chiamate}: $A - B$
        \end{itemize}

        \item  Il nodo $B$, dopo aver completato la chiamata per il figlio sinistro, può procedere a richiamare la funzione ricorsiva per il figlio destro \texttt{dfs(t.right())}, ovvero il nodo $D$: ciò implica \texttt{dfs(Tree D)}.
        \begin{itemize}[leftmargin=1em]
            \item \textbf{Sequenza di stampa}: $C$
            \item \textbf{Stack chiamate}: $A - B - D$
        \end{itemize}

        \item Anche il nodo $D$ non presenta figli, dunque \texttt{dfs(t.left())} e \texttt{dfs(t.right())} restituiscono \texttt{NULL} e si passa alla stampa del nodo stesso, con conseguente terminazione della sua porzione di codice. Infine, il controllo ritorna al nodo $B$.
        \begin{itemize}[leftmargin=1em]
            \item \textbf{Sequenza di stampa}: $C - D$
            \item \textbf{Stack chiamate}: $A - B$
        \end{itemize}

        \item A questo punto, il nodo $B$ ha completato la visita dei propri figli sinistro ($C$) e destro ($D$). Di conseguenza si va oltre le chiamate \texttt{dfs(t.left())} e \texttt{dfs(t.right())} e si stampa $B$. Dopo la stampa di $B$, si ha la terminazione della sua porzione di codice ricorsivo, e il controllo ritorna al nodo $A$.
        \begin{itemize}[leftmargin=1em]
            \item \textbf{Sequenza di stampa}: $C - D - B$
            \item \textbf{Stack chiamate}: $A$
        \end{itemize}

        \item Terminata la visita del sottoalbero sinistro di $A$, la funzione procede ora con il figlio destro, eseguendo \texttt{dfs(t.right())} e quindi in modo ricorsivo la funzione \texttt{dfs(Tree E)}.
        \begin{itemize}[leftmargin=1em]
            \item \textbf{Sequenza di stampa}: $C - D - B$
            \item \textbf{Stack chiamate}: $A - E$
        \end{itemize}

        \item Dunque, una volta che \texttt{dfs(Tree E)} incomincia le sue chiamate ricorsive, viene \textbf{visitato tutto il sottoalbero destro}, con un \textbf{procedimento analogo} a quello utilizzato precedentemente per visitare il sottoalbero sinistro.
        \begin{itemize}[leftmargin=1em]
            \item \textbf{Sequenza di stampa}: $C - D - B - \dots$
            \item \textbf{Stack chiamate}: $A - E - \dots$
        \end{itemize}
    \end{enumerate}
    
    \subsubsection{Visita inorder (DFS)}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Funzionamento della visita inorder
        ]
        Fissato $i \geqslant 1$, la \textbf{visita inorder} di $T$ consiste nell'effettuare la invista di $T_1, ..., T_i$, nell'esaminare $r$, e poi nell'effettuare la invisita di $T_(i+1), ..., T_k$.
    \end{tcolorbox}
    \begin{figure}[h]
        \centering
        \vspace{-18pt}  % Riduce lo spazio sopra
        \subfloat[albero attraversato inorder]{%
            \includegraphics[width=0.44\textwidth]{figures/3_alberi/img10.png}%
        }
        \hspace{2cm}
        \subfloat[Pseudocodice visita inorder]{%
            \includegraphics[width=0.35\textwidth]{figures/3_alberi/img11.png}%
        } 
        \vspace{-10pt}  % Riduce lo spazio sotto
    \end{figure}
    \noindent
    Anche in questo caso analizziamo passo per passo il funzionamento della funzione \texttt{dfs()} e l'evoluzione della sequenza di stampa e dello stack di chiamate:

    \vspace{8pt}
    \begin{enumerate}[leftmargin=1em]
        \item La visita incomincia chiamando \texttt{dfs(Tree A)} sul nodo radice ($A$). Come per la visita in postorder, la radice non viene subito stampata, ma si procede a richiamare a richiamare ricorsivamente il suo figlio sinistro ($B$) tramite \texttt{dfs(t.left())}.
        \begin{itemize}[leftmargin=1em]
            \item \textbf{Sequenza di stampa}: $-$
            \item \textbf{Stack chiamate}: $A$
        \end{itemize}

        \item Quando la funzione \texttt{dfs(Tree B)} viene richiamata ricorsivamente sul nodo $B$, si riparte dall'inizio e nuovamente si chiama in modo ricorsivo il figlio sinistro di $B$ ($C$).
        \begin{itemize}[leftmargin=1em]
            \item \textbf{Sequenza di stampa}: $-$
            \item \textbf{Stack chiamate}: $A - B$
        \end{itemize}

        \item Una volta che \texttt{dfs(Tree C)} è stata chiamata, la chiamata ricorsiva al figlio sinistro di $C$, all'interno della funzione, restituisce \texttt{NULL} proprio perché il nodo $C$ non ha figli.\\
        Dunque si procede con l'operazione subito successiva, la stampa del nodo, per poi trovare un'altra chiamata ricorsiva al figlio destro di $C$ che restituià anch'essa \texttt{NULL} per lo stesso motivo di prima.
        \begin{itemize}[leftmargin=1em]
            \item \textbf{Sequenza di stampa}: $C$
            \item \textbf{Stack chiamate}: $A - B - C$
        \end{itemize}

        \item Arrivati a questo punto la porzione di codice eseguita da $C$ termina e il controllo torna al nodo $B$.
        \begin{itemize}[leftmargin=1em]
            \item \textbf{Sequenza di stampa}: $C$
            \item \textbf{Stack chiamate}: $A - B$
        \end{itemize}

        \item Quando il nodo $B$ termina la chiamata al figlio sinistro ($C$), l'operazione successiva è la stampa del nodo stesso. Subito dopo la stampa viene eseguita una chiamata ricorsiva al figlio destro (nodo $D$).
        \begin{itemize}[leftmargin=1em]
            \item \textbf{Sequenza di stampa}: $C - B$
            \item \textbf{Stack chiamate}: $A - B$
        \end{itemize}

        \newpage
        \item Non appena \texttt{dfs(Tree D)} è in esecuzione vengono eseguite le istruzioni secondo l'ordine prestabilito: \texttt{dfs(t.left())} restituisce \texttt{NULL} (nessun figlio sinistro), $D$ viene stampato e \texttt{dfs(t.right())}, non avendo figli, restituisce anch'esso \texttt{NULL}.
        \begin{itemize}[leftmargin=1em]
            \item \textbf{Sequenza di stampa}: $C - B - D$
            \item \textbf{Stack chiamate}: $A - B - D$
        \end{itemize}

        \item Dopo l'esecuzione di tutta la porzione di codice del nodo $D$, il controllo torna a $B$, ma anche quest'ultimo, avendo visitato figlio sinistro e destro, ha terminato le istruzioni nella sua porzione di codice. Quindi, in cascata, il controllo torna al nodo $A$, che, dopo aver visitato tutto il suo sottoalbero sinistro tramite la chiamata ricorsiva \texttt{dfs(t.left())} può essere stampato come prevede l'istruzione successiva della sua porzione di codice. 
        \begin{itemize}[leftmargin=1em]
            \item \textbf{Sequenza di stampa}: $C - B - D - A$
            \item \textbf{Stack chiamate}: $A$
        \end{itemize}

        \item Infine, dopo la stampa del nodo $A$, viene effettuata una chiamata al sottoalbero destro tramite \texttt{dfs(t.right())}. Anche in questo caso, \textbf{il procedimento di visita è analogo} a quello utilizzato precedentemente per il \textbf{sottoalbero sinistro}.
        \begin{itemize}[leftmargin=1em]
            \item \textbf{Sequenza di stampa}: $C - B - D - A - \dots$
            \item \textbf{Stack chiamate}: $A - \dots$
        \end{itemize}
    \end{enumerate}

    \subsubsection{Attraversamento di un albero binario in C}
    La funzione per l'attraversamento di un albero binario fa riferimento alla visita in preorder.
    \begin{lstlisting}[style=mystyle, language=C++, numbers=left]
void preorder(inttree *p, void(*op)(inttree*)){
    if(p){
        (*op)(p);
        preorder(p->left,op);
        preorder(p->right,op);
    }
}
    \end{lstlisting}

    \begin{itemize}[leftmargin=1em]
        \item \textbf{Tipo di ritorno}: la funzione non restituisce alcun valore, infatti il suo scopo è unicamente quello di visitare i nodi dell'albero;
        
        \item \textbf{Parametri}: la funzione \texttt{preorder} accetta due parametri;
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{11}\rule{0.6ex}{0.6ex}}]
            \item \texttt{inttree *p}: è un puntatore alla struttura del nodo di un albero, definita al capitolo \ref{par:Creazione di un albero binario}. Solitamente viene passato il puntatore alla radice del nodo dell'albero, \texttt{*root}, definito nel main, per poter iniziare la visita di tutto l'albero. Successivamente, tramite le chiamate ricorsive, il puntatore non farà più riferimento alla radice ma ai vari nodi figli;
            \item \texttt{void (*op) (inttree*)}: è un puntatore a funzione (\texttt{(*op)}), \textbf{cioè una funzione passata come argomento}, che accetta come parametro un puntatore alla struttura di un nodo dell'albero \texttt(\texttt{inttree*}) e non restituisce nulla (\texttt{void}).\\
            In questo modo, passando come argomento  a \texttt{preorder} il nome di una qualsiasi funzione che come argomento ha un puntatore alla struttura di un nodo dell'albero, è possibile eseguire un'operazione specifica all'interno della visita.
            
            \vspace{8pt}
            Ad esempio, può essere utilizzato per richiamare una funzione che si occupa della stampa dei nodi, 
            così da \textbf{tenere traccia della sequenza di attraversamento}.
            \begin{lstlisting}[style=mystyle, language=C++]
void stampaNodo(inttree *n) {
    printf("%d ", n->data);
}
            \end{lstlisting}
        \end{itemize}
        \item \textbf{Funzionamento del codice}: il corpo della funzione presenta un controllo condizionale e due chiamate ricorsive per l'esecuzione della visita dell'albero.
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{12}\rule{0.6ex}{0.6ex}}]
            \item \textit{riga 2}: viene effettuato un controllo di validità sul nodo che si sta visitando, assicurandosi che esista (cioè che non sia \texttt{NULL}). Questo controllo risulta utile nel momento in cui si raggiunge una foglia, i cui figli sinistro e destro non esistono, per fare in modo di cedere il controllo al nodo successivo;
            \item \textit{riga 3}: viene eseguita la funzione passata come parametro; \texttt{(*op)} rappresenta la funzione puntata da \texttt{op}, mentre \texttt{p} è l'argomento (il nodo attualmente visitato) che le viene passato;
            \item \textit{riga 4}: viene effettuata una chiamata ricorsiva a \texttt{preorder}, specificando come parametri il figlio sinistro (\texttt{p->left}) del nodo corrente e il puntatore alla funzione \texttt{op}.\\
            In questo modo, la visita procede ricorsivamente su tutti i figli sinistri dell'albero;
            \item \textit{riga 5}: allo stesso modo, quando il figlio sinistro di un determinato nodo è stato visitato, con \texttt{p->right} si passa alla visita ricorsiva del figlio destro dello stesso nodo.
        \end{itemize}
    \end{itemize}
    
    \vspace{8pt}
    \noindent
    \textbf{\textit{N.B}}: ovviamente per creare le altre tipologie di visite (postorder e inorder), è sufficiente invertire l'ordine  delle istruzioni all'interno della condizione \texttt{if} secondo la metodologia prevista dal tipo di attraversamento.

    \vspace{8pt}
    \noindent
    \textbf{\textit{Esempio di utilizzo}}
    \begin{lstlisting}[style=mystyle, language=C++, , escapeinside={(*@}{@*)}]
int main(int argc, char *argv[]) {
    inttree *root = NULL;
    root = malloc(sizeof(inttree));

    // Allocazione di tutti i nodi e assegnazione del valore per ognuno
    // come fatto al capitolo (*@\ref{par:Costruzione di un albero binario}@*).
    // ...
    // ...

    // Esecuzione della visita preorder
    printf("Attraversamento in preorder: ");
    preorder(root, stampaNodo);
    printf("\n");

    return 0;
}
    \end{lstlisting}

    \subsubsection{Cancellazione di un albero}
    Per poter effettuare la cancellazione di un albero, la seguente implementazione fa leva sull'utilizzo di una struttura ricorsiva, in modo da \textbf{liberare correttamente} tutta la memoria occupata da un albero binario.
    \begin{lstlisting}[style=mystyle, language=C++, numbers=left]
void destroytree (inttree *p) {
    if (p->left){ // Se esiste un sottoalbero sinistro 
        destroytree (p->left); // Libera il sottoalbero
    }

    if (p->right){ // Se esiste un sottoalbero destro
        destroytree (p->right); // Libera il sottoalbero
    }

    free (p); / Per finire libera la memoria della radice
}
    \end{lstlisting}
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Tipo di ritorno}: la funzione non restituisce alcun valore, infatti in suo scopo è unicamente quello di \textbf{rilasciare la memoria} precedentemente allocata per ciascun nodo dell'albero.
        
        \item \textbf{Parametri}: la funzione \texttt{destroytree} accetta un singolo parametro, ovvero \texttt{inttree *p}.\\
        Quest'ultimo è un puntatore alla struttura del nodo dell'albero, definita al capitolo \ref{par:Creazione di un albero binario}.\\
        A partire dal nodo specificato (in genere la radice \texttt{root}), la funzione visita ricorsivamente tutti i sottoalberi (sinistro e destro), liberando la memoria associata a ciscun ogni nodo.
 
        \item \textbf{Funzionamento del codice}: l'idea di base della funzione \texttt{destroy} è che \textit{"non posso liberare un nodo finché non ho liberato i figli, perché se liberassi il nodo prima, perderei il puntatore ai figli e non potrei più raggiungerli per deallocarli"}.
        
        \vspace{8pt}
        Dunque, la sequenza di cancellazione segue l'ordine di \textbf{visita postorder} discussa al capitolo \ref{par:Visita in postorder (DFS)}, quindi, considerando lo stesso albero,  $C-D-B-F-G-E-A$. In accordo con il funzionamento postorder, il codice presenta la \textbf{seguente logica}:
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{13}\rule{0.6ex}{0.6ex}}]
            \item \textit{righe 2-4}: viene effettuato un controllo sul figlio sinistro del nodo passato come parametro. Se esiste, la funzione \texttt{destroytree} viene richiamata ricorsivamente fino a raggiungere una foglia (nodo privo di figli), che restituirà un controllo falso.
            \item \textit{riga 6-8}: quando il controllo su \texttt{p->left} risulta falso, si passa al controllo su \texttt{p->right}. Anche in questo caso viene richiamata la funzione \texttt{destroytree} in modo ricorsivo fino a che non si arriva ad una foglia, che per definizione non presenta figli.
            \item \textit{riga 10}: quando entrambi i controlli risultano falsi, significa che il nodo corrente non ha più figli, quindi può essere deallocato in sicurezza tramite \texttt{free(p)}.\\
            Al termine della liberazione, la funzione termina e il controllo ritorna al nodo superiore che era in attesa della conclusione della chiamata ricorsiva nello \textbf{stack delle chiamate}.
        \end{itemize}
    \end{itemize}

    \vspace{8pt}
    \noindent
    \textbf{\textit{Esempio di utilizzo}}
    \begin{lstlisting}[style=mystyle, language=C++, , escapeinside={(*@}{@*)}]
int main(int argc, char *argv[]) {
    inttree *root = NULL;
    root = malloc(sizeof(inttree));

    // Allocazione di tutti i nodi e assegnazione del valore per ognuno
    // come fatto al capitolo (*@\ref{par:Costruzione di un albero binario}@*).
    // ...
    // ...

    // Ora, per liberare tutta la memoria occupata da questo albero, basta una sola chiamata
    destroytree(root);

    return 0;
}
    \end{lstlisting}

    \subsection{Alberi binari di ricerca (BST)}
    \label{par:Alberi binari di ricerca (BST)}
    Come detto precedentemente al capitolo \ref{par:I dizionari} un \textbf{dizionario} in informatica è una \textbf{struttura dati astratta} che memorizza coppie (\textit{chiave, valore}), quindi servono a memorizzare dati associativi come, ad esempio, una rubrica telefonica o una tabellla di simboli.\\
    I dizionari consentono \textbf{tre operazioni fondamentali:}
    \begin{itemize}[leftmargin=1em]
        \item \texttt{lookup(Item k)} $\rightarrow$ cercare un elemento con chiave \texttt{k};
        \item \texttt{insert(Item k, Item v)} $\rightarrow$ inserire un elemento con chiave \texttt{k} e valore \texttt{v};
        \item \texttt{remove(Item k)} $\rightarrow$ rimuovere l'elemento con chiave \texttt{k}.
    \end{itemize}

    \vspace{8pt}
    \noindent
    Un dizionario può essere implementato in vari modi:

    \vspace{2pt}
    \noindent
    \begin{minipage}[t]{0.700\textwidth}  
        \includegraphics[width=\linewidth]{figures/3_alberi/img12.png}
        *=Si assume che l'elemento sia già stato trovato, altrimenti $O(n)$
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{68pt}{  
        \begin{minipage}[t]{0.276\textwidth}
            Queste tipologie di implementazioni presentano diversi \textbf{limiti di efficienza}.
            Ad esempio, i \textbf{vettori ordinati} permettono una ricerca veloce ma inserimenti e rimozioni lente,
        \end{minipage} 
    } 

    \vspace{5pt}
    \noindent
    poichè dovrei spostare tutti gli elementi ($O(n)$). Nei \textbf{vettori non ordinati}, invece, la ricerca richiede di scorrere tutti gli elementi ($O(n)$), mentre l'inserimento e la rimozione sono operazioni facili e veloci ($O(1)$) che prevedono un quantitativo di operazioni fisso, purché si conosca già la posizione dell'elemento su cui operare, come un'inserimento in testa e una rimozione dalla coda. Se invece fosse necessario inserire o rimuovere in una posizione specifica, il costo salirebbe nuovamente a $O(n)$.\\
    Si conclude quindi che \textbf{utilizzare i vettori non è una buona idea}.
    \begin{tcolorbox}
        [
            colback=green!10,  % Sfondo verde chiaro
            colframe=green!60!black,  % Bordo verde più acceso
            coltitle=black,  % Colore del testo del titolo
            fonttitle=\bfseries,  % Testo del titolo in grassetto
            title={\centering \textbf{L'idea degli alberi binari di ricerca}},  % Titolo centrato 
            enhanced,  % Miglioramenti grafici
            attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
            boxed title style={colback=white, colframe=green!60!black, rounded corners},
            breakable
        ]
        Per risolvere il problema legato all'inefficienza dei vettori, vengono introdotti gli \textbf{alberi binari di ricerca} (BST - Binary Search Trees) proprio come una \textbf{struttura dati efficiente} per implementare i dizionari dinamici ordinati. 
    \end{tcolorbox}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cos'è un albero binario di ricerca?
        ]
        Un \textbf{albero binario di ricerca} è un modo per realizzare una \textbf{struttura dati} che mantiene \textbf{i dati in ordine}, proprio come farebbe un vettore ordinato, grazie alla sua costruzione secondo \textbf{una logica \textit{dicotomica}}. Inoltre, all'interno dell'albero \textbf{ogni nodo rappresenta una coppia} (\textit{chiave, valore}).
    \end{tcolorbox}
    \noindent
    La logica dicotomica implica che tra i nodi valgano \textbf{le seguenti proprietà}, che, per come sono definite, si applicano \textbf{in maniera ricorsiva}:
    \begin{itemize}[leftmargin=1em]
        \item Per ogni nodo $u$, tutte le chiavi contenute nel sottoalbero radicato nel figlio sinistro di $u$ sono minori della chiave contenuta in $u$;
        \item Per ogni nodo $u$, tutte le chiavi contenute nel sottoalbero radicato nel figlio destro di $u$ sono maggiori della chiave contenuta in $u$.
    \end{itemize}

    \vspace{8pt}
    \noindent
    \textbf{\textit{"Dicotomia"}} significa \textit{dividere in due}.
    In pratica, ogni volta che viene confrontata una chiave con quella del nodo corrente, si decide se "scendere a sinistra" o "scendere a destra", escludendo metà dell'albero.\\
    In questo modo tutte le operazioni di ricerca, inserimento e cancellazione sfruttano questa divisione \textbf{per ridurre progressivamente lo spazio di ricerca} (agevolare la ricerca).
    \begin{tcolorbox}
        [
            colback=green!10,  % Sfondo verde chiaro
            colframe=green!60!black,  % Bordo verde più acceso
            coltitle=black,  % Colore del testo del titolo
            fonttitle=\bfseries,  % Testo del titolo in grassetto
            title={\centering \textbf{\textit{Alcune precisazioni}}},  % Titolo centrato 
            enhanced,  % Miglioramenti grafici
            attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
            boxed title style={colback=white, colframe=green!60!black, rounded corners},
            breakable
        ]
        Le chiavi dei nodi sono \textbf{maggiori} o \textbf{minori} \textbf{strette}, perché l'idea generale è che si utilizza una struttura dati per un dizionario, quindi \textbf{non è possibile che per una chiave} nella struttura \textbf{siano associati più valori}, ad esempio, non posso avere due nodi così strutturati:
        \begin{itemize}[leftmargin=1em]
            \item \texttt{(10, Alberto)}
            \item \texttt{(10, Roberto)}
        \end{itemize}
        Però, nulla vieta che ad una chiave sia associato un insieme (dinamico o non), ad esempio, \texttt{(10, ["Alberto", "Roberto"])}
    \end{tcolorbox}
    \noindent
    \begin{minipage}[t]{0.315\textwidth}  
        \includegraphics[width=\linewidth]{figures/3_alberi/img13.png}
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{125pt}{  
        \begin{minipage}[t]{0.662\textwidth}
            Le operazioni previste dagli alberi binari di ricerca sono:
            \begin{itemize}[leftmargin=1em]
                \item \textbf{Ricerca} di un elemento nell'insieme;
                \item \textbf{Inserimento} di un elemento nell'insieme;
                \item Ricerca del \textbf{minimo} e del \textbf{massimo} dell'insieme;
                \item \textbf{Successore} e \textbf{predecessore} di un elemento nell'insieme;
                \item \textbf{Cancellazione} di un elemento dall'insieme.
            \end{itemize}
        \end{minipage} 
    }  

    \subsubsection{Implementazione della ricerca}
    \label{par:Implementazione della ricerca}
    Negli alberi binari di ricerca, la ricerca di un nodo può essere effettuata in modalità \textbf{ricorsiva} oppure in modalità \textbf{iterativa}.

    \vspace{8pt}
    \noindent
    \textbf{\textit{Ricerca ricorsiva}}
    \begin{lstlisting}[style=mystyle, language=C++, numbers=left]
// ricerca RICORSIVA della chiave x (chiave == data)
bstree *search(bstree *p, int x) {
    //se trovo x oppure ho finito la ricorsione allora ritorno p
    if(p==NULL || p->data==x) return p;

    // x > data...search the right subtree
    else if(x > p->data) return search(p->right, x);

    //x < data ... search the left subtree
    else return search(p->left, x);
}
    \end{lstlisting}

    \begin{itemize}[leftmargin=1em]
        \item \textbf{Tipo di ritorno}: la funzione restituisce un puntatore a un nodo della struttura \texttt{bstree}, la cui composizione è identica a quella di un albero binario vista al capitolo \ref{par:Creazione di un albero binario}.\\
        Il nodo restituito è: 
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{14}\rule{0.6ex}{0.6ex}}]
            \item Il \textbf{nodo trovato} se la chiave \texttt{x} è presente nell'albero;
            \item Oppure \texttt{NULL}, se la chiave non esiste, cioè \textbf{se la ricerca termina su un puntatore nullo}.
        \end{itemize}
        Dunque, il tipo di ritorno consente di sapere \textbf{dove si trova l'elemento}, oppure \textbf{che non esiste}. 

        \item \textbf{Parametri}: la funzione \texttt{bstree} accetta due parametri;
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{15}\rule{0.6ex}{0.6ex}}]
            \item \texttt{bstree *p}: è il puntatore al nodo corrente dell'albero binario di ricerca.\\
            In genere la prima chiamata della funzione riceve la radice dell'albero (\texttt{root}), ma nelle chiamate ricorsive il parametro \texttt{p} sarà aggiornato ai figli sinistro o destro.
            \item \texttt{int x}: rappresenta la chiave da cercare (in questo caso un intero). Si confronta con il campo data contenuto nel nodo corrente.
        \end{itemize}
 
        \item \textbf{Funzionamento del codice}: la funzione implementa una \textbf{ricerca dicotomica ricorsiva}.
        Nell'esempio riportato in Figure \ref{fig:figura35}, viene effettuata la \textbf{ricerca del valore $16$}.

        \vspace{-15pt}
        \begin{minipage}[t]{0.263\textwidth}  

            \vspace{-5pt}
            \begin{figure}[H]
                \addtocounter{figure}{11}
                \centering                
                \caption{Albero BST}
                \label{fig:figura35}
            \end{figure}

            \vspace{-19pt}
            \includegraphics[width=\linewidth]{figures/3_alberi/img14.png}
        \end{minipage}%
        \hspace{5pt} % Spazio tra immagine e testo
        \raisebox{-15pt}{  
            \begin{minipage}[t]{0.689\textwidth}
                \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{16}\rule{0.6ex}{0.6ex}}]
                    \item \textit{riga 4}: la prima istruzione della funzione è un \textbf{controllo di terminazione} per fare in modo che, al ripetere della funzione ricorsiva, si capisca se la chiave del nodo è quella cercata o meno; Se \texttt{p==NULL}, significa che abbiamo raggiunto un ramo vuoto, la chiave non esiste e la funzione restitiuisce \texttt{NULL}, mentre se \texttt{p->data==x} abbiamo trovato il nodo desiderato e si ritorna il puntatore al nodo stesso.
                    \item \textit{riga 7}: questa seconda istruzione implementa la ricerca ricorsiva nel sotto albero destro. Se la chiave cercata \texttt{x} \textbf{è maggiore della chiave del nodo corrente} (\texttt{p->data}), allora, secondo la proprietà del BST (capitolo \ref{par:Alberi binari di ricerca (BST)}), il \textbf{valore} può trovarsi solo nel \textbf{sottoalbero destro}.\\
                    Dunque, la funzione richiama se stessa (in modo ricorsivo), passando come parametri il figlio destro del nodo sul quale si 
                \end{itemize}
            \end{minipage} 
        }  

        \vspace{3pt}
        \begin{adjustwidth}{1em}{0pt}
            stava lavorando (\texttt{p->right}), e ancora una volta la chiave cercata (\texttt{x}). A questo punto la funzione ricomincia, e se il controllo di terminazione non si attiva, viene ricontrollato se \texttt{x} è maggiore o minore di \texttt{p->data}.
        \end{adjustwidth}
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{17}\rule{0.6ex}{0.6ex}}]
            \item \textit{riga 10}: anche in questo caso viene implementata la ricerca ricorsiva ma nel sottoalbero sinistro. È \textbf{importante notare} che non viene specificato \texttt{x<p->left} proprio perché come descritto al capitolo capitolo \ref{par:Alberi binari di ricerca (BST)} (\textit{"Alcune precisazioni"}), \textbf{non possono essere presenti nodi con lo stesso valore di chiave}, dunque è scontato che  sia l'unica altra opzione possibile.\\
            Quindi, se la chiave cercata \texttt{x} \textbf{è minore della chiave del nodo corrente} (\texttt{p->data}), allora, secondo la proprietà del BST, il \textbf{valore} può trovarsi solo nel \textbf{sottoalbero sinistro}.\\
            Anche in questo caso, viene richiamata ricorsivamente la funzione, con \texttt{p->left} come nuovo nodo di partenza, fino a che non si attiva il controllo di terminazione, o \texttt{x} è maggiore di \texttt{p->data}.
        \end{itemize}
    \end{itemize}

    \vspace{8pt}
    \noindent
    \textbf{\textit{Ricerca iterativa}}
    \begin{lstlisting}[style=mystyle, language=C++, numbers=left]
// ricerca ITERATIVA della chiave x (chiave == data)
bstree *itsearch(bstree *p, int x) {
    bstree *q = p;
    while (q && x!= q->data){
        if (x < q->data) q = q->left;
        else q = q->right;
    }
    return q;
}
    \end{lstlisting}
    Il \textbf{tipo di ritorno} e i \textbf{parametri}, sono uguali a quelli della ricerca in modalità ricorsiva, ciò che cambia è la \textbf{struttura interna della funzione}, che però produce lo stesso risultato.
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Funzionamento del codice}: in questo caso si effettua una \textbf{ricerca dicotomica}, ovvero ad ogni passo si elimina metà dell'albero possibile, usando però una modalità iterativa.
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{18}\rule{0.6ex}{0.6ex}}]
            \item \textit{riga 3}: viene creato un puntatore locale (\texttt{*q}) alla struttura \texttt{bstree}, il quale viene fatto puntare al parametro \texttt{p} che di solito rappresenta la radice (\texttt{root}). In questo modo partendo da \texttt{p}, \texttt{*q} verra usato per scorrere l'albero.
            \item \textit{riga 4}: il while continua finché il nodo esiste e la chiave non è stata trovata. L'\textbf{uscita dal while} rappresenta il \textbf{controllo di terminazione}: se \texttt{q} è \texttt{NULL} la chiave non esiste, altrimenti è stata trovata.
            \item \textit{riga 5-6}: viene definito il controllo condizionale per fare in modo di "scorrere" l'albero a destra se \texttt{x > q->data} o a sinistra se \texttt{x < q->data}.
            \item \textit{riga 8}: quando la condizione del \texttt{while} non viene più rispettata, la chiave del nodo viene restituita.
        \end{itemize}
    \end{itemize}

    \vspace{8pt}
    \noindent
    \textbf{\textit{Esempio di utilizzo (valido per entrambi i tipi di ricerca)}}\\
    Ipotizziamo di voler effettuare la ricerca del nodo $16$, come illustrato in Figure \ref{fig:figura35}.
    \begin{lstlisting}[style=mystyle, language=C++, , escapeinside={(*@}{@*)}]
int main(int argc, char *argv[]) {
    bstree *root = NULL;
    root = malloc(sizeof(bstree));

    // Allocazione di tutti i nodi e assegnazione di chiave-valore per
    // ognuno  di essi, secondo la logica dicotomica (*@(Figure \ref{fig:figura35})@*).
    // ...
    // ...

    bstree *res = search(root, 16); // Per la ricerca ricorsiva
    //bstree *res = itsearch(root, 16); // Per la ricerca iterativa

    if(res) printf("chiave trovata! valore = %d\n", res->data);
    else printf("chiave NON presente nell'albero\n");

    return 0;
}
    \end{lstlisting}

    \subsubsection{Creazione di un nuovo nodo}
    \label{par:Creazione di un nuovo nodo}
    \begin{lstlisting}[style=mystyle, language=C++, numbers=left]
// Funzione per creare un nodo
bstree *new_node(int x){
    bstree *p;
    p = malloc(sizeof(bstree));
    p->data = x;
    p->left = NULL;
    p->right = NULL;
    return p;
}
    \end{lstlisting}
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Tipo di ritorno}: la funzione restituisce un puntatore alla struttura del nodo appena creato.
        \item \textbf{Parametri}: la funzione \texttt{new\_node()} accetta come unico parametro un intero (\texttt{int x}), ovvero la chiave da salvare nel nodo.
        \item \textbf{Funzionamento del codice}: vengono definite le istruzioni per assegnare al nuovo nodo il valore della chiave e dei suoi figli sinistro e destro.
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{19}\rule{0.6ex}{0.6ex}}]
            \item \textit{riga 3-4}: viene dichiarato il puntatore \texttt{p} alla struttura \texttt{bstree}. Successivamente, tramite \texttt{malloc(sizeof(bstree))} viene allocata dinamicamente la memoria necessaria a contenere un nodo, e il puntatore \texttt{p} viene fatto puntare a questa nuova area di memoria.
            \item \textit{riga 5}: viene assegnato al campo \texttt{data} del nodo il valore \texttt{x}, fornito come parametro.
            \item \textit{riga 6-7}: i puntatori \texttt{left} e \texttt{right} vengono inizializzati a \texttt{NULL}. Ciò significa che, al momento della creazione, \textbf{il nodo non ha figli} ed è \textbf{una foglia}.
            \item \textit{riga 8}: la funzione restituisce il puntatore al nodo creato.
        \end{itemize}
    \end{itemize}

    \subsubsection{Inserimento di un nodo}
    \label{par:Inserimento di un nodo}
    Come per la ricerca dei nodi, anche l'\textbf{inserimento di un nodo} all'interno dell'albero può avvenire mediante due modalità: \textbf{ricorsiva} o \textbf{iterativa}.

    \vspace{8pt}
    \noindent
    \textbf{\textit{Inserimento ricorsivo}}
    \begin{lstlisting}[style=mystyle, language=C++, numbers=left]
// Funzione per inserire un nodo
bstree *insert(bstree *p, int x){
    //void tree
    if(p==NULL) return new_node(x); 

    //insert to right
    else if(x > p->data) p->right = insert(p->right, x); 

    //insert to left
    else p->left = insert(p->left, x); 

    return p;
}
    \end{lstlisting}
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Tipo di ritorno}: la funzione restituisce un puntatore a \texttt{bstree}.\\ Il valore restituito rappresenta la radice del sottoalbero risultante dopo l'inserimento;
        \item \textbf{Parametri}: la funzione accetta due parametri;
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{20}\rule{0.6ex}{0.6ex}}]
            \item \texttt{bstree *p}: è il puntatore al nodo corrente dell'albero binario di ricerca.\\
            In genere la prima chiamata della funzione riceve la radice dell'albero (\texttt{root}), ma nelle chiamate ricorsive il parametro \texttt{p} sarà aggiornato ai figli sinistro o destro.
            \item \texttt{int x}: è la chiave da inserire nel campo \texttt{data} del nuovo nodo.
        \end{itemize}
        \item \textbf{Funzionamento del codice}: la struttura del codice è simile a quella che viene utilizzata per effettuare la ricerca di un nodo (capitolo \ref{par:Implementazione della ricerca}). Come avviene per la ricerca di un nodo, anche l'\textbf{inserimento sfrutta la logica dicotomica} utilizzata per la creazione dell'albero binario in modo tale che \textbf{in base al valore della chiave del nodo che si vuole inserire}, venga \textit{"esclusa"} una metà dell'albero ad ogni ricorsione o iterazione (in questo caso ad ogni ricorsione).\\
        Nell'esempio riportato in Figure \ref{fig:figura36} viene effettuato l'inserimento del valore $11$.\\
        \begin{minipage}[t]{0.263\textwidth}  

            \vspace{-23pt}
            \begin{figure}[H]
                \centering                
                \caption{Albero BST}
                \label{fig:figura36}
            \end{figure}

            \vspace{-19pt}
            \includegraphics[width=\linewidth]{figures/3_alberi/img15.png}
        \end{minipage}%
        \hspace{5pt} % Spazio tra immagine e testo
        \raisebox{0pt}{  
            \begin{minipage}[t]{0.689\textwidth}
                \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{21}\rule{0.6ex}{0.6ex}}]
                    \item \textit{riga 3}: se il primo controllo condizionale è verificato (\texttt{p=NULL}), significa che siamo arrivati alla posizione corretta dove deve essere inserito il nuovo nodo. Una volta trovata la posizione corretta, viene creato e restituito un nuovo nodo tramite la funzione \texttt{new\_node(x)} vista al capitolo \ref{par:Creazione di un nuovo nodo}.
                    \item \textit{riga 7}: in questo secondo controllo condizionale viene controllato se la chiave \texttt{x} da inserire sia maggiore della chiave del nodo corrente (\texttt{x > p->data}). In caso affermativo viene richiamata la funzione in modo ricorsivo sul figlio destro del nodo corrente (\texttt{p->right}), come specificato dalle proprietà dei BST.
                    \item \textit{riga 9}: il terzo controllo condizionale viene eseguito nel caso in cui il nodo corrente \textbf{non sia nullo} (\texttt{p!=NULL}) e \texttt{x} \textbf{non sia maggiore} di \texttt{p->data}. Ciò vuol dire che \texttt{x < p->data} e dunque, 
                \end{itemize}
            \end{minipage} 
        }  
        
        \vspace{4pt}
        \begin{adjustwidth}{1em}{0pt}
            secondo le proprietà dei BST, la funzione viene richiamata in modo ricorsivo sul figlio sinistro del nodo corrente (\texttt{p->left}).
        \end{adjustwidth}
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{22}\rule{0.6ex}{0.6ex}}]
            \item \textit{riga 11}: la funzione ritorna sempre \texttt{p}, cioè la radice del sottoalbero risultante, o per meglio dire, il padre del figlio appena creato.
        \end{itemize}
    \end{itemize}

    \vspace{8pt}
    \noindent
    \textbf{\textit{Inserimento iterativo}}
    \begin{lstlisting}[style=mystyle, language=C++, numbers=left]
bstree *itinsert(bstree *p, int x){
    bstree *y = NULL, *q = p;
    while(q){ //scendo fino ad una foglia
        y = q;
        if (q->data > x) q = q->left;
        else q = q->right;
    }
    if(y==NULL) return new_node(x); // se albero vuoto
    else if(y->data > x)  y->left=new_node(x); // inserisco sx
    else y->right=new_node(x); // inserisco dx
    
    return p;
}
    \end{lstlisting}
    Il \textbf{tipo di ritorno} e i \textbf{parametri}, sono uguali a quelli dell'inserimento in modalità ricorsiva, ciò che cambia è la \textbf{struttura interna della funzione}, che però produce lo stesso risultato.
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Funzionamento del codice}: il procedimento sfrutta la stessa logica dicotomica vista nella versione ricorsiva, ma la navigazione avviene mediante un ciclo \texttt{while}. La visita scende nell'albero \textit{"scorrendo"} ogni volta il puntatore verso il figlio sinistro o destro, finché non si arriva alla posizione corretta per inserire il nuovo nodo.
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{23}\rule{0.6ex}{0.6ex}}]
            \item \textit{riga 2}: vengono dichiarati due puntatori alla struttura \texttt{bstree}.
            \begin{itemize}[leftmargin=1.4em]
                \item [$\rightarrow$] \texttt{*q}: viene fatto puntare a \texttt{p}, che nella fase iniziale rappresenta il nodo radice (\texttt{root});
                \item [$\rightarrow$] \texttt{*y}: viene fatto puntare a \texttt{NULL}. Il motivo è che in seguito, \texttt{y} e \texttt{q} verranno fatti scorrere assieme, in questo modo \texttt{y} partendo \textit{"in ritardo"} memorizzerà sempre il nodo precedente a \texttt{q}. Da questo punto di vista si può dire che \texttt{y} sia sempre il padre di \texttt{q}. 
            \end{itemize}
            \item \textit{riga 3}: subito dopo viene utilizzato un ciclo \texttt{while} per controllare che il nodo corrente \texttt{q} non sia \texttt{NULL}. In questo modo si ha la sicurezza che il nodo corrente non sia una foglia ed è possibile definire le successive istruzioni per poter scorrere l'albero in base alla chiave che si vuole ricercare.
            \item \textit{riga 4-6}: alla prima iterazione, il nodo \texttt{y} che puntava a \texttt{NULL} prende il nodo \texttt{q}; In questo modo, in base al valore di \texttt{x} (controllo condizionale), \texttt{q} viene fatto scorrere verso il figlio destro o sinistro e \texttt{y} memorizzerà il nodo che è considerato il padre di questi ultimi.
        \end{itemize}
        
        \vspace{8pt}
        Quando si esce dal ciclo \texttt{while} significa che \texttt{q}, andando a destra o a sinistra è arrivato ad un nodo \texttt{NULL}, quindi oltre una foglia.
        A questo punto viene eseguito uno dei controlli condizionali:
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{24}\rule{0.6ex}{0.6ex}}]
            \item \textit{riga 8}: in questo controllo condizionale si gestisce il caso in cui \texttt{y} sia rimasto a \texttt{NULL}. Quando succede ciò, significa che anche \texttt{q} era a \texttt{NULL} e dunque l'albero era vuoto: viene quindi richiamata la funzione \texttt{new\_node(x)} per creare ed inserire il primo nodo dell'albero.
            \item \textit{riga 9-10}: in questi ultimi due controlli condizionali viene deciso se creare un figlio sinistro o un figlio destro. Si è detto che il puntatore \texttt{y} rappresenta il padre di \texttt{q}, in altre parole sarà l'ultimo nodo valido (foglia) alla terminazione del  ciclo \texttt{while}.\\
            Dunque, per capire se il nuovo nodo debba essere un figlio destro si controlla che  \texttt{x > y->data}, mentre per capire se debba essere un figlio sinistro si controlla che \texttt{x < y->data}. 
            \item \textit{riga 12}: viene restituita la radice originale dell'albero.
        \end{itemize}
    \end{itemize}

    \vspace{8pt}
    \noindent
    \textbf{\textit{Esempio di utilizzo (valido per entrambi i tipi di inserimento)}}\\
    Ipotizziamo di voler effettuare l'inserimento del nodo $11$, come illustrato in Figure \ref{fig:figura36}.
    \begin{lstlisting}[style=mystyle, language=C++, , escapeinside={(*@}{@*)}]
int main(int argc, char *argv[]) {
    bstree *root = NULL;
    /* N.B: In questo caso la malloc non serve perche' viene effettuata
    dalla funzione di inserimento quando necessario tramite la funzione
    "new_node()" (quindi solitamente al primo passaggio). */

    // Inserimento ricorsivo dei valori 
    root = insert(root, 8);
    root = insert(root, 5);
    // ...
    // ...
    root = insert(root, 11);  

    // Per l'inserimento iterativo basterebbe sostituire:
    // root = itinsert(root, 11);
    return 0;
}
    \end{lstlisting}

    \subsubsection{Ricerca del massimo e del minimo}
    \label{par:Ricerca del massimo e del minimo}
    Ancora una volta la logica dicotomica con la quale vengono creati gli alberi binari torna utile per la ricerca del nodo dell'albero con valore di chiave massimo o minimo.\\
    Partendo dalla radice, per trovare il \textbf{nodo minimo} va ispezionato sempre il \textbf{lato sinistro dell'albero binario}, mentre per trovare il \textbf{nodo massimo} va ispezionato \textbf{lato destro} dell'albero.\\
    \begin{minipage}[t]{0.300\textwidth}  
        \includegraphics[width=\linewidth]{figures/3_alberi/img16.png}
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{215pt}{  
        \begin{minipage}[t]{0.677\textwidth}
            \textbf{\textit{Esempio pratico}}
            \begin{itemize}[leftmargin=1em]
                \item \textit{Nodo minimo}: Per trovare il \textbf{nodo con valore di chiave minimo} all'interno dell'albero binario, si effettua una ricerca sempre verso sinistra. Il nodo minimo è quello il cui figlio sinistro è \texttt{NULL} (nel caso dell'immagine il nodo $5$);
                \item \textit{Nodo massimo}: Per trovare il \textbf{nodo con valore di chiave massimo} all'interno dell'albero binario, si effettua una ricerca sempre verso destra. Il nodo minimo è quello il cui figlio destro è \texttt{NULL} (nel caso dell'immagine il nodo $18$);
            \end{itemize}

            \vspace{8pt}
            Lo stesso discorso vale per trovare il \textbf{massimo o il minimo di un sottoalbero} radicato a partire da un nodo specifico dell'albero: ad esempio, il massimo del sottoalbero radicato nel nodo con valore di chiave $17$ è  la radice stessa poiché il suo figlio destro è \texttt{NULL}.
        \end{minipage} 
    } 
    Anche la ricerca del massimo e del minimo possono essere effettuate in modalità \textbf{ricorsiva} o in modalità \textbf{iterativa}. Il \textbf{costo} di entrambe le operazioni di ricerca \textbf{è proporzionale all'altezza dell'albero}.

    \vspace{8pt}
    \noindent
    \textbf{\textit{Ricerca ricorsiva del massimo e del minimo}}
    \begin{lstlisting}[style=mystyle, language=C++, numbers=left]
// Function to find the maximun value
bstree *find_maximum(bstree *p) {
    if(p == NULL) return NULL;
    else if(p->right != NULL) return find_maximum(p->right);
    return p;
}

// Function to find the minimum value
bstree *find_minimum(bstree *p) {
    if(p == NULL) return NULL;
    else if(p->left != NULL) return find_minimum(p->left);
    return p;
}
    \end{lstlisting}
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Tipo di ritorno}: la funzioni restituiscono un puntatore a \texttt{bstree}. Se l'albero non è vuoto, il valore restituito sarà il nodo che contiene la chiave massima o minima del BST;
        \item \textbf{Parametri}: entrambe le funzioni accettano un solo parametro, ovvero un puntatore alla struttura di un nodo \texttt{bstree *p}. In base alla logica della funzione, \texttt{p} è il puntatore al nodo dal quale si vuole iniziare la ricerca del massimo o del minimo.\\
        Solitamente si utilizza \texttt{root} se si vuole esaminare l'intero albero, ma è possibile passare anche il puntatore alla radice di un sottoalbero.
        \item \textbf{Funzionamento del codice}: come detto precedentemente, la logica dietro la ricerca del valore massimo e del valore minimo è abbastanza semplice.
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{25}\rule{0.6ex}{0.6ex}}]
            \item \textit{riga 3/10}: se il puntatore passato come parametro è nullo (\texttt{p==NULL}), significa che l'albero è vuoto e non è possibile determinare alcun valore massimo o minimo;
            \item \textit{riga 4/11}: per implementare ciò che è stato detto precedentemente viene effettuato un controllo condizionale che differisce in base al tipo di funzione:
            
            \newpage
            \begin{itemize}[leftmargin=1.4em]
                \item [$\rightarrow$] nel caso della ricerca del massimo si verifica se il \textbf{figlio destro} del nodo corrente non è nullo;
                \item [$\rightarrow$] nel caso della ricerca del minimo si verifica se il \textbf{figlio sinistro} del nodo corrente non è nullo.
            \end{itemize}
            Nel caso in cui il \textbf{controllo condizionale sia vero}, la funzione viene richiamata in modo ricorsivo specificando il figlio verso il quale ci si vuole spostare (\texttt{p->right} per il massimo e \texttt{p->left} per il minimo), in modo tale che la funzione ricominci con la posizione successiva da analizzare.
            
            \item \textit{riga 5/12}: se invece i controlli condizionali risultassero falsi, significherebbe che il massimo/minimo è stato trovato perché il figlio destro/sinistro non esiste (\texttt{p->right==NULL o p->left==NULL}), uscendo così dalla ricorsione.\\
            A questo punto viene restituito \texttt{p}, ovvero l'ultimo nodo valido visitato, il quale rappresenterà il valore massimo/minimo dell'albero.
        \end{itemize}
    \end{itemize}

    \vspace{8pt}
    \noindent
    \textbf{\textit{Ricerca iterativa del massimo e del minimo}}
    \begin{lstlisting}[style=mystyle, language=C++, numbers=left]
bstree *itfind_minimum(bstree *p) {
    if(p == NULL) return NULL;
    while (p->left != NULL) p = p->left;
    return p;
}

bstree *itfind_maximum(bstree *p) {
    if(p == NULL) return NULL;
    while (p->right != NULL) p = p->right;
    return p;
}
    \end{lstlisting}
    Il \textbf{tipo di ritorno} e i \textbf{parametri}, sono uguali a quelli che vengono utilizzati con la modalità ricorsiva, cio che cambia è la struttura interna della funzione che però produce lo stesso risultato.\\
    Utilizzando un'altra modalità di esecuzione, il \textbf{funzionamento del codice} per forza di cose cambia, ma la funzione rimane comunque \textbf{molto semplice} e la maggior parte delle istruzioni rimangono invariate.
    I controlli condizionali che nella modalità ricorsiva vengono utilizzati per capire quando richiamare ricorsivamente la funzione, in questo caso vengono utilizzati come guardia nel ciclo \texttt{while} per fare in modo di "scorrere" l'albero a destra o a sinistra in base al valore che si vuole trovare (massimo o minimo).

    \vspace{8pt}
    \noindent
    \textbf{\textit{Esempio di utilizzo (valido per entrambe le modalità)}}
    \begin{lstlisting}[style=mystyle, language=C++, numbers=left]
int main(int argc, char *argv[]) {
    bstree *root = NULL;
    /* Creazione di un albero BST in logica dicotomica utilizzando la
    funzione di inserimento, come fatto al capitolo (*@(\ref{par:Inserimento di un nodo})@*) */
    // ... 
    // ... 

    // Ricerca ricorsiva del massimo e del minimo
    bstree *min_node = find_minimum(root);
    bstree *max_node = find_maximum(root);

    // Ricerca iterativa del massimo e del minimo
    // bstree *min_node = itfind_minimum(root);
    // bstree *max_node = itfind_maximum(root);

    printf("Minimo trovato = %d\n", min_node->data);
    printf("Massimo trovato = %d\n", max_node->data);

    return 0;
}
    \end{lstlisting}

    \subsubsection{Ricerca del successore-predecessore}
    \label{par:Ricerca del successore-predecessore}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Definizione di successore
        ]
        Il \textbf{successore} di un nodo \textit{u} è il più piccolo nodo maggiore di \textit{u}.\\
        Allo stesso modo, possiamo dire che il \textbf{predecessore} di un nodo \textit{u} è il più grande nodo minore di \textit{u}.
    \end{tcolorbox}
    \noindent
    \begin{minipage}[t]{0.300\textwidth}  

        \vspace{-24pt}
        \begin{figure}[H]
            \centering               
            \addtocounter{figure}{1} 
            \caption{Albero BST}
            \label{fig:figura38}
        \end{figure}

        \vspace{-20pt}
        \includegraphics[width=\linewidth]{figures/3_alberi/img17.png}
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{0pt}{  
        \begin{minipage}[t]{0.677\textwidth}
            Per trovare il successore di \textit{u}, sono dati {due casi}:
            \begin{itemize}[leftmargin=1em]
                \item \textit{Caso 1}: Se il nodo \textit{u} \textbf{ha un figlio destro}, il successore \textit{v} è il minimo nodo del sottoalbero destro;
                Dunque in questo caso la situazione è molto semplice perché basta utilizzare la funzione vista al capitolo \ref{par:Ricerca del massimo e del minimo} per la ricerca del minimo.\\
                Trovando il nodo più piccolo, una \textbf{caratteristica determinante} di questo caso è che il successore non ha figlio sinistro.
                \item \textit{Caso 2}: Se il nodo \textit{u} \textbf{non ha un figlio destro}, il successore è il \textbf{primo antenato} (\textit{v}) di \textit{u}, per cui \textit{u} sta nel sottoalbero sinistro dell'antenato \textit{v}.\\
                Ad esempio, ipotizziamo di voler cercare il successore del nodo $6$ come illustrato in Figure \ref{fig:figura38}. Per prima cosa si controlla il sottoalbero radicato in $5$, e ci si chiede \textit{"u (}$6$\textit{) sta nel sottoalbero sinistro di v (}$5$\textit{)?"} In questo caso no, infatti $5$ non è
            \end{itemize}
        \end{minipage} 
    } 

    \vspace{5pt}
    \noindent
    il successore. Subito dopo, continuando a salire, si arriva al sottoalbero radicato in $8$: \textit{"u (}$6$\textit{) sta nel sottoalbero sinistro di v (}$8$\textit{)?"} In questo caso la risposta è si, dunque $8$ è il successore. Ciò è dato anche dal fatto che trovandosi nell'albero sinistro, il primo antenato \textit{v} che incontro, \textbf{per le proprietà dei BST}, sarà sicuramente più grande del nodo \textit{u}: in questo caso andrà effettuato \textbf{un controllo tra le chiavi dei nodi}.

    \vspace{8pt}
    \noindent
    Dunque, la struttura di un albero binario di ricerca consente di determinare il successore di un nodo \textbf{senza mai effettuare il confronto tra le chiavi} (quando il successore viene trovato con il \textit{caso 1}) come invece avviene per la ricerca del massimo o del minimo.

    \vspace{8pt}
    \noindent
    \textbf{\textit{Ricerca iterativa del successore}}
    \begin{lstlisting}[style=mystyle, language=C++, numbers=left]
/* Definisco la funzione che ricerca il nodo antenato per gestire il 
caso 2 */
bstree* ancestor(bstree *p, bstree *px){
    int x = px->data;
    bstree *y = NULL; //l'antenato
    bstree *q = p;
    while (q && x != q->data){
        y = q;
        if (x < q->data) q = q->left;
        else q = q->right;
    }
    return y;
}
    \end{lstlisting}
    \begin{lstlisting}[style=mystyle, language=C++, numbers=left]
// Funzione principale per la ricerca del successore
bstree* successor(bstree *p, bstree *px){
    if(px->right) return find_minimum(px->right); //Caso 1
    bstree *y = ancestor(p, px); // Caso 2 (discesa)
    while (px && y && px == y->right){ //Caso 2 (risalita)
        px = y;
        y = ancestor(p, px);
    }
    return y;
}
    \end{lstlisting}
    Per seguire un filo logico durante il discorso, analizziamo per prima la funzione \texttt{successor}.
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Tipo di ritorno}: la funzione restituisce un puntatore (\texttt{y}) al nodo del successore cercato;
        \item \textbf{Parametri}: la funzione accetta in ingresso due parametri;
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{26}\rule{0.6ex}{0.6ex}}]
            \item \texttt{bstree *p}: un puntatore alla struttura di un nodo generico che viene utilizzato per passare il puntatore alla radice dell'intero albero;
            \item \texttt{bstree *px}: anche \texttt{px} è un puntatore alla struttura di un nodo generico, ma viene utilizzato per passare il puntatore al nodo dell'albero del quale si vuole cercare il successore;
        \end{itemize}
        \item \textbf{Funzionamento del codice}: come detto precedentemente, quando ci si occupa della ricerca del successore, bisogna gestire due casi;
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{27}\rule{0.6ex}{0.6ex}}]
            \item \textit{riga 3}: in questa riga viene gestito il caso più semplice (caso 1).\\
            Viene effettuato un controllo condizionale sull'esistenza del figlio destro sul nodo del quale ci interessa trovare il successore (\texttt{px->right}). Se il controllo risulta vero, significa che il nodo \texttt{px} avrà un sottoalbero che, per le caratteristiche dei BST, conterrà solo nodi con un valore di chiave maggiore al suo.\\
            A questo punto, per trovare il successore di \texttt{px} basta utilizzare \texttt{find\_minimum} o \texttt{itfind\_mi\-nimum} sul figlio destro di \texttt{px} per trovare il nodo minimo dell'intero sottoalbero;

            \item \textit{riga 4}: da questo punto in poi viene gestito il caso in cui il nodo di cui si vuole conoscere il successore \textbf{non abbia un figlio destro} (caso 2). 
            
            \vspace{8pt}
            \textbf{Funzionamento di \texttt{ancestor}}: come detto precedentemente, bisogna risalire lungo l'albero, partendo dal nodo di cui vogliamo conoscere il successore. Poiché i nodi non hanno un puntatore al padre, per trovare il primo nodo “sopra” \texttt{px} dobbiamo necessariamente scendere partendo dalla radice. La funzione \texttt{ancestor} si occupa proprio di trovare il nodo che sta immediatamente sopra \texttt{px} lungo il cammino dalla radice. Il \textbf{tipo di ritorno} e i \textbf{parametri} sono quindi gli stessi della funzione \texttt{successor}.
            \begin{itemize}[leftmargin=1.4em]
                \item [$\rightarrow$] \textit{riga 4}: il valore della chiave del nodo \texttt{px} viene salvato nella variabile \texttt{x};
                \item [$\rightarrow$] \textit{riga 5}: viene dichiarato un puntatore \texttt{y} e inizializzato a \texttt{NULL}: questo punterà di volta in volta al nodo più recente incontrato nel cammino;
                \item [$\rightarrow$] \textit{riga 6}: viene creato un puntatore \texttt{q} e gli viene assegnata la radice \texttt{p}, per poter scorrere tutto l'albero partendo dall'alto;
                \item [$\rightarrow$] \textit{riga 7}: Per poter effettuare lo scorrimento si utilizza un ciclo \texttt{while} la cui condizione è quella di continuare la sua iterazione fino a che il nodo \texttt{q} è valido e fino a che le chiavi del nodo \texttt{px} e del nodo \texttt{q} non coincidono. 
                \item [$\rightarrow$] \textit{riga 8}: ad ogni iterazione il nodo puntato da \texttt{q} viene salvato in \texttt{y}. In questo modo, \textbf{quando finalmente arriva a \texttt{px}}, il nodo \texttt{y} sarà già impostato al nodo che lo precede lungo il cammino;
                \item [$\rightarrow$] \textit{riga 9-10}: infine, in queste righe vengono gestiti i controlli condizionali per quanto riguarda lo spostamento all'interno dell'albero e, come sempre fatto per la logica costruttiva degli alberi BST, ci si sposta sul figlio destro se la chiave cercata (x) del nodo \texttt{px} è più grande della chiave del nodo attuale \texttt{q}, altrimenti ci si sposta sul nodo sinistro. 
                \item [$\rightarrow$] \textit{riga 12}: quando la condizione nel ciclo \texttt{while} non è più rispettata si restituice \texttt{y}.  
            \end{itemize}
            Alla fine della funzione \texttt{ancestor()}, \textbf{\texttt{y} contiene il nodo padre (inteso come nodo immediatamente sopra) del nodo \texttt{px} lungo il cammino dalla radice.}

            \item \textit{riga 5}: da qui in poi, nel codice del successore, viene eseguito un ulteriore \texttt{while} per verificare se il nodo antenato trovato con \texttt{ancestor} sia realmente il \textbf{successore} di \texttt{px}, oppure se sia necessario risalire ulteriormente.\\
            \textbf{\textit{Perché risalire?}} Perché se \texttt{px} è figlio destro di \texttt{y}, \texttt{y} non può essere il suo successore (per le proprietà dei BST).

            \item \textit{riga 6-7}: a questo punto del codice, una volta entrati nel \texttt{while} di risalita, abbiamo appurato che il nodo "appena sopra" il nodo \texttt{px} (ovvero (\texttt{y})) non è il suo successore. Ciò vuol dire che non serve più memorizzare il nodo \texttt{px} originale, ma bisogna \textbf{risalire per trovare il primo nodo che è abbia un figlio sinistro}: il nodo trovato sarà di sicuro il successore del nodo \texttt{px} originale poiché avendo un figlio sinistro avrà un valore di chiave maggiore.
            Per fare ciò all'interno del \texttt{while}, \texttt{y} diventa il nuovo nodo originale "fittizzio" e vine richiamata su di esso la funzione \texttt{ancestor()};

            \item \textit{riga 9}: quando la guardia del \texttt{while} non è più rispettata siamo sicuri di aver trovato il successore del nodo originale restituendo \texttt{y} che contiene il risultato di \texttt{ancestors()}.
        \end{itemize}
    \end{itemize}

    \vspace{8pt}
    \noindent
    \textbf{\textit{Esempio di utilizzo}}\\
    Ipotizziamo di voler effettuare la ricerca del successore del nodo $17$ come in Figure \ref{fig:figura38}.
    \begin{lstlisting}[style=mystyle, language=C++]
int main(int argc, char *argv[]) {
    bstree *root = NULL;
    /* Creazione dell'albero BST in logica dicotomica illustrato in  
    (*@Figure \ref{fig:figura38}@*) utilizzando la funzione di inserimento, come fatto al
    capitolo (*@(\ref{par:Inserimento di un nodo})@*) */
    // ... 
    // ... 

    bstree *px = itsearch(root, 17); // Scelgo un nodo
    bstree *succ = successor(root, px); // Individuo il suo successore
    printf("Il successore del nodo %d e' %d\n", px->data, succ->data);
}
    \end{lstlisting}
    \begin{tcolorbox}
        [
            colback=green!10,  % Sfondo verde chiaro
            colframe=green!60!black,  % Bordo verde più acceso
            coltitle=black,  % Colore del testo del titolo
            fonttitle=\bfseries,  % Testo del titolo in grassetto
            title={\centering \textbf{\textit{Passaggio da successore a predecessore}}},  % Titolo centrato 
            enhanced,  % Miglioramenti grafici
            attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
            boxed title style={colback=white, colframe=green!60!black, rounded corners},
            breakable
        ]
        Il discorso intrapreso per quando riguarda la ricerca del successore ovviamente vale anche per la ricerca del \textbf{predecessore} di un determinato nod all'interno dell albero. 
        \begin{itemize}[leftmargin=1em]
            \item Il ragionamento con il \textit{caso 1} e il \textit{caso 2} vengono effettuati tenendo in considerazione il \textbf{figlio sinistro} e \textbf{non} il figlio destro;
            \item Nello specifico, per il \textit{caso 1} al posto della funzione \texttt{find\_minimum()} si utilizzerà \textbf{\texttt{find\_maximum()}}.
        \end{itemize}
    \end{tcolorbox}

    \subsubsection{Cancellazione di un nodo}
    Tramite la cancellazione di un nodo viene \textbf{rimossa la chiave $k$ dall'albero $T$}.\\
    Durante la cancellazione di un determinato nodo possono sorgere \textbf{tre differenti casi}:
    \begin{itemize}[leftmargin=1em]
        \item \textit{Caso 1} - \textbf{\textit{Il nodo $u$ da eliminare non ha figli}}: in questo caso $u$ è una foglia e viene semplicemente rimossa. \textbf{Eliminare le foglie non cambia l'ordine dei nodi rimanenti};
        \item \textit{Caso 2} - \textbf{\textit{Il nodo $u$ da eliminare ha un solo figlio $f$} (destro o sinistro)}: in questo caso si elimina il nodo $u$ rendendo $f$ figlio del padre di $u$.\\ Come si può notare nell'esempio \textit{(b)}, nonostante il nodo con valore di chiave $18$ sia la radice di un sottoalbero, quest'ultimo può essere collegato senza alcun tipo di problema al nodo con valore di chiave $8$. Infatti, $18$ era il figlio destro del nodo $8$, dunque tutti i nodi sotto di esso saranno comunque maggiori di $8$, \textbf{rispettando così le proprietà degli alberi BST}.
    \end{itemize}
    \begin{figure}[h]
        \centering
        \vspace{-12pt}  % Riduce lo spazio sopra
        \subfloat[\textit{Caso 1 - nessun figlio}]{%
            \includegraphics[width=0.46\textwidth]{figures/3_alberi/img18.png}%
        }
        \hspace{1cm}
        \subfloat[\textit{Caso 2 - un solo figlio}]{%
            \includegraphics[width=0.465\textwidth]{figures/3_alberi/img19.png}%
        } 
        \vspace{-10pt}  % Riduce lo spazio sotto
    \end{figure}

    \begin{itemize}[leftmargin=1em]
        \item \textit{Caso 3} - \textbf{\textit{Il nodo $u$ da eliminare ha due figli}}: in questo caso la logica dietro l'eliminazione del nodo diventa leggermente più complessa. Come illustrato in Figure \ref{fig:figura39}, supponiamo di\\
        \begin{minipage}[t]{0.527\textwidth}  
            
            \vspace{-20pt}
            \begin{figure}[H]
                \centering               
                \caption{Cancellazione di un nodo}
                \label{fig:figura39}
            \end{figure}

            \vspace{-20pt}
            \includegraphics[width=\linewidth]{figures/3_alberi/img20.png}
        \end{minipage}%
        \hspace{5pt} % Spazio tra immagine e testo
        \raisebox{0pt}{  
            \begin{minipage}[t]{0.426\textwidth}
                voler eliminare il nodo $u$ con valore di chiave $8$.
                Per prima cosa bisogna individuare il successore di $u$, ovvero, come detto al capitolo \ref{par:Ricerca del successore-predecessore}, \textit{"il più piccolo valore  più grande di $u$"}: quando si va a rimuovere un nodo con due figli, il suo \textbf{successore} ha la caratteristica di essere il sostituto adatto a ricoprire quella posizione in modo tale che le proprietà degli alberi BST vengano rispettate. 
            \end{minipage} 
        } 

        A questo punto possiamo dire che il successore ($v$) \textbf{rispetti le seguenti proprietà}:
        \vspace{3pt}
        \noindent
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{28}\rule{0.6ex}{0.6ex}}]
            \item È sicuramente \textbf{maggiore} dei nodi nel sottoalbero sinistro di $u$;
            \item È sicuramente \textbf{minore} dei nodi nel sottoalbero destro di $u$.
        \end{itemize}
        Una volta che il successore è stato individuato, bisogna sovrascriverlo al nodo che si vuole cancellare, eliminando anch'esso dalla sua posizione attuale.

        \vspace{8pt}
        A questo punto il \textit{caso 3} si può \textbf{ridurre ad uno dei due casi} visti in precedenza:
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{29}\rule{0.6ex}{0.6ex}}]
            \item \textit{Caso 1}: \textbf{il successore è una foglia}, quindi può essere sovrascritto e rimosso senza ulteriori accorgimenti;
            \item \textit{Caso 2}: \textbf{il successore ha solo un figlio destro}.\\
            A differenza di un normale \textit{caso 2}, quando si arriva ad esso passando dal \textit{caso 3}, \textbf{non può mai capitare} che il \textbf{successore} abbia \textbf{solo figlio sinistro}, perché se avesse il figlio sinistro \textbf{non sarebbe il minimo} del sottoalbero destro (capitolo \ref{par:Ricerca del massimo e del minimo} - caso $1$).
        \end{itemize}
    \end{itemize}


    \vspace{8pt}
    \noindent
    \textbf{\textit{Cancellazione ricorsiva di un nodo}}
    \begin{lstlisting}[style=mystyle, language=C++, numbers=left]
bstree *deleteNode(bstree *p, int x) {
    if(p==NULL) return NULL;
    if (x > p->data) p->right = deleteNode(p->right, x);
    else if(x < p->data) p->left = deleteNode(p->left, x);
    else{ //node found is p
        if(p->left==NULL && p->right==NULL){ //Nessun figlo (caso 1)
            free(p);
            return NULL;
        }
        else if(p->left==NULL || p->right==NULL){ //Un figlio (caso 2)
            bstree *temp;
            if(p->left==NULL) temp = p->right;
            else temp = p->left;
            free(p); 
            return temp;  
        }
        else{ //Due figli (caso 3)
            bstree *temp = find_minimum(p->right);
            p->data = temp->data;
            p->right = deleteNode(p->right, temp->data); 
        }
    }
    return p;
}
    \end{lstlisting}
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Tipo di ritorno}: la procedura di cancellazione di un nodo restituisce un puntatore alla radice dell'albero, che \textbf{può cambiare} se il nodo cancellato \textbf{è proprio la radice};
        \item \textbf{Parametri}: la funzione accetta in ingresso due parametri;
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{30}\rule{0.6ex}{0.6ex}}]
            \item \texttt{bstree *p}: un puntatore alla struttura di un nodo generico che viene utilizzato per passare il puntatore alla radice dell'intero albero;
            \item \texttt{int x}: un valore intero \texttt{x}, che rappresenta la chiave del nodo da cancellare.
        \end{itemize}
        \item \textbf{Funzionamento del codice}: All'interno della funzione \texttt{deleteNode()} vengono gestiti tutti i casi di cancellazione del nodo.
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{31}\rule{0.6ex}{0.6ex}}]
            \item \textit{riga 2}: si gestisce il caso base il caso base: se il puntatore \texttt{p} è \texttt{NULL}, vuol dire che non esiste alcun albero o che non è stato trovato alcun nodo con valore \texttt{x}. In questo caso viene semplicemente restituito \texttt{NULL};
            
            \item \textit{riga 3-4}: in queste due righe vengono gestiti i controlli codizionali per la ricera del nodo da rimuovere all'interno dell'albero. Se la chiave \texttt{x} è maggiore della chiave del nodo corrente (\texttt{x > p->data}), allora la ricerca avverrà richiamando ricorsivamente \texttt{deleteNode()} sulla radice del sottoalbero destro, altrimenti (\texttt{x < p->data}) la ricerca avviene, sempre in modo ricorsivo, ma sul sottoalbero sinistro;

            \item \textit{riga 5}: se si entra in quest'ultimo caso significa che il nodo da eliminare è stato trovato (\texttt{x == p->data}). All'interno di esso vengono implementati i 3 casi differenti per gestire l'eliminazione del nodo in base alla sua posizione all'interno dell'albero;

            \item \textit{riga 6-8}: il primo controllo condizionale gestisce il caso in cui il nodo da rimuovere sia una foglia (\textit{caso 1}). Quest'ultimo è valido solo se entrambi i puntatori ai figli destro e sinistro sono \texttt{NULL}. Verificato ciò, si procede ad eliminare il nodo \texttt{p} tramite il comando \texttt{free()} e viene ritornato \texttt{NULL} come nuovo puntatore da assegnare al padre (o alla radice se \texttt{p} era la radice).;
     
            \item \textit{riga 10-16}: il secondo controllo condizionale gestisce il caso in cui il nodo da rimuovere abbia un solo figlio (che sia destro o sinistro, ovvero \textit{caso 2}). Quest'ultimo è valido solo se almeno uno dei due puntatori ai figli è nullo. Una volta all'interno del controllo condizionale è bene \textbf{prestare attenzione anche al meccanismo di ricorsione} che viene utilizzato per permettere di \textbf{salvare il figlio del nodo} che si vuole eliminare.
            
            \vspace{8pt}
            Facendo riferimento alla Figure \ref{fig:figura39}, ipotizziamo di voler rimuovere il nodo con valore di chiave $9$ ed essere posizionati in $15$. La funzione inizia e ci si ferma nella \textit{riga 4} (poiché $9 < 15$) dove avvengono due cose:
            \begin{itemize}[leftmargin=1.4em]
                \item [$\rightarrow$] Si scende a sinistra perché viene richiamata \texttt{deleteNode()} su \texttt{p->left}, ovvero $9$;
                \item [$\rightarrow$] Allo stesso tempo, il puntatore al figlio sinistro ($9$) prenderà il risultato della chiamata appena avvenuta su \texttt{deleteNode()}.
            \end{itemize}
            Una volta su $9$, si entra nell'ultimo \texttt{else} e, in seguito, nel controllo condizionale per i nodi con un solo figlio, poiché l'unico figlio di $9$ è $12$.
            Viene dichiarato un puntatore generico alla struttura di un nodo \texttt{temp}: quest'ultimo verrà utilizzato per salvare temporaneamente il figlio ($12$), così da poter fare la \texttt{free()} del nodo $9$ senza perderlo.\\
            A questo punto \texttt{temp} viene restituito a \texttt{p->left} (il puntatore al figlio sinistro di $15$) come risultato della funzione ricorsiva chiamata prima: in questo modo, $12$ diventa figlio sinistro diretto di $15$.
            \item \textit{riga 18-21}: il terzo controllo condizionale gestisce il caso in cui il nodo da rimuovere abbia figlio destro e sinistro, ed ovviamente è valido se non si entra negli altri due casi prima. Precedentemente si è detto che, in teoria, per eliminare un nodo con due figli si dovrebbe trovare il suo successore (capitolo \ref{par:Ricerca del successore-predecessore}).
            Dal punto di vista implementativo, però, nel BST il successore coincide sempre con il nodo avente il valore minimo nel sottoalbero destro.
            Per questo motivo, nel codice non viene richiamata esplicitamente una funzione \texttt{successor()}, ma si utilizza direttamente la funzione \texttt{find\_minimum(p->right)} (capitolo \ref{par:Ricerca del massimo e del minimo}), che rappresenta esattamente tale concetto.

            \vspace{8pt}
            Trovato il suo successore, il valore della chiave di quest'ultimo viene semplicemente sovrascritto (\texttt{p->data = temp->data}) sul nodo da eliminare.\\
            A questo punto il problema è che il successore \textbf{esiste ancora fisicamente al suo posto originario}. La sua rimozione è semplice: per definizione il successore di un nodo non ha un figlio sinistro, quindi si richiama ricorsivamente la funzione \texttt{deleteNode()} che ne gestirà l'eliminazione seguendo il \textit{caso 1} se è una foglia o il \textit{caso 2} se ha un figlio destro. 
        \end{itemize}
    \end{itemize}

    \vspace{8pt}
    \noindent
    \textbf{\textit{Esempio di utilizzo}}\\
    Ipotizziamo di voler cancellare il nodo $8$ come illustrato in Figure \ref{fig:figura39}.
    \begin{lstlisting}[style=mystyle, language=C++]
int main(int argc, char *argv[]) {
    bstree *root = NULL;
    /* Creazione dell'albero BST in logica dicotomica illustrato in  
    (*@Figure \ref{fig:figura39}@*) utilizzando la funzione di inserimento, come fatto al
    capitolo (*@(\ref{par:Inserimento di un nodo})@*) */
    // ... 
    // ... 

    root = deleteNode(root, 8); // Cancellazione del nodo 8
    printf("La nuova radice e' %d\n", root->data);
}
    \end{lstlisting}


    \subsubsection{Alberi BST: alcune osservazioni}
    Tutte le operazioni effettuate fino ad ora (ricerca, inserimento, ecc\dots) sono confinate ai nodi posizionati lungo ad un cammino semplice dalla radice alla foglia.\\
    Durante tutte queste operazioni un fattore impattante è il \textbf{tempo di ricerca}.
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Tempo di ricerca
        ]
        Il \textbf{tempo di ricerca} è limitato superiormente da $h$, dove $h$ è l'altezza dell'albero.
    \end{tcolorbox}
    \noindent
    \begin{minipage}[t]{0.195\textwidth}  
        \includegraphics[width=\linewidth]{figures/3_alberi/img21.png}
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{127pt}{  
        \begin{minipage}[t]{0.782\textwidth}
            Come si può vedere dall'immagine, avendo un BST di altezza $h$, il caso pessimo è $O(h)$ dove è previsto di arrivare nella \textbf{parte più profonda dell'albero}.
            Il problema sorge quando si hanno $n$ nodi: il \textbf{caso pessimo} della struttura dell'albero è quello che viene generato quando gli \textbf{elementi} vengono \textbf{inseriti in ordine} perché l'albero può "allungarsi". Ad esempio, si pensi ad un albero dove vengono inseriti i seguenti nodi: \texttt{1->2->3->4->5->} e così via \dots, ovviamente tutti nel ramo destro. Quindi un albero contenente $n$ nodi, avrà altezza $h=O(n)$ e \textbf{tempo di ricerca} $O(h)$. In questo caso si parla di \textbf{albero non bilanciato}.
        \end{minipage} 
    }
    Gli alberi binari di ricerca, sono sì una buona idea per portare la ricerca binaria nel campo degli alberi, però \textbf{se i dati sono inseriti in certi modi sbagliati} (caso pessimo), si ottiene un'altezza dell'albero di $O(n)$ e quindi \textbf{non si ha nessun vantaggio} rispetto ad una banale \textbf{ricerca lineare} (liste).

    
    \vspace{8pt}
    \noindent
    Quando sono stati sviluppati gli alberi binari di ricerca, si è cercato di capire cosa succede in media, oltre che nel caso pessimo, e si è visto che facendo degli \textbf{inserimenti in ordine casuale}, l'altezza media dell'albero è $O(log \; n)$. Nella realtà però, non ci si affida al caso ma si utilizzano delle \textbf{tecniche per mantenere l'albero bilanciato}, o per meglio dire, \textbf{ribilanciarlo}.
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cos'è un BST bilaciato?
        ]
        Un BST \textit{“bilanciato”} è un albero binario in cui l'altezza è proporzionale al logaritmo del numero di nodi ($h = log_2(n+1) -1$).
    \end{tcolorbox}
    \noindent
    \begin{minipage}[t]{0.257\textwidth}  
        \includegraphics[width=\linewidth]{figures/3_alberi/img22.png}
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{79pt}{  
        \begin{minipage}[t]{0.720\textwidth}
            Quindi, se l'albero è \textbf{ben bilanciato} l'altezza è limitata superiormente esattamente da $h = O(log \; n)$.
            Quello che si vuole ottenere è \textbf{un meccanismo per ribilanciare gli alberi non bilanciati} e fare quindi in modo che la loro altezza sia più simile a $log \; n$ piuttosto che $n$ evitando casi particolari come il precedente. Un approccio possibile è quello degli \textbf{alberi AVL}.
        \end{minipage} 
    } 

    \subsubsection{Alberi BST: Alberi Adelson-Velsky and Landis (AVL)}
    Gli alberi AVL introducono alcune proprietà addizionali sugli alberi BST \textbf{per fare in modo che rimangano bilanciati}. Una di queste è il \textbf{fattore di bilanciamento}.
    \begin{tcolorbox}
        [
            colback=green!10,  % Sfondo verde chiaro
            colframe=green!60!black,  % Bordo verde più acceso
            coltitle=black,  % Colore del testo del titolo
            fonttitle=\bfseries,  % Testo del titolo in grassetto
            title={\centering \textbf{\textit{Fattore di bilanciamento}}},  % Titolo centrato 
            enhanced,  % Miglioramenti grafici
            attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
            boxed title style={colback=white, colframe=green!60!black, rounded corners},
            breakable
        ]
        Il \textbf{fattore di bilanciamento} $\beta(v)$ di un nodo $v$ è la differenza di altezza fra i sottoalberi destro e sinistro di $v$.
    \end{tcolorbox}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cos'è un albero AVL?
        ]
        Un albero binario di ricerca è un \textbf{albero AVL} se per ogni nodo $v$ l'altezza del sottoalbero sinistro di $v$ e quella del sottoalbero destro di $v$ differiscono al massimo di $1$ ($\beta(v)=h(left(v))-h(right(v))$). In altre parole il \textbf{fattore di bilanciamento} deve essere un valore compreso tra $ -1 \leqslant \beta(v) \leqslant 1$.
    \end{tcolorbox}
    \noindent
    In un albero BST l'inserimento di una nuova foglia in un determinato punto dell'albero può causare uno \textbf{sbilanciamento}. Nello specifico il \textbf{nodo sbilanciato} è il primo antenato che, dopo l'inserimento del nuovo nodo, presenta un fattore di bilanciamento $ > 1$.\\
    Per evitare gli sbilanciamenti viene utilizzato il concetto di \textbf{rotazione}.
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cos'è una rotazione?
        ]
        Una rotazione è un operazione locale che viene \textbf{eseguita} sul \textbf{nodo sbilanciato} causando lo spostamento di tre nodi: il nodo sbilanciato stesso, suo figlio e il suo nipote.\\
        Lo sbilanciamento viene riequilibrato \textbf{senza violare} le \textbf{proprietà strutturali} dei BST.
        Dunque, le \textbf{rotazioni} permettono di \textbf{abbassare} il fattore di bilanciamento.
    \end{tcolorbox}
    \noindent
    Esistono solo due rotazioni elementari: \textbf{rotazione a sinistra} e \textbf{rotazone a destra}.\\
    Invece, le \textbf{forme di sbilanciamento} di un albero BST sono quattro, e come detto prima, variano in base al punto di inserimento del nuovo nodo:
    \begin{itemize}[leftmargin=1em]
        \item \textit{Caso left-left (LL)}: il caso \textbf{\textit{left-left}} si verifica quando il nuovo nodo viene inserito nel sottoalbero sinistro del figlio sinistro del primo nodo, il quale diventa sbilanciato.
        
        \vspace{-8pt}
        \begin{minipage}[t]{0.550\textwidth} 
            \vspace{2pt}
            \includegraphics[width=\linewidth]{figures/3_alberi/img23.png}
        \end{minipage}%
        \hspace{5pt} % Spazio tra immagine e testo
        \raisebox{-8pt}{  
            \begin{minipage}[t]{0.403\textwidth}
                In questo caso il ramo sinistro "pesa" troppo e presenta un \textbf{fattore di bilanciamento} $ > 1$. Il caso \textit{left-left} possiede una \textbf{forma lineare}, dunque, per ribilanciare l'albero basta effettuare una sola rotazione verso destra.
            \end{minipage} 
        } 

        \vspace{12pt}
        \item \textit{Caso right-right (RR)}: il caso \textbf{\textit{right-right}} si verifica quando il nuovo nodo viene inserito nel sottoalbero destro del figlio destro del primo, il quale diventa sbilanciato
        
        \vspace{-10pt}
        \begin{minipage}[t]{0.550\textwidth} 
            \vspace{2pt}
            \includegraphics[width=\linewidth]{figures/3_alberi/img24.png}
        \end{minipage}%
        \hspace{5pt} % Spazio tra immagine e testo
        \raisebox{-10pt}{  
            \begin{minipage}[t]{0.403\textwidth}
                Anche in questo caso il ramo destro "pesa" troppo e presenta un \textbf{fattore di bilanciamento} $<-1$. Il caso \textit{right-right} possiede una \textbf {forma lineare}, e per ribilanciare l'albero, basta effettuare una sola rotazione verso sinistra.
            \end{minipage} 
        } 

        \vspace{12pt}
        \item \textit{Caso left-right (LR)}: il caso \textbf{\textit{left-right}} si verifica quando il nuovo nodo viene inserito nel sottoalbero destro del figlio sinistro del primo nodo, il quale diventa sbilanciato.
        \begin{figure}[H]
            \centering
            \vspace{-10pt}  % Riduce lo spazio sopra
            \includegraphics[width=0.9\textwidth]{figures/3_alberi/img25.png}
            \vspace{-16pt}  % Riduce lo spazio sopra
        \end{figure}
        Il fattore di bilanciamento in questo caso è $ > 1$. In questo caso il sottoalbero presenta una \textbf{forma a "zig-zag"} che, per essere bilanciata, necessita di una \textbf{doppia rotazione}: 
        \begin{enumerate}[leftmargin=1.3em]
            \item \textbf{Rotazione a sinistra}: viene effettuata sul figlio destro del figlio sinistro del nodo sbilanciato, per fare in modo di riportarsi alla \textbf{forma \textit{left-left}};
            \item \textbf{Rotazione a destra}: viene effettuata sul nodo sbilanciato per completare il bilancianento.
        \end{enumerate}

        \vspace{8pt}
        \noindent
        \item \textit{Caso right-left (RL)}: il caso \textit{right-left} si verifica quando il nuovo nodo viene inserito nel sottoalbero sinistro del figlio destro del primo nodo, il quale diventa sbilanciato.
        \begin{figure}[H]
            \centering
            \vspace{-10pt}  % Riduce lo spazio sopra
            \includegraphics[width=0.9\textwidth]{figures/3_alberi/img26.png}
            \vspace{-16pt}  % Riduce lo spazio sopra
        \end{figure}
        Presenta fattore di bilanciamento $ < -1$, e una forma a "zig-zag" che necessita di una doppia rotazione, in questo caso in senso inverso rispetto alla precedente: 
        \begin{enumerate}[leftmargin=1.3em]
            \item \textbf{Rotazione a destra}: viene effettuata sul figlio sinistro del figlio destro del nodo sbilanciato, per fare in modo di riportarsi alla \textbf{forma \textit{right-right}};
            \item \textbf{Rotazione a sinistra}: viene effettuata sul nodo sbilanciato per completare il bilancianento.
        \end{enumerate}
    \end{itemize}
    

    
    \vspace{8pt}
    \noindent
    \textbf{\textit{Rotazione a sinistra/destra per il bilanciamento}}

    \vspace{-3pt}
    \noindent
    \begin{minipage}[t]{0.487\textwidth}  
        \begin{lstlisting}[style=mystyle, language=C]
bstree *rotateleft(bstree *x) {
    bstree *y;
    y = x->right;
    x->right = y->left;
    y->left = x;
    return (y);
}
        \end{lstlisting}
    \end{minipage}%
    \hspace{6pt} % Spazio tra immagine e testo
    \begin{minipage}[t]{0.487\textwidth}
        \begin{lstlisting}[style=mystyle, language=C]
bstree * rotateright(bstree *x) {
    bstree *y;
    y = x->left;
    x->left = y->right;
    y->right = x;
    return (y);
}
        \end{lstlisting}
    \end{minipage}\\

    \begin{itemize}[leftmargin=1em]
        \item \textbf{Tipo di ritorno}: entrambe le funzioni ritornano un puntatore alla struttura di un nodo. Infatti, dopo la rotazione la radice dell'albero cambia: ciò che viene restituito è proprio la nuova radice dell'albero;
        \item \textbf{Parametri}: entrambe le funzioni accettano un unico parametro, ovvero il puntatore alla struttura del nodo che si vuole ruotare (\texttt{bstree *x});
        \item \textbf{Funzionamento del codice}: la logica utilizzata per la creazione delle due funzioni di rotazione è la stessa, ciò che le differenzia è il verso della rotazione (sinistra o destra).

        \vspace{8pt}
        \textbf{Funzionamento di \texttt{rotateleft} (e \texttt{rotateright})}\\
        Per illustrare il funzionamento di \texttt{rotateleft} utilizziamo la seguente immagine.\\
        Nel caso iniziale ciò che crea lo sbilanciamento è l'aggiunta del nodo $C$. Dunque deve essere effettuata una rotazione a sinistra specificando il puntatore al nodo $A$ nei parametri della funzione. Ovviamente il funzionamento di \texttt{rotateright} è il medesimo, solo invertito.

    \end{itemize}
    \begin{figure}[H]
        \centering
        \vspace{-10pt}  % Riduce lo spazio sopra
        \includegraphics[width=0.8\textwidth]{figures/3_alberi/img27.png}
        \vspace{-16pt}  % Riduce lo spazio sopra
    \end{figure}


    \newpage
    \section{Analisi della complessità degli algoritmi}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Obbiettivo
        ]
        L'obiettivo dell'\textbf{analisi} degli algoritmi è quello di \textbf{stimare la loro complessità} in termini di \textbf{tempo di calcolo}.
    \end{tcolorbox}
    \noindent
    Dunque, l'analisi della complessità degli algoritmi torna \textbf{utile} per \textbf{svariati motivi}:
    \begin{itemize}[leftmargin=1em]
        \item Stimare il tempo impiegato per un dato in input;
        \item Stimare il più grande input gestibile in tempi ragionevoli;
        \item Confrontare l'efficienza di algoritmi diversi;
        \item Ottimizzare le parti più importanti.
    \end{itemize}

    \subsection{Complessità e dimensione dell'input}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cos'è la complessità?
        ]
        
        Possiamo definire la \textbf{complessità} come una funzione matematica che descrive l'andamento del tempo di calcolo in relazione alla \textit{\textbf{dimensione dell'input}}.\\
        $T: "Dimensione\;dell'input" \rightarrow "Tempo\;di\;calcolo"$
    \end{tcolorbox}
    \noindent
    Dunque, maggiore è la dimensione dell'input, maggiore è il tempo di calcolo, con una \textbf{conseguente crescita} delle \textbf{risorse impiegate} dall'algoritmo per risolvere il problema.\\
    Le due principali tipologie di risorse impiegate sono:
    \begin{itemize}[leftmargin=1em]
        \item \textit{Risorse di \textbf{complessità temporale}}: cioè la quantità di tempo richiesta dall'algoritmo;
        \item \textit{Risorse di \textbf{complessità spaziale}}: la quantità di memoria necessaria durante l'esecuzione.
    \end{itemize}
    In realtà, \textit{complessità spaziale} diventa un problema secondario, che si andrà ad analizzare solo nel caso in cui, confrontando due algoritmi per determinarne il \textit{"migliore"}, abbiano la stessa complessità in termini di tempo.

    \vspace{-3pt}
    \begin{tcolorbox}
        [
            colback=green!10,  % Sfondo verde chiaro
            colframe=green!60!black,  % Bordo verde più acceso
            coltitle=black,  % Colore del testo del titolo
            fonttitle=\bfseries,  % Testo del titolo in grassetto
            title={\centering \textbf{\textit{Dimensione dell'input}}},  % Titolo centrato 
            enhanced,  % Miglioramenti grafici
            attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
            boxed title style={colback=white, colframe=green!60!black, rounded corners},
            breakable
        ]
        Con dimensione dell'input intendiamo la sua \textbf{taglia}, e abbiamo due possibili casi:

        \vspace{4pt}
        \begin{itemize}[leftmargin=1em]
            \item \textit{Criterio di \textbf{costo uniforme}}: la taglia dell'input è il \textbf{numero di elementi di cui è costituito}. In altre parole, ogni elemento dell'input costa $1$ unità, \textbf{indipendentemente} da quanti \textbf{bit servono per rappresentarlo}.\\
            \textbf{\textit{Esempio}}: per la ricerca del minimo in un vettore di $n$ elementi, l'algoritmo che lo elabora avrà un costo \textbf{proporzionale a $n$}.

            \vspace{4pt}
            \item \textit{Criterio di \textbf{costo logaritmico}}: la taglia dell'input è il \textbf{numero di bit necessari per rappresentarlo}. In questo caso, il costo dell'elaborazione dipende direttamente dalla \textbf{lunghezza in bit} dei dati in ingresso, e non dal numero di elementi di cui è composto.\\
            \textbf{\textit{Esempio}}: avendo in ingresso un numero intero molto grande, si può considerare il numero di bit necessari per rappresentarli.
        \end{itemize}
    \end{tcolorbox}
    \noindent
    Nella pratica, se ogni elemento dell'input occupa un numero costante di bit, allora i due criteri (uniforme e logaritmico) forniscono risultati equivalenti, \textbf{a meno} di una \textbf{costante moltiplicativa} applicata alla dimensione dell'\textbf{input}.
    Ad esempio, un input costituito da $n$ byte (criterio di costo uniforme) corrisponde a $8n$ bit (criterio di costo logaritmico).

    \subsection{Definizione di tempo e modello di calcolo} 
    \label{par:Definizione di tempo e modello di calcolo}
    Tuttavia, come introdotto al capitolo \ref{par:Complessità di un algoritmo}, l'approccio più immediato per valutare il \textbf{tempo di esecuzione/calcolo} di un algoritmo, non è quello di misurare i secondi impiegati dal calcolatore poiché entrerebbero in gioco dei fattori esterni, non dipendenti dall'algoritmo stesso. Quindi misurando solo \textit{"quanti secondi impiega un'algoritmo"}, non si possono confrontare gli algoritmi in modo universale, ma solo \textit{"sul computer in quel determinato momento"}.

    \vspace{8pt}
    \noindent
    L'\textbf{analisi della complessità} vuole invece essere \textbf{indipendente dal calcolatore}, proprio per questo, un \textbf{approccio} sicuramente \textbf{migliore} è quello di considerare come \textit{"tempo di calcolo"} il numero di istruzioni elementari eseguite.
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Tempo $\equiv$ numero istruzioni elementari
        ]
        Un'\textbf{istruzione} viene considerata \textbf{elementare} se può essere eseguita in tempo \textit{"costante"} dal processore (Il tempo di esecuzione \textit{\textbf{corrisponde}} al numero di istruzioni elementari).
    \end{tcolorbox}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cos'è il tempo di calcolo?
        ]
        Poiché i problemi da risolvere hanno una dimensione che dipende dalla grandezza dei dati di ingresso, viene spontaneo esprimere il \textbf{tempo di calcolo} come: \textit{il \textbf{costo complessivo} delle \textbf{operazioni elementari} in funzione della \textbf{dimensione $n$ dei dati} in ingresso}.
    \end{tcolorbox}
    \noindent
    Per poter capire quali istruzioni debbano essere considerate elementari, si utilizza il concetto di \textbf{modello di calcolo}, ovvero una rappresentazione semplificata ma rigorosa di un calcolatore, che definisce \textbf{quali operazioni} sono \textbf{ammesse} e \textbf{quanto costano}, tutto ciò in modo \textbf{indipendente} dalle caratteristiche \textbf{dell'hardware}.\\
    Un buon modello di calcolo \textbf{soddisfa tre requisiti} fondamentali:
    \begin{itemize}[leftmargin=1em]
        \item \textit{\textbf{Astrazione}}: deve permettere di \textbf{ignorare} i \textbf{dettagli irrilevanti} del calcolatore (ad esempio, non interessa conoscere la tipologia di processore e di quanta memoria disponga);
        \item \textit{\textbf{Realismo}}: deve riflettere una situazione reale;
        \item \textit{\textbf{Potenza matematica}}: deve consentire di trarre conclusioni matematiche (formali) sul costo computazionale.
    \end{itemize}

    \subsubsection{Random Access Machine (RAM)}
    Il modello di calcolo che normalmente viene utilizzato è detto \textbf{Random Access Machine (RAM)} ed è caratterizzato da:
    \begin{itemize}[leftmargin=1em]
        \item \textit{\textbf{Memoria}}: si assume che la memoria presenti una quantità infinita di celle di dimensione finita, poiché si vuole capire il funzionamento dell'algoritmo al crescere della dimensione dell'input, ciascuna delle quali è accessibile in tempo costante;
        \item \textit{\textbf{Processore (singolo)}}: ha un processore singolo che esegue un insieme limitato di \textbf{istruzioni elementari} (come somma, sottrazione, moltiplicazione, operazioni logiche, salti condizionati, ecc\dots);
        \item  \textit{\textbf{Costo delle istruzioni elementari}}: ad ogni istruzione elementare viene assegnato, un \textbf{costo costante}, che rappresenta il tempo richiesto per eseguirla.
    \end{itemize}
    \noindent
    Lo scopo finale non è confrontare le prestazioni dei processori (compito dei benchmark), ma determinare se un algoritmo è più efficiente di un altro.

    \subsection{Valutazione del caso pessimo, medio e ottimo}
    \label{par:Valutazione del caso pessimo, medio e ottimo}
    Principalmente, il costo delle singole operazioni è valutato nel \textbf{caso pessimo}, ovvero sul dato di ingresso più sfavorevole tra tutti quelli di dimensione $n$.\\
    In alternativa, si può considerare anche il \textbf{caso medio}, calcolando la media dei costi su tutti i possibili input di dimensione $n$, pesata in base alla probabilità con cui ciascun dato può verificarsi. Mentre, talvolta si introduce anche il \textbf{caso ottimo} che rappresenta il costo minimo dell'algoritmo su un input di diemnsione $n$.

    \vspace{8pt}
    \noindent
    Il caso ottimo è \textbf{raramente utile}: infatti un buon comportamento nel caso ottimo \textbf{non garantisce prestazioni accettabili negli altri casi} e può dare un'\textbf{illusione di efficienza} non rappresentativa del comportamento complessivo dell'algoritmo.
    \begin{tcolorbox}
        [
            colback=green!10,  % Sfondo verde chiaro
            colframe=green!60!black,  % Bordo verde più acceso
            coltitle=black,  % Colore del testo del titolo
            fonttitle=\bfseries,  % Testo del titolo in grassetto
            title={\centering \textbf{Perché valutiamo il caso pessimo se può verificarsi molto raramente?}},  % Titolo centrato 
            enhanced,  % Miglioramenti grafici
            attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
            boxed title style={colback=white, colframe=green!60!black, rounded corners},
            breakable
        ]
        Il vantaggio del caso pessimo è dato dal fatto che questo tipo di valutazione non richiederà mai, per nessun dato di dimensione $n$, un tempo maggiore.\\
        Invece, la valutazione nel caso medio sembra più realistica, ma è ignota la distribuzione di probabilità: spesso viene utilizzata una distribuzione uniforme che per molti problemi è irrealistica 
    \end{tcolorbox}

    \subsubsection{Tempo di calcolo della funzione \texttt{min()} (iterativa)}
    \label{par:Tempo_calcolo_min_iterativa}
    In questo caso si vuole stimare il tempo di calcolo della funzione \texttt{min()} che si occupa di trovare l'elemento più piccolo all'interno di un vettore. Per prima cosa si controlla il numero delle operazioni elementari dalla quale è costituita la funzione in esame.\\ A questo punto possiamo: 
    \begin{itemize}[leftmargin=1em]
        \item Indicare con $C_h$ il costo richiesto per l'esecuzione dell'istruzione $h-$esima, perché non so esattamente quante operazioni macchina servano per eseguire l'istruzione (colonna "costo");
        \item Inoltre, effettuando una valutazione nel \textbf{caso pessimo}, per ogni $h-$esima istruzione si specifica il \textbf{massimo numero di volte} che questa viene eseguita (colonna "\# Volte").
    \end{itemize}
    \begin{figure}[H]
        \centering
        \vspace{-10pt}  % Riduce lo spazio sopra
        \includegraphics[width=\textwidth]{figures/tempo_e_modello_calcolo/img1.png}
        \vspace{-30pt}  % Riduce lo spazio sopra 
    \end{figure}
    \textbf{\textit{N.B}}: per quanto riguarda il ciclo for, è giusto scrivere che viene eseguito $n$ volte, poiché anche la $n-1$esima volta la riga viene eseguita prima di capire che la condizione non è rispettata. Infatti come si può notare, le istruzioni al suo interno vengono eseguite $n-1$ volte.

    \vspace{8pt}
    \noindent
    Dunque, il tempo di calcolo $T(n)$ di \texttt{min()} si ottiene sommando il prodotto del costo di ciascuna istruzione per il numero di volte che e stata eseguita:\\
    $T(n) = c_1 + c_2(n) + c_3(n-1) + c_4(n-1) + c_5 = (c_2 + c_3 + c_4)n + (c_1 + c_5 - c_3 - c_4) = an + b$\\
    (Posso scrivere $an + b$ perché non si conosce il valore dei costi da $c_1...c_5$).
    \begin{tcolorbox}
        [
            colback=green!10,  % Sfondo verde chiaro
            colframe=green!60!black,  % Bordo verde più acceso
            coltitle=black,  % Colore del testo del titolo
            fonttitle=\bfseries,  % Testo del titolo in grassetto
            title={\centering \textbf{Osservazioni sull'identificazione del caso}},  % Titolo centrato 
            enhanced,  % Miglioramenti grafici
            attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
            boxed title style={colback=white, colframe=green!60!black, rounded corners},
            breakable
        ]
        Per distinguere caso ottimo, medio e pessimo, occorre capire come varia il numero di operazioni dell'algoritmo al variare dell'input.\\
        Nel caso della funzione \texttt{min()}, il numero di iterazioni del ciclo e il numero di confronti eseguiti sono \textbf{indipendenti dai valori dell'input}: il \texttt{for} viene sempre eseguito $n$ volte e il confronto viene sempre effettuato $n-1$ volte. \\
        Di conseguenza, la funzione presenta un tempo di esecuzione $T(n)$ lineare sia nel caso pessimo sia nel caso medio.
    \end{tcolorbox}

    \subsubsection{Tempo di calcolo della funzione \texttt{binarySearch()} (ricorsiva)}
    \label{par:Tempo_calcolo_binary_search}
    In quest'altro caso si considera la funzione \texttt{binarySearch()} che si occupa di ricercare \textbf{la posizione} di un elemento all'interno di una sequenza ordinata, memorizzata in un vettore $A$.\\
    La logica che sta dietro la \textbf{ricerca binaria}, è la stessa che viene utilizzata per la ricerca di un nodo negli alberi binari: ogni volta che viene richiamata la funzione in modo ricorsivo, si elimina metà del vettore (\textbf{ricerca dicotomica} - capitolo \ref{par:Alberi binari di ricerca (BST)}).
    \begin{figure}[H]
        \centering
        \vspace{-10pt}  % Riduce lo spazio sopra
        \includegraphics[width=\textwidth]{figures/tempo_e_modello_calcolo/img2.png}
        \vspace{-30pt}  % Riduce lo spazio sopra 
    \end{figure}
    \noindent
    A differenza del caso precedente (capitolo \ref{par:Tempo_calcolo_min_iterativa}), l'algoritmo esegue porzioni di codice differenti a seconda dei valori di input (\textit{i} e \textit{j}), che sono rispettivamente, l'\textbf{indice iniziale} del vettore e l'\textbf{indice finale} del vettore.
    Per avere una valutazione del tempo di calcolo si andrà a valutare il \textbf{caso pessimo} di \textbf{entrambe le porzioni} di codice, inserendo due colonne etichettate con "\#", che indicano quante volte ciascuna riga viene eseguita :
    \begin{itemize}[leftmargin=1em]
        \item \textit{i $>$ j}: questa porzione di codice esegue direttamente la condizione di chiusura poiché se \textit{i} è maggiore di \textit{j} si sta indicando un insieme di elementi nullo in cui la posizione dell'elemento non può esistere.\\
        In questo caso si può vedere come, nella colonna \#($i > j$), vengono eseguite solo le righe con costo $c_1$ e $c_2$, poiché subito dopo la ricorsione termina, di conseguenza tutte le altre righe vengono eseguite $0$ volte. Dunque il tempo di calcolo sarà dato da: $T(n) = c_1 + c_2 = c$, dove $n$ è zero perché non esiste una grandezza ($n$) specifica per il vettore.
        \item \textit{i $<$ j}: in quest'altra porzione di codice il vettore viene suddiviso in due parti \textbf{sinistra} e \textbf{destra}. La parte sinistra ha grandezza $[(n-1)/2]$, mentre la parte destra $[n/2]$.\\
        Il caso pessimo prevede la ricerca di un elemento \textbf{maggiore del massimo contenuto} nel

        \vspace{-10pt}
        \begin{minipage}[t]{0.550\textwidth} 
            \vspace{2pt}
            \includegraphics[width=\linewidth]{figures/tempo_e_modello_calcolo/img3.png}
        \end{minipage}%
        \hspace{5pt} % Spazio tra immagine e testo
        \raisebox{-10pt}{  
            \begin{minipage}[t]{0.403\textwidth}
                vettore, dunque $v$ sarà sempre maggiore di $A[m]$ e l'algoritmo sceglierà sempre la parte di vettore più grande ($[n/2]$).\\
            \end{minipage} 
        }
        \begin{minipage}[t]{0.550\textwidth} 
            \vspace{2pt}
            \includegraphics[width=\linewidth]{figures/tempo_e_modello_calcolo/img4.png}
        \end{minipage}%
        \hspace{5pt} % Spazio tra immagine e testo
        \raisebox{-10pt}{  
            \begin{minipage}[t]{0.403\textwidth}
                La ricerca di un elemento non presente all'interno del vettore, causa l'esecuzione ricorsiva delle istruzioni con costo: $c_3, c_4, c_6, c_7+T(n/2)$.\\
                Inoltre, ad ogni ricorsione viene esplorata la metà destra, scartatando metà degli elementi rimanenti, aggiornando gli indici di inizio ($i$), fine ($j$) e dell'elemento mediano del vettore 
            \end{minipage} 
        }

        \vspace{5pt}
        ($m$), fino ad esaurire tutti gli elementi. Il costo della funzione è quindi: $T(n) = c_1 + c_2 + c_4 + c_6 + c_7 + T(\frac{n}{2}) = d + T(\frac{n}{2})$ dove $d$ rappresenta la somma da $c_1...c_7$.

        \vspace{8pt}
        Questo significa che l'equazione non è definita in modo semplice da un solo valore, ma da una \textbf{relazione di ricorrenza} (capitolo \ref{par:Le ricorrenze}). Una tecnica che viene utilizzata per risolvere le\\
        \begin{minipage}[t]{0.353\textwidth}  
            \vspace{-23pt}
            \[
                T(n) =
                \begin{cases}
                    c \quad  \quad  \quad \quad \; se \; n=0\\
                    T(\frac{n}{2}) + d \quad se \; n\geqslant 1
                \end{cases}
            \]
        \end{minipage}% 
        \hspace{5pt} % Spazio tra immagine e testo
        \raisebox{0pt}{  
            \begin{minipage}[t]{0.600\textwidth}
                relazioni di ricorrenza consiste nel \textbf{produrre una catena di uguaglianze} ottenute per
                sostituzioni successive.\\
                Infatti possiamo scrivere che $T(n) = T(n/2)+d =$
            \end{minipage}  
        } 

        \vspace{2pt}
        $T(n/4)+2d = ... = T(n/2^k)+kd$, da cui possiamo ricavare che $\frac{n}{2^k} \Rightarrow k = log \; n$.\\
        Andando avanti con la ricorrenza si arriverà ad un punto in cui $T(n/2^k)+kd = T(1) +kd = [T(0) + d] + kd = T(0) + d(k+1) = c + kd + d = d\; log\;n + (c+d)$.

    \end{itemize}

    \subsection{Ordini di complessità}
    Dopo aver analizzato gli algoritmi al capitolo \ref{par:Valutazione del caso pessimo, medio e ottimo} sono state ottenute due \textbf{funzioni di complessità}, con una \textbf{serie di parametri} che \textbf{non si è in grado di determinare}.\\
    Questa difficoltà viene aggirata utilizzando il concetto di \textbf{crescita asintotica}.
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Concetto di crescita asintotica
        ]
        Quando analizziamo un algoritmo, non ci interessa tanto il tempo preciso di esecuzione, ma \textbf{come cresce questo tempo} quando la dimensione dell'input $n$ diventa molto grande.
        \begin{itemize}[leftmargin=1em]
            \item \textit{\textbf{Crescita lineare}}: \texttt{min}: $an + b \Rightarrow O(n)$ 
            \item \textit{\textbf{Crescita logaritmica}}: \texttt{BinarySearch()}: $d\; log\;n + (c+d) \Rightarrow O(log \;n)$ 
        \end{itemize}
    \end{tcolorbox}
    \noindent
    Questo concetto è utile perché permette di \textbf{confrontare algoritmi diversi} senza \textbf{preoccuparsi} delle costanti (che dipendono dall'hardware o dall'implementazione).\\
    Permette di capire \textbf{quale algoritmo sarà più efficiente} su input grandi, anche se su input piccoli può sembrare più lento.

    \vspace{8pt}
    \noindent
    \textbf{\textit{Esempio intuitivo}}: Supponiamo di avere due algoritmi.
    \begin{itemize}[leftmargin=1em]
        \item \textbf{\textit{Algoritmo A}}: richiede $100n$ operazioni $\rightarrow$ complessità $O(n)$;
        \item \textbf{\textit{Algoritmo B}}: richiede $n^2$ operazioni $\rightarrow$ complessità $O(n^2)$
    \end{itemize}
    \begin{itemize}[leftmargin=1em]
        \item  [$\rightarrow$] Per $n=10$, \textit{A} fa $1000$ operazioni, mentre \textit{B} ne fa $100$;
        \item [$\rightarrow$] Per $n=100$, \textit{A} fa $100.000$ operazioni, mentre \textit{B} ne fa $1.000.000$;
    \end{itemize}
    Quindi asintoticamente \textit{A} è il migliore, anche se su input piccolo \textit{B} sembrava il migliore.
    
    \subsubsection{Principali classi di efficienza asintotiche}
    \label{par:Principali classi di efficienza asintotiche}
    Nella seguente tabella vengono mostrati il numero di passi necessari per compleatre l'algoritmo in base alla complessità e alla dimensione dell'input.

    \vspace{-10pt} 
    \begin{figure}[h]
        \centering
        \vspace{-5pt}  % Riduce lo spazio sopra
        \subfloat[]{%
            \includegraphics[width=0.58\linewidth]{figures/tempo_e_modello_calcolo/img5.png}
        } 
        \hspace{0.1cm}
        \subfloat[]{%
            \includegraphics[width=0.38\linewidth]{figures/tempo_e_modello_calcolo/img9.png}
        }
    \end{figure}
    \FloatBarrier

    \vspace{-12pt}
    \begin{itemize}[leftmargin=1em]
        \item \textbf{Complessità \textit{logaritmica}}: Tipicamente, il risultato di ridurre le dimensioni del problema di un fattore costante ad ogni iterazione. \textbf{N.B}: un algoritmo in questa classe di effcienza non può tenere conto di tutto il suo input, altrimenti avrebbe effcienza lineare;
        \item \textbf{Complessità \textit{lineare}}:  Algoritmi che e ettuano un numero costante di iterazioni sull input (ad esempio una ricerca sequenziale);
        \item \textbf{Complessità \textit{loglineare} (o superlineare)}: Algoritmi che necessitano di effettuare almeno una scansione completa dell'input, ma che riducono di un fattore costante le iterazioni intermedie (ad esempio gli algoritmi divide-et-impera);
        \item \textbf{Complessità \textit{quadratica}}: Tipica degli algoritmi che sono basati su due iterazioni annidate. Ad esempio, alcuni algoritmi di ordinamento che effettuano operazioni su matrici $n \cdot n$;
        \item \textbf{Complessità \textit{cubica}}: Tipica degli algoritmi che sono basati su tre iterazioni annidate, diversi algoritmi di algebra lineare ricadono in questa classe;
        \item \textbf{Complessità \textit{esponenziale}}: Algoritmi che e ettuano ricerca sui sottoinsiemi di un insieme di $n$ elementi;
        \item \textbf{Complessità \textit{fattoriale}}: Algoritmi che e effettuano ricerca su permutazioni di un insieme di $n$ elementi.
    \end{itemize}


    \subsubsection{Notazioni asintotiche}
    Per \textbf{descrivere la crescita asintotica} di un algoritmo, quindi come cresce il tempo di esecuzione dell'algoritmo al crescere dell'input $n$, vengomo utilizzate delle \textbf{notazioni}.
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Notazione Big-O ($O$ grande)
        ]
        Descrive il \textbf{limite superiore} della crescita di un algoritmo.
        \begin{itemize}[leftmargin=1em]
            \item Garantisce che il tempo di calcolo non esploderà oltre una certa funzione;
            \item Di conseguenza, viene utilizzata per \textbf{descrivere il caso peggiore}.
        \end{itemize}
    \end{tcolorbox}
    \noindent
    \textbf{\textit{Esempio}}: se un algoritmo è $O(n)$, significa che al crescere dell'input non farà mai più di un numero di operazioni proporzionale a $n$.

    \vspace{8pt}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Notazione Omega ($\Omega$ grande)
        ]
        Descrive il \textbf{limite inferiore} della crescita di un algoritmo.
        \begin{itemize}[leftmargin=1em]
            \item Indica il lavoro minimo che l'algoritmo deve svolgere, anche nel caso migliore;
            \item Serve a capire che \textbf{sotto una certa soglia di complessità non si può scendere}.
        \end{itemize}
    \end{tcolorbox}
    \noindent
    \textbf{\textit{Esempio}}: se un algoritmo è $\Omega(n)$, significa che anche nel caso più favorevole deve comunque guardare almeno $n$ elementi.

    \vspace{8pt}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Notazione Theta ($\Theta$ grande)
        ]
        Descrive i due \textbf{limiti} (\textbf{inferiore e superiore}) della crescita di un algoritmo.
        \begin{itemize}[leftmargin=1em]
            \item Indica la \textbf{crescita reale} dell'algoritmo;
            \item Torna utile quando sappiamo che un algoritmo cresce esattamente come una certa funzione, permettendo di \textbf{classificarlo con precisione}.
        \end{itemize}
    \end{tcolorbox}
    \noindent
    \textbf{\textit{Esempio}}: se un algoritmo è $\Theta(nlogn)$, significa che cresce proprio in quel modo: non più veloce, non più lento.

    \vspace{-10pt} 
    \begin{figure}[h]
        \centering
        \vspace{-5pt}  % Riduce lo spazio sopra
        \subfloat[Notazione $O$ grande]{%
            \includegraphics[width=0.31\linewidth]{figures/tempo_e_modello_calcolo/img6.png}
        } 
        \hspace{0.1cm}
        \subfloat[Notazione $\Omega$ grande]{%
            \includegraphics[width=0.31\linewidth]{figures/tempo_e_modello_calcolo/img7.png}
        }
        \hspace{0.1cm}
        \subfloat[Notazione $\Theta$ grande]{%
            \includegraphics[width=0.31\linewidth]{figures/tempo_e_modello_calcolo/img8.png}
        }
        \vspace{-15pt}  % Riduce lo spazio sotto
    \end{figure}
    \FloatBarrier

    \subsection{Le ricorrenze}
    \label{par:Le ricorrenze}
    Quando un algoritmo contiene una \textbf{chiamata ricorsiva a se stesso} il suo tempo di esecuzione spesso può essere descritto attraverso \textbf{una ricorrenza}.
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Cos'è una ricorrenza?
        ]
        Una \textbf{ricorrenza} è un'equazione che descrive una funzione (tipicamente il tempo di esecuzione $T(n)$) in termini del suo stesso valore calcolato su input più piccoli.
    \end{tcolorbox}
    \noindent
    Le ricorrenze nascono quando un algoritmo ricorsivo \textbf{divide il problema in sottoproblemi} più piccoli e \textbf{richiama se stesso}.\\
    Infatti, come è stato visto al capitolo \ref{par:Tempo_calcolo_binary_search}, l'algoritmo \texttt{binarySearch()} dimezza il problema ad ogni passo tramite la seguente ricorrenza: $T(n) = T(\frac{n}{2})+d$, che abbiamo visto avere complessità logaritmica $O(log\;n)$.\\
    Quindi, è possibile esprimere il tempo di esecuzione viene espresso come \textbf{la somma di}:
    \begin{itemize}[leftmargin=1em]
        \item Il \textbf{costo} per \textbf{dividere o combinare} il problema (nel caso precedente $d$);
        \item Il \textbf{costo} per le \textbf{chiamate ricorsive} su sottoproblemi più piccoli (nel caso precdente $T(\frac{n}{2})$).
    \end{itemize}


    \vspace{8pt}
    \noindent
    Per risolvere le ricorrenze è possibile \textbf{utilizzare tre metodi} differenti: metodo di \textbf{sostituzione}, metodo dell'\textbf{esperto} o metodo dell'\textbf{albero di ricorsione}.

    \subsubsection{Metodo di sostituzione (o per tentativi)}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Idea di base
        ]
        Il metodo della sostituzione consiste nell'\textbf{ipotizzare la forma della soluzione} per poi utilizzare l'\textbf{induzione} matematica per \textbf{dimostrare che la soluzione ipotizzata} funziona.
    \end{tcolorbox}
    \noindent
    Il metodo di sostituzione puo essere usato per determinare il limite inferiore o superiore di una ricorrenza, e \textbf{la sua applicazione ha senso} solo nei casi in cui è \textbf{"facile" immaginare} la \textbf{forma} della soluzione.\\
    Ad esempio, una prima ipotesi può essere effettuata nei casi in cui l'algoritmo \textbf{rispecchia una delle descrizioni} di complessità (logaritmica, lineare, loglineare, ecc...) - Capitolo \ref{par:Principali classi di efficienza asintotiche}.

    \vspace{8pt}
    \noindent
    Una volta fatta l'ipotesi, si procede a produrre una \textbf{catena di uglianze} ottenute per \textbf{sostituzioni successive} (come già fatto al capitolo \ref{par:Tempo_calcolo_binary_search}) cercando di arrivare all'ipotesi effettuata in precedenza.

    \vspace{-8pt}
    \begin{tcolorbox}
        [
            colback=green!10,  % Sfondo verde chiaro
            colframe=green!60!black,  % Bordo verde più acceso
            coltitle=black,  % Colore del testo del titolo
            fonttitle=\bfseries,  % Testo del titolo in grassetto
            title={\centering \textbf{Osservazioni}},  % Titolo centrato 
            enhanced,  % Miglioramenti grafici
            attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
            boxed title style={colback=white, colframe=green!60!black, rounded corners},
            breakable
        ]
        È importante notare che non esiste un metodo generale per formulare l'ipotesi della soluzione corretta di una ricorrenza, infatti se quest'ultima è simile ad una già vista, \textbf{ha senso provare una soluzione analoga}.
    \end{tcolorbox}
    
    \subsubsection{Metodo dell'esperto}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Idea di base
        ]
        Il metodo dell'esperto (Master Theorem) è una \textbf{\textit{"formula pronta}}" per un'\textbf{intera famiglia di ricorrenze} tipiche, che dividono un problema di dimensione $n$ in $a$ sottoproblemi di dimensione $n/b$.
    \end{tcolorbox}
    \noindent
    La seguente formula $T(n) = aT(n/b)+f(n)$ dove $a\geqslant1$ e $b>1$ fornisce subito il risultato:
    \begin{itemize}[leftmargin=1em]
        \item Ogni $a-$esimo sottoproblema viene risolto nel tempo $T(n/b)$;
        \item Il costo per dividere il problema e combinare i risultati dei sottoproblemi è descritto da $f(n)$
    \end{itemize}
    Dunque, questa metodologia di soluzione per le ricorrenze \textbf{risulta perfetta solo per algoritmi classici} come mergesort, binary search, quicksort, ecc...

    \vspace{8pt}
    \noindent
    Proprio perché viene utilizzata per una famiglia di algoritmi tipici di cui si conosce l'andamento reale del caso pessimo $\Theta(...)$, è possibile \textbf{individuare tre casi} in cui l'andamento dell'algoritmo può ricadere:\\
    Date le costanti intere $a\geqslant 1$ e $b\geqslant 2$ e le costanti reali $c>0$ e $\beta\geqslant 0$. Sia $T(n)$ data dalla relazione di ricorrenza:
    \vspace{-15pt}
    \[
        T(n) =
        \begin{cases}
            c \quad  \quad  \quad \quad \quad \quad \quad se\;n\leqslant 1\\
            aT(n/b) + cn^\beta \quad \; se\;n>1
        \end{cases}
        con \;\alpha=\frac{log\;a}{log\;b}=log_ba:\;\quad
        T(n) =
        \begin{cases}
            \Theta(n^\alpha) \quad \quad \quad \alpha>\beta\\
            \Theta(n^\alpha log n) \quad \alpha=\beta\\
            \Theta(n^\beta) \quad \quad \quad \alpha<\beta\\
        \end{cases}
    \]

    \noindent
    \textbf{Esempio del \textit{Caso 1}}\\
    Immaginiamo di avere la ricorrenza $T(n) = 9T(n/3)+n$, si ha dunque:
    \begin{itemize}[leftmargin=1em]
        \item $a=9, b=3$
        \item $\alpha=log_39=2$
        \item $\beta=1$
    \end{itemize}
    Quindi $\alpha>\beta \Rightarrow T(n)=\Theta(n^\alpha)=\Theta(n^2)$

    \vspace{8pt}
    \noindent
    \textbf{Esempio del \textit{Caso 2}}\\
    Immaginiamo di avere la ricorrenza $T(n) = T(n/3)+1$, si ha dunque:
    \begin{itemize}[leftmargin=1em]
        \item $a=1, b=3$
        \item $\alpha=\frac{log 1}{log 3}=0$
        \item $\beta=0$
    \end{itemize}
    Quindi $\alpha=\beta \Rightarrow T(n)=\Theta(n^\alpha log\;n)=\Theta(log\;n)$

    \vspace{8pt}
    \noindent
    \textbf{Esempio del \textit{Caso 3}}\\
    Immaginiamo di avere la ricorrenza $T(n) = 3T(n/4)+n$, si ha dunque:
    \begin{itemize}[leftmargin=1em]
        \item $a=3, b=4$
        \item $\alpha=\frac{log 4}{log 3}=0.793$
        \item $\beta=1$
    \end{itemize}
    Quindi $\alpha<\beta \Rightarrow T(n)=\Theta(n^\beta)=\Theta(n)$

    \subsubsection{Metodo dell'albero di ricorsione (analisi per livelli)}
    \label{par:Metodo dell'albero di ricorsione (analisi per livelli)}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Idea di base
        ]
        La \textbf{ricorsione} viene immaginata \textbf{come un albero}: ogni \textbf{nodo è un sottoproblema} con un determinato costo, e \textbf{ogni livello} dell'albero rappresenta \textbf{un passo} della ricorsione.
    \end{tcolorbox}
    \noindent
    Quindi, si calcola il \textbf{costo di ogni livello} (somma dei costi dei singoli nodi per quel livello), e poi \textbf{si sommano tutti i livelli}. Possiamo immaginarlo come un processo di questo tipo:
    \begin{itemize}[leftmargin=1em]
        \item \textbf{\textit{Livello 0}}: abbiamo l'espressione originale;
        \item \textbf{\textit{Livello 1}}: espressione a cui è stata applicata un'espansione;
        \item \textbf{\textit{Livello 2}}: vengono applicate due espansioni;
        \item ... si continua fino al caso base.
    \end{itemize}
    \begin{minipage}[t]{0.550\textwidth} 
        \vspace{2pt}
        \includegraphics[width=\linewidth]{figures/tempo_e_modello_calcolo/img10.png}
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{-10pt}{  
        \begin{minipage}[t]{0.427\textwidth}
            Per comprendere meglio il concetto si consideri la ricorrenza:

            \vspace{-15pt}
            \[
                T(n) =
                \begin{cases}
                    1 \quad \quad \quad \quad \quad \quad \;\;se\;n=1\\
                    4T(n/2) + n^2 \quad \;n=2^h,\;h>0
                \end{cases}
            \]

            Dunque, il \textbf{costo complessivo} di ciascun livello dell'albero (escluso l'ultimo che è il caso base) è sempre $n^2$: i sottoproblemi sono più piccoli ma più numerosi.
            Invece, $4T(n/2)$ è il costo per la chiamata ricorsiva che genera $4$ sottoproblemi di dimensione $n/2$.
        \end{minipage} 
    }
    \begin{itemize}[leftmargin=1em]
        \item \textbf{\textit{Livello 0} (radice)}
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{32}\rule{0.6ex}{0.6ex}}]
            \item Si ha un solo problema di dimensione $n$.
        \end{itemize}
        \item \textbf{\textit{Livello 1}}
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{33}\rule{0.6ex}{0.6ex}}]
            \item Il problema si divide in 4 sottoproblemi (coefficiente 4);
            \item Il costo di ciascuno è $n^2/4$;
            \item Ognuno ha dimensione $n/2$;
            \item Costo totale del livello $4\cdot(n^2/4) = n^2$
        \end{itemize}
        \item \textbf{\textit{Livello 2}}
        \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{33}\rule{0.6ex}{0.6ex}}]
            \item Ogni sottoproblema del livello $1$ si divide di nuovo in $4$ → in totale $4^2=16$ sottoproblemi;
            \item Il costo di ciascuno è $n^2/16$;
            \item Ognuno ha dimensione $n/4$;
            \item Costo totale del livello $16\cdot(n^2/16) = n^2$
        \end{itemize}
    \end{itemize}
    Quindi, seguendo il pattern, il numero di sottoproblemi cresce ad ogni livello di $4^i$ e la dimensione di ognuno diminuisce di $n/2^i$.

    \vspace{8pt}
    \noindent
    In questo caso specifico è facile capire la complessità della ricorrenza, poiché \textbf{il numero di sottoproblemi cresce esponenzialmente} ($4^i$), ma allo stesso momento la loro dimensione cala esponenzialmente ($n/2^i$) e questo permette al costo totale di ogni livello di rimanere costante ($n^2$), ma ripetuto per tutti i livelli.
    Dunque, la ricorrenza ha complessità $O(n^2\;log\;n)$.
    \begin{tcolorbox}
        [
            colback=green!10,  % Sfondo verde chiaro
            colframe=green!60!black,  % Bordo verde più acceso
            coltitle=black,  % Colore del testo del titolo
            fonttitle=\bfseries,  % Testo del titolo in grassetto
            title={\centering \textbf{Osservazioni}},  % Titolo centrato 
            enhanced,  % Miglioramenti grafici
            attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
            boxed title style={colback=white, colframe=green!60!black, rounded corners},
            breakable
        ]
        Grazie al fatto che la ricorsione viene suddivisa il livelli, questo approccio risulta molto utile per capire intuitivamente dove si concentra il costo (in alto, in basso o se è distribuito su tutti i livelli) 
    \end{tcolorbox}

    \subsection{Ordinamento}
    Dato un generico problema, è possibile progettare un gran numero di \textbf{algoritmi differenti} per la sua risoluzione, ognuno caratterizzato dal proprio tempo di calcolo: alcuni molto lenti, altri molto veloci.
    \begin{itemize}[leftmargin=1em]
        \item Gli algoritmi con \textbf{complessità esponenziale} (tipo $2^n$) \textbf{non sono accettabili} come soluzione nel momento in cui si lavora con \textbf{input grandi}, a meno che non sia possibile dimostrare che il problema posto sia inerentemente difficile;
        \item Invece, realizzando un'algoritmo di \textbf{complessità polinomiale} (tipo $n^2$ o $n\cdot logn$), si ha già fatto un buon lavoro, ma si cerca comunque di \textit{"abbassarne la complessità"}.
    \end{itemize}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Obbiettivo
        ]
        In questi casi l'\textbf{obbiettivo} principale è quello di valutare gli algoritmi in base alla \textbf{tipologia dell'input}. Ovviamente gli algoritmi \textit{"migliori"} sono quelli che garantiscono tempi di esecuzione accettabili anche su input molto grandi. 
    \end{tcolorbox}
    Infatti, in alcuni casi, gli \textbf{algoritmi} si \textbf{comportano diversamente} in base alle \textbf{caratteristiche dell'input} e conoscere in anticipo tali caratteristiche permette di scegliere il miglior algoritmo per quella determinata situazione.

    \newpage
    \noindent
    Il \textbf{problema dell'ordinamento} è un buon esempio per mostrare questi concetti, proprio perché \textbf{comparendo in tanti contesti} e avendo \textbf{soluzioni diverse} è perfetto per scegliere l'implementazione migliore in base all'input.
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Problema dell'ordinamento (sorting)
        ]
        Dato un vettore di $n$ elementi, il problema dell'ordinamento prevede la \textbf{permutazione del vettore} per fare in modo che i suoi elementi compaiano in \textbf{ordine non decresente}.
    \end{tcolorbox}
    \noindent
    Se si volesse utilizzare un \textbf{approccio \textit{"demente"}}, si potrebbero generare tutte le possibili permutazioni fino a che non se ne trova una già ordinata, in questo caso:
    \begin{itemize}[leftmargin=1em]
        \item Per verificare che un vettore $A$ sia ordinato, basta un ciclo \texttt{for}, quindi richiede $O(n)$ tempo;
        \item Il numero di permutazioni possibili è $n!$.
    \end{itemize}
    Dunque, procedendo il questo modo si avrebbe una complessità $O(n\cdot n!)$, ovvero una \textbf{complessità superpolinomiale}. Per evitare ciò, l'approccio migliore è quello di utilizzare degli \textbf{algoritmi di ordinamento}, decisamente più adatti a questa tipologia di problema.

    \subsubsection{Selection Sort}
    \label{par:Selection Sort}
    Il selection sort è un semplice algoritmo polinomiale che è basato sulla proprietà che in una sequenza ordinata, il primo elemento ha valore minimo.
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Algoritmo selection sort
        ]
        In un \textbf{algoritmo selection sort} si cerca il minimo e si scambia tale elemento con quello nella prima posizione della \textbf{parte non ordinata del vettore}, riducendo il problema agli $n-1$ restanti valori. 
    \end{tcolorbox}
    \noindent
    Dato un input del tipo $A = \{7, 4, 2, 1, 8, 3, 5\}$ con $n=7$, l'algoritmo \texttt{selectionSort()} si comporta nel seguente modo:

    \vspace{-15pt} 
    \begin{figure}[h]
        \centering
        \vspace{-5pt}  % Riduce lo spazio sopra
        \subfloat[]{%
            \includegraphics[width=0.495\linewidth]{figures/tempo_e_modello_calcolo/img11.png}
        } 
        \hspace{0.1cm}
        \subfloat[]{%
            \includegraphics[width=0.40\linewidth]{figures/tempo_e_modello_calcolo/img12.png}
        }
    \end{figure}
    \FloatBarrier

    \begin{tcolorbox}
        [
            colback=green!10,  % Sfondo verde chiaro
            colframe=green!60!black,  % Bordo verde più acceso
            coltitle=black,  % Colore del testo del titolo
            fonttitle=\bfseries,  % Testo del titolo in grassetto
            title={\centering \textbf{Complessità del \texttt{selectionSort()}}},  % Titolo centrato 
            enhanced,  % Miglioramenti grafici
            attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
            boxed title style={colback=white, colframe=green!60!black, rounded corners},
            breakable
        ]
        In questo particolare algoritmo \textbf{non importa quale sia l'ordine iniziale dell'input} dato. Questo perché lo \textbf{spostamento di un valore} ha sempre \textbf{costo costante}.

        \vspace{8pt}
        L'algoritmo \texttt{selectionSort()} esegue un ciclo esterno che va da $i=1$ a $n-1$, e ad ogni iterazione, chiama la funzione \texttt{min()} su un sottoarray da $i$ a $n$.\\
        La funzione \texttt{min()} esegue un ciclo interno che fa $n-i$ confronti, quindi sempre meno confronti man mano che il vettore si riordina.\\
        Sapendo che la somma dei primi $k$ numeri naturali è $1+2+...+k=\frac{k(k+1)}{2}$ possiamo dire che: 

        \vspace{-20pt}
        \[
            \sum_{k=1}^{n-1} k = \sum_{i=1}^{n-1} (n-i) = \frac{n(n-1)}{2} = \frac{n^2}{2} - \frac{n}{2}
        \]
        Questo cresce come $n^2$, quindi la complessità è quadratica $O(n^2)$, anche se l'array è già ordinato, perché deve \textbf{comunque cercare il minimo} nel sottoarray, anche se è già al posto giusto.
    \end{tcolorbox}

    \subsubsection{Insertion sort}
    L'algoritmo \texttt{insertionSort()} è un'algoritmo efficiente per ordinare piccoli insiemi di elementi. Si basa sul principio di ordinamento di una mano di carte da gioco.

    \vspace{-2pt}
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Algoritmo insertion sort
        ]
        Per seguire l'analogia, si considerino le carte una per volta, ad esempio, da sinistra verso destra: ogni volta che viene considerata una nuova carta, si inserisce nella posizione giusta rispetto alle altre carte gia considerate e ordinate, traslando di una posizione verso destra tutte le carte maggiori.
    \end{tcolorbox}

    \noindent
    \begin{minipage}[t]{0.540\textwidth} 
        \includegraphics[width=\linewidth]{figures/tempo_e_modello_calcolo/img16.png}
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{177pt}{  
        \begin{minipage}[t]{0.437\textwidth}
            Immaginiamo di avere un input del tipo $A=\{2, 3, 1, 4, 7, 3\}$.\\
            L'\textbf{idea di base} è la seguente: se si prende solo il primo elemento $[2]$, in se per se è già ordinato, potrebbe anche non essere la sua posizione giusta, ma preso come sottovettore è ordinato.\\
            Vado poi a vedere il valore successivo $[3]$ e lo confronto con il valore $[2]$ (che è l'ultimo del vettore ordinato): $[3]>[2]$ quindi la parte iniziale del vettore è ordinata \{2, 3, ...\}.
        \end{minipage} 
    }

    \noindent
    Andando avanti si troverà $[1]$, più piccolo sia di $[2]$ che di $[3]$.
    L'elemento minore viene messo in una variabile temporantea (\texttt{temp}), mentre gli elementi della parte già ordinata del vettore vengono traslati (partendo dal più grande) uno ad uno verso destra di una posizione, sovrascrivendo l'elemento alla propria destra. A questo punto all'inizio del vettore si è creato uno spazio vuoto $[...]$ (dovuto alla traslazione della parte ordinata del vettore) su cui andrà inserita la variabile \texttt{temp} contenente l'elemento precedentemente sovrascritto, nonché il più piccolo elemento del vettore esplorato fino a quel momento.\\
    Ovviamente, nel caso in cui l'elemento da inserire vada posizionato nel mezzo del vettore ordinato, durante la traslazione dei singoli elementi ci si fermerebbe nel punto in cui \texttt{temp} sia maggiore dell'elemento \texttt{A[i]}. Ad esempio, si consideri un input del tipo $A=\{7, 4, 2, 1, 8, 3, 5\}$. 

    \vspace{-10pt}
    \begin{figure}[H]
        \centering
        \vspace{-5pt}  % Riduce lo spazio sopra
        \subfloat[]{%
            \includegraphics[width=0.41\linewidth]{figures/tempo_e_modello_calcolo/img13.png}
        } 
        \hspace{1cm}
        \subfloat[]{%
            \includegraphics[width=0.41\linewidth]{figures/tempo_e_modello_calcolo/img14.png}
        }
        \hspace{1cm}
        \subfloat[]{%
            \includegraphics[width=0.41\linewidth]{figures/tempo_e_modello_calcolo/img15.png}
        }
    \end{figure}
    \FloatBarrier

    \vspace{-10pt}
    \noindent
    Per la logica che sta dietro al \texttt{selection sort()}, anche se l'input iniziale è già ordinato, l'algoritmo andrà a cercare comunque il valore minimo e lo sovrascriverà nella prima posizione della parte non ordinata dell'array, quindi, come detto al capitolo (capitolo \ref{par:Selection Sort}), la complessità dell'algoritmo non dipende dall'input di ingresso.

    \vspace{8pt}
    \noindent
    Invece, a differenza del \texttt{selection sort()}, la \textbf{complessità} dell'\texttt{insertion sort()} dipende dalla \textbf{disposizione iniziale dei dati in ingresso} poiché, per come è strutturato l'algoritmo, man mano che si scorre l'array si andranno a posizionare i nuovi elementi nella posizione corretta rispetto a tutti gli altri.\\
    Proprio per questa caratteristica, la complessità dell'\texttt{insertion sort()} cambia a seconda del caso di studio (capitolo \ref{par:Valutazione del caso pessimo, medio e ottimo}):
    \begin{itemize}[leftmargin=1em]
        \item \textit{Complessità nel caso \textbf{pessimo}}: il caso peggiore si ha quando l'input $A$ è \textbf{ordinato alla rovescia}, ad esempio: $A = \{8, 7, 6, 5, 4, 3, 2, 1\}$.\\
        In questo caso ad ogni iterazione del ciclo \texttt{for}, si entrerebbe anche nel ciclo \texttt{while} più interno poiché la variabile \texttt{temp} andrebbe spostata in prima posizione, e ciò richiederebbe un numero di spostamenti pari a 
        \[
            \sum_{i=1}^{n-1} (n-i)
        \]
        \textbf{\textit{Complessità?}} Dunque la complessità sarebbe uguale a quella del \texttt{selection sort()} per la presenza dell'annidamento dei  due cicli $\rightarrow$ $O(n^2)$.

        \vspace{8pt}
        \item \textit{Complessità nel caso \textbf{ottimo}}: il caso migliore si ha quando l'input $A$ è una sequenza già ordinata, quindi $A = {1, 2, 3, 4, 5, 6, 7, 8}$\\
        In questo caso, non avverà mai che \texttt{A[j-1]} $[1]$ sia maggiore di \texttt{temp} $[2]$ e cosi via..., non permettendo al ciclo \texttt{while} di verificarsi.
        Rimane solo il ciclo esterno, che esegue operazioni di costo \textbf{costante}. \\
        \textbf{\textit{Complessità?}} In questo caso, la complessità per delle istruzioni costanti vale $O(n)$.
    \end{itemize}

    \subsubsection{Merge sort}
    L'algoritmo \texttt{MergeSort()} è basato sulla tecnica \textbf{divide et impera}.
    \begin{tcolorbox}[
        colback=yellow!20, 
        colframe=darkgray, 
        title=Algoritmo merge sort
        ]
        \begin{itemize}[leftmargin=1em]
            \item \textbf{Divide}: spezza il vettore di $n$ elementi in due sottovettori di $n/2$ elementi;
            \item \textbf{Impera}: chiama \texttt{MergeSort()} ricorsivamente sui due sottovettori;
            \item \textbf{Combina}: una volta ottenuti singoli valori, questi vengono riuniti (merge) in modo ordinato, fino a riottenere i due sottovettori iniziali ordinati.
        \end{itemize}
    \end{tcolorbox}

    \vspace{-45pt} 
    \begin{figure}[H]
        \centering
        \vspace{-5pt}  % Riduce lo spazio sopra
        \subfloat[Partizionamento dei dati]{%
            \includegraphics[width=0.47\linewidth]{figures/tempo_e_modello_calcolo/img17.png}
        } 
        \hspace{0.1cm}
        \subfloat[Fusione dei dati]{%
            \includegraphics[width=0.47\linewidth]{figures/tempo_e_modello_calcolo/img18.png}
        }
    \end{figure}
    \FloatBarrier

    \vspace{-10pt}
    \noindent
    \begin{minipage}[t]{0.500\textwidth} 
        \includegraphics[width=\linewidth]{figures/tempo_e_modello_calcolo/img20.png}
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{95pt}{  
        \begin{minipage}[t]{0.497\textwidth}
            La prima parte dell'algoritmo \texttt{mergeSort()} si occupa di effettuare le chiamate ricorsive per la suddivisione del vettore non ordinato fino ai singoli valori (come in figura \textit{d}).
            Prendiamo in considerazione il vettore: $A = [4, 3, 2, 1]$.\\
            Nella \textit{riga 2} viene calcolata la metà del vettore (se il vettore è dispari si andrà per eccesso).
        \end{minipage} 
    }
    In questo caso, il vettore viene diviso in parte sinistra $[4, 3]$ e parte destra $[2, 1]$.

    \vspace{8pt}
    \noindent
    \textbf{\textit{Prima ricorsione (riga 2)}}\\
    Una volta che il vettore è stato diviso in due parti, la prima istruzione ricorsiva (\textit{riga 3}) richiama la funzione \texttt{mergeSort(A, first, mid)} per poter lavorare sulla parte sinistra, ossia $[4,3]$.
    Dunque, la \textit{riga 2} viene rieseguita e il sottovettore viene ulteriormente suddiviso in:
    \begin{itemize}[leftmargin=1em]
        \item parte sinistra $[4]$;
        \item parte destra $[3]$.
    \end{itemize}
    Subito dopo, le istruzioni ricorsive vengono tentate nuovamente, ma:
    \begin{itemize}[leftmargin=1em]
        \item \texttt{mergeSort(A, first, mid)} non prosegue poiché il sottovettore ha un solo elemento $[4]$;
        \item anche, \texttt{mergeSort(A, mid+1, last)} non prosegue perché anche $[3]$ è un singolo elemento.
    \end{itemize}
    Raggiunto il caso base per entrambi i sottovettori, è possibile richiamare \texttt{merge()} per combinarli e ottenere il vettore ordinato $[3,4]$.

    \vspace{8pt}
    \noindent
    \textbf{\textit{Seconda ricorsione (riga 3)}}\\
    Terminata la ricorsione sulla parte sinistra del vettore iniziale, il controllo ritorna alla chiamata precedente, che ora può eseguire l’istruzione ricorsiva successiva (\textit{riga 4}) sulla parte destra, utilizzando \texttt{mergeSort(A, mid+1, last)}.\\
    Il procedimento è analogo al precedente: la \textit{riga 2} suddivide il sottovettore destro in $[2]$ e $[1]$, mentre le istruzioni ricorsive (\textit{righe 3} e \textit{4}) non proseguono perché entrambi i vettori hanno un solo elemento.
    Infine viene richiamata \texttt{merge()} per ordinare i due elementi e ottenere $[1,2]$.

    \vspace{8pt}
    \noindent
    \textbf{\textit{Merge finale (riga 4)}}\\
    Terminate entrambe le ricorsioni, significa che i due sottovettori originari sono ora ordinati. L’ultima istruzione rimasta della chiamata principale è dunque la \texttt{merge()} finale, che combina i due sottovettori ordinati per ottenere un unico vettore ordinato (come illustrato in figura \textit{e}). 

    \vspace{8pt}
    \noindent
    Nello specifico, una generica operazione di \texttt{merge()} funziona in questo modo:\\
    \begin{minipage}[t]{0.560\textwidth} 
        \includegraphics[width=\linewidth]{figures/tempo_e_modello_calcolo/img23.png}
        \includegraphics[width=\linewidth]{figures/tempo_e_modello_calcolo/img21.png}
        \includegraphics[width=\linewidth]{figures/tempo_e_modello_calcolo/img22.png}
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{18pt}{  
        \begin{minipage}[t]{0.417\textwidth}
            \textit{\textbf{N.B}}: \textit{first, last e mid} sono tali che $1 \leqslant first \leqslant mid \leqslant last \leqslant n$.

            \vspace{8pt}
            Bisogna specificare che il merge agisce su dei sottovettori già ordinati: infatti il primo \texttt{merge()} viene effettuato sui singoli elementi, e da quì, ogni volta che si effettua un \texttt{merge()} si avranno sempre dei sottovettori ordinati, $A[first...mid]$ e $A[id+1...last]$.

            \vspace{8pt}
            Per fondere le due metà ordinate, la procedura \texttt{merge()} si avvale di un vettore di appoggio $B$, utilizzato come parametro globale.\\
            Vengono qundi utilizzati tre indici $i, j$ e $k$ per scandire, rispettivamente, $A[first..mid]$, $A[mid+1...last]$ e $B[start...end]$. Ad ogni passo, sono
        \end{minipage} 
    }

    \vspace{3pt}
    \noindent
    confrontati gli elementi $A[i]$ e $A[j]$, il minore viene copiato in $B[k]$, e vengono incrementati di una posizione $k$ e l'indice dell'elemento che risulta minore. 

    \vspace{8pt}
    \noindent
    Il procedimento viene iterato fino a che una delle due metà è esaurita ($A[first..mid]$ oppure $A[mid+1...last]$). Non appena una delle due metà si svuota per prima, è possibile proseguire l'ordinamento in modi differenti:
    \begin{itemize}[leftmargin=1em]
        \item Se la \textbf{prima metà è stata esaurita per prima} ($i>mid$) gli eventuali elementi $A[j..end]$ della metà non scandita si trovano già nella posizione corretta per l'ordinamento.\\
        Dunque, non è necessario spostare gli elementi non scanditi in $A$ nel vettore di appoggio $B$, ma piuttosto, spostare tutti gli elementi già ordinati da $B$ ad $A$;
        \item Se invece \textbf{si svuota prima la seconda parte}, gli elementi non scanditi $A[i...mid]$ della prima metà vengono subito spostati nelle ultime posizioni $A[k...last]$ che competono loro nell'ordinamento finale. Infine, la posizione $B[first...k-1]$ è ricopiata in $A[first...k-1]$, ottenendo così $A[first...last]$.
    \end{itemize}
    
    \vspace{8pt}
    \noindent
    Il codice per il funzionamento del \texttt{merge()} è il seguente, illustrato in figura \ref{fig:figure67}.
    \begin{figure}[H]
        \centering
        \addtocounter{figure}{27}
        \caption{Pseudocodice della funzione \texttt{merge()}}
        \label{fig:figure67}
        \vspace{-10pt}  % Riduce lo spazio sopra
        \includegraphics[width=0.9\textwidth]{figures/tempo_e_modello_calcolo/img19.png}
        \vspace{-5pt}  % Riduce lo spazio sopra 
    \end{figure}
    \noindent
    Per capire quale sia la complessità di \texttt{mergeSort()} dobbiamo prima trovare separatamente la complessità di \texttt{merge()}.\\
    Nel \textbf{caso pessimo} ogni valore in $A$ deve essere trasferito in $B$, e questo accade quando rimangono tutti tranne un solo elemento della sottoparte destra di $A$. Quindi come illustrato

    \vspace{2pt}
    \noindent 
    \begin{minipage}[t]{0.560\textwidth} 
         \includegraphics[width=\textwidth]{figures/tempo_e_modello_calcolo/img24.png}
    \end{minipage}%
    \hspace{5pt} % Spazio tra immagine e testo
    \raisebox{66pt}{  
        \begin{minipage}[t]{0.417\textwidth}
            nell'immagine, in $A$ è rimasto un singolo valore che è già nella sua posizione corretta, gli altri $n-1$ valori sono stati trasferiti in $B$. A questo punto andranno tutti riportati in $A$, e  anche in 
        \end{minipage} 
    }

    \vspace{-2pt}
    \noindent
    questo caso l'operazione ha costo $n-1$. Possiamo quindi dire che la complessità di \texttt{merge()} è $O(n)$ perché il \textbf{numero di operazioni cresce in modo lineare} rispetto al \textbf{numero totale di elementi} nei due sottovettori.
    \begin{tcolorbox}
        [
            colback=green!10,  % Sfondo verde chiaro
            colframe=green!60!black,  % Bordo verde più acceso
            coltitle=black,  % Colore del testo del titolo
            fonttitle=\bfseries,  % Testo del titolo in grassetto
            title={\centering \textbf{Osservazione sulla complessità di \texttt{merge()}}},  % Titolo centrato 
            enhanced,  % Miglioramenti grafici
            attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
            boxed title style={colback=white, colframe=green!60!black, rounded corners},
            breakable
        ]
        Il fatto che la complessità di \texttt{merge()} sia $O(n)$ è anche intuibile dal momento che la funzione non contiene cicli annidati: il ciclo principale viene eseguito al massimo $n-1$ volte e ogni iterazione ha costo costante. Ne deriva quindi un costo complessivo lineare. 
    \end{tcolorbox}

    \vspace{8pt}
    \noindent
    A questo punto l'analisi della complessità si sposta sul capire quale sia la complessità dell'\textbf{intero algoritmo}.
    Quando analizziamo il \texttt{mergeSort()} vengono effettuate le seguenti operazioni:
    \begin{enumerate}[leftmargin=1.3em]
        \item Viene preso un array di dimensione $n$;
        \item Viene diviso in \textbf{due metà}: una di dimensione $n/2$ e l'altra di dimensione $n/2$;
        \item Si applica ricorsivamente il \texttt{mergeSort()} su entrambe le metà.
    \end{enumerate}
    Quindi per ordinare l'array completo:
    \begin{itemize}[leftmargin=1em]
        \item Per ordinare la prima metà $\rightarrow$ costo $T(n/2)$;
        \item Per ordinare la seconda metà $\rightarrow$ costo $T(n/2)$.
    \end{itemize}
    Sommando i termini si ottiene: $T(n)= T(n/2) + T(n/2) +$ \textit{costo del merge} $= T(n)= 2T(n/2) + O(n)$, dove:
    \begin{itemize}[leftmargin=1em]
        \item $2T(n/2)$ è il tempo per ordinare le due metà;
        \item $O(n)$ è il tempo per fonderle con \texttt{merge()}.
    \end{itemize}

    \vspace{8pt}
    \noindent
    Dopo aver ottenuto l'equazione del costo dell'algoritmo, per trovare la complessità possiamo approfittare del fatto che \texttt{mergeSort()} sia un algoritmo ricorsivo e utilizzare il \textbf{metodo dell'albero di ricorsione} visto al capitolo \ref{par:Metodo dell'albero di ricorsione (analisi per livelli)}.
    \begin{figure}[H]
        \centering
        \vspace{-10pt}  % Riduce lo spazio sopra
        \includegraphics[width=0.9\textwidth]{figures/tempo_e_modello_calcolo/img25.png}
        \vspace{-5pt}  % Riduce lo spazio sopra 
    \end{figure}
    \noindent
    Dunque, il \textbf{costo complessivo} di ciascun livello dell'albero è sempre $n$, perché il costo del \texttt{merge()} rimane costante per qualsiasi coppia di sottovettori.\\
    Invece, $2T(n/2)$ è il costo per la chiamata ricorsiva che genera $2$ sottovettori di dimensione $n/2$ ogni volta che viene richiamata fino ad ottenere i singoli valori.\\
    \textbf{Il numero di sottovettori cresce esponenzialmente} ($2^i$), ma allo stesso momento la loro dimensione cala esponenzialmente ($n/2^i$) e il costo totale di ogni \texttt{merge()} costante ($n$).
    Dunque, la ricorrenza ha complessità $O(n\;log\;n)$.
\end{document}