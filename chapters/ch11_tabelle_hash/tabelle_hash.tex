\documentclass[../../main_document/main.tex]{subfiles}

\begin{document}
\section{Hashing}
L'\textbf{hashing} è una \textbf{tecnica alternativa} agli alberi binari di ricerca (capitolo \ref{par:Alberi binari di ricerca (BST)}) o agli array associativi, utilizzata per realizzare i dizionari.

\vspace{8pt}
\noindent
A differenza dell'implementazione tramite alberi, nella quale si riusciva a mantenere la stessa complessità nei casi di \texttt{insert()}, \texttt{lookup()} e \texttt{remove()}, nel caso ideale, la cosa migliore sarebbe quella di \textbf{mantenere una complessità costante} per tutti i tipi di operazioni, che sia inoltre \textbf{inferiore} a quella delle strutture ad albero.\\
Questa implementazione ideale prende il nome di \textbf{tabelle di hash}.
\begin{figure}[H]
    \centering
    \vspace{-10pt}  % Riduce lo spazio sopra
    \includegraphics[width=0.95\textwidth]{hashing/img1.png}
    \vspace{-5pt}  % Riduce lo spazio sopra 
\end{figure}
\noindent
Per comprendere il funzionamento delle tabelle hash dobbiamo prendere in considerazione il concetto di \textbf{insieme universo \textit{U}}, ovvero un insieme di tutte le possibili chiavi, la cui grandezza varia arbitrariamente in base ai dati che si vogliono contenere.
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Idea di base
    ]
    Quello che si vuole fare è memorizzare tutti i dati dell'insieme \textbf{\textit{U}} in un vettore di dimensione ($m$) finita $T[0...m-1]$, ed avere un meccanismo per cui, data una chiave, trovare rapidamente la posizione in cui è memorizzata.
\end{tcolorbox}
\noindent
Le chiavi possono essere delle stringhe, degli oggetti o dei numeri, e il compito delle tabelle hash è quello di trasformarle in un indice all'interno di esse.
Per fare ciò viengono utilizzate le \textbf{funzioni hash}.
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Cos'è una funzione hash?
    ]
    Una \textbf{funzione hash} è una funzione $H$ che mappa ciascuna chiave $k$ appartenente all'insieme universo $U$ ($k \in U$) nell'indice $H(k)$ di un vettore $A$, destinato a contenere la coppia $(k,v)$. Viene definita come $H: U \rightarrow \{0,1,...,m-1\}$.
\end{tcolorbox}
\noindent
\begin{minipage}[t]{0.560\textwidth}
    \vspace{-25pt}
    \begin{figure}[H]
        \centering
        \addtocounter{figure}{10}
        \caption{Esempio di funzione hash}
        \label{fig:hash_example}
    \end{figure}

    \vspace{-20pt}
    \includegraphics[width=\textwidth]{hashing/img2.png}
\end{minipage}%
\hspace{5pt} % Spazio tra immagine e testo
\raisebox{2pt}{
    \begin{minipage}[t]{0.417\textwidth}
        Come si può vedere dall'immagine, viene presa una chiave (in questo caso una stringa) che verrà poi trasformata in qualche modo, tramite la funzione hash (che può essere anche una black box), in un indice.

        \vspace{8pt}
        A questo punto sorge un \textbf{problema}: l'insieme delle chiavi è potenzialmente infinito, ma non si vuole che sia lo stesso anche per la tabella hash, dal momento in cui si potrebbe non disporre
    \end{minipage}
}
\noindent
dello spazio in memoria necessario per qualunque coppia chiave-valore. Dunque, quello che succede è che avvengono delle \textbf{collisioni}.

\subsection{Tabelle ad accesso diretto}
Prima di affrontare il problema delle collisioni, è utile analizzare un \textbf{caso particolare} in cui esse possono essere \textbf{completamente evitate}: le \textbf{tabelle ad accesso diretto}.

\vspace{8pt}
\noindent
Questo approccio è applicabile solo quando l'insieme universo $U$ delle chiavi è limitato e di dimensione ridotta, tale da poter essere rappresentato direttamente in memoria senza \textbf{sprechi} eccessivi. Utilizzando un approccio del genere è possibile utilizzare un vettore $A$ della stessa dimensione dell'insieme $U$, quindi $m=|U|$, nel quale ogni chiave $k$ che appartiene all'insieme $U$ viene memorizzata direttamente nella posizione $A[k]$.\\
La funzione hash utilizzata è quindi la \textbf{funzione identità} $ h(k) = k$, in questo caso una \textbf{funzione hash perfetta}, come quella illustrata in figura \ref{fig:hash_example}, che garantisce l'esecuzione delle operazioni di \texttt{insert()}, \texttt{lookup()} e \texttt{remove()} in tempo $O(1)$ nel caso peggiore.\\
In questo modo ogni chiave verrebbe memorizzata in una posizione distinta della tabella.

\subsubsection{Funzioni hash perfette}
\label{par:Funzioni hash perfette}
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Funzioni hash perfette
    ]
    Una funzione hash $h$ si dice \textbf{perfetta} se è \textbf{iniettiva}, ovvero se non da origine a collisioni:

    \vspace{-15pt}
    \[
        \forall k_1, k_2 \in U: k_1\neq k_2 \Rightarrow H(k_1) \neq H(k_2)
    \]
\end{tcolorbox}
\noindent
Tuttavia, questo metodo presenta un \textbf{limite fondamentale}:\\
oltre al fatto che se l'insieme universo $U$ è molto grande, l'approccio non è praticabile, nel caso in cui il numero di chiavi memorizzate nel dizionario sia molto inferiore al massimo disponibile, quindi $m=|U|$, si incorrerebbe in uno \textbf{spreco di meoria} poiché molte posizioni del vettore verrebbero lasciate inutilizzate.\\
Per questo motivo, le \textbf{tabelle ad accesso diretto} sono utilizzabili solo in \textbf{contesti specifici} e rappresentano principalmente un modello teorico di riferimento per le tabelle hash.

\vspace{8pt}
\noindent
Per evitare inutili sprechi di memoria, la dimensione $m$ del vettore non deve essere determinata sulla base dell'intero universo $U$, ma piuttosto in funzione del \textbf{numero di chiavi attese}, ovvero la \textbf{quantità $k$ di elementi} che si prevede saranno \textbf{effettivamente presenti nel dizionario} in un determinato momento.
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Quando si verifica una collisione?
    ]
    Si verifica una \textbf{collisione} quando due chiavi distinte $k_1 \neq k_2$ vengono mappate dalla funzione hash sulla stessa posizione del vettore, ovvero quando $H(k_1)=H(k_2)$.
\end{tcolorbox}
\noindent
Le collisioni mettono quindi in luce due \textbf{aspetti fondamentali} nella progettazione di una tabella hash:
\begin{itemize}[leftmargin=1em]
    \item La \textbf{scelta della funzione hash} è cruciale, infatti una funzione mal progettata può distribuire le chiavi in modo sbilanciato, causando una concentrazione eccessiva in alcune posizioni del vettore, lasciando quasi del tutto inutilizzate altre.
    \item È essenziale progettare dei \textbf{meccanismi} efficienti per la \textbf{gestione delle collisioni}, poiché
\end{itemize}

\vspace{3pt}
\noindent
\begin{minipage}[t]{0.610\textwidth}
    \includegraphics[width=\textwidth]{hashing/img3.png}
\end{minipage}%
\hspace{5pt} % Spazio tra immagine e testo
\raisebox{170pt}{
    \begin{minipage}[t]{0.367\textwidth}
        anche scegliendo una buona funzione di hash, quando il numero di chiavi possibili supera il numero di posizioni disponibili nella tabella, le collisioni sono inevitabili.\\
        Questi meccanismi permettono quindi di \textbf{garantire il corretto funzionamento} delle operazioni di inserimento, ricerca e cancellazione.
    \end{minipage}
}

\subsection{Minimizzare le collisoni}
\label{par:ch_1.2}
Se \textbf{non è possibile evitare} le collisioni, si cerca di \textbf{minimizzarne il numero}.\\
La \textbf{qualità di una funzione hash} dipende in modo cruciale dalla \textbf{sua capacità} di distribuire le chiavi dell'universo $U$ negli indici $[0...m-1]$ della tabella hash \textbf{in modo uniforme}.\\
Una distribuzione sbilanciata porta a un aumento del numero di collisioni in alcune celle, con conseguente peggioramento delle prestazioni del dizionario.

\vspace{8pt}
\noindent
Uno dei criteri più diffusi per valutare la qualità di una funzione hash è l'\textbf{uniformità semplice}:
\begin{itemize}[leftmargin=1em]
    \item Sia $P(k)$ la probabilità che una qualunque chiave $k$ sia inserita nel dizionario;
    \item Sia $Q(i)$ la probabilità che una qualunque chiave finisca nella cella $i$-esima della tabella.
\end{itemize}
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Uniformità semplice
    ]
    Una funzione hash $h$ gode di \textbf{uniformità semplice} se, per ogni posizione $i$ della tabella, la probabilità che una chiave $k$ venga mappata in $i$ è uguale a $1/m$, quindi $Q(i)=1/m$.
\end{tcolorbox}
Quindi, l'evento che interessa è: \textit{"la chiave $k_n$ scelta finisce nella cella i"}, e ciò accade se la funzione hash, per qualche motivo, mappa una determinata chiave per quella cella: $h(k_1)=i$, oppure $h(k_2)=i$, e così via... definendo eventi tra loro mutualmente esclusivi.

\vspace{-10pt}
\[
    Q(i) = \sum_{\substack{k \in U: h(k) = i}} P(k)
\]
Quando un evento può accadere tramite alternative mutualmente esclusive, la probabilità totale è la somma delle probabilità alternative.\\
Proprio per questo motivo ottengo $Q(i)$ sommando le probabilità che le chiavi $k_n$ hanno di finire in $i$: se questa poi risulta uguale a $1/m$ la funzione hash gode di uniformità semplice.
\begin{tcolorbox}
    [
        colback=green!10,  % Sfondo verde chiaro
        colframe=green!60!black,  % Bordo verde più acceso
        coltitle=black,  % Colore del testo del titolo
        fonttitle=\bfseries,  % Testo del titolo in grassetto
        title={\centering \textbf{\textit{Problema fondamentale}}},  % Titolo centrato 
        enhanced,  % Miglioramenti grafici
        attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
        boxed title style={colback=white, colframe=green!60!black, rounded corners},
        breakable
    ]
    Per poter ottenere una \textbf{funzione hash con uniformità semplice}, la \textbf{distribuzione delle probabilità} $P$ deve essere \textbf{nota}.\\
    Ad esempio, si supponga di avere $m=10$ celle nella tabella.
    \begin{itemize}[leftmargin=1em]
        \item $90\%$ delle chiavi che iniziano con \textit{"A"};
        \item $10\%$ delle chiavi che iniziano con \textit{"Z"}.
    \end{itemize}
    Per costruire una funzione hash con uniformità semplice bisognerebbe fare in modo che le celle che iniziano con \textit{"A"} occupino il $90\%$ delle celle ($0...8$), mentre le chiavi che iniziano con \textit{"Z"} occupino il $10\%$ delle celle (cella $9$) in modo che la probabilità che una chiave cada nelle celle $0...8$ sia dello $0.9$ e la probabilità che cada nella cella $9$ sia dello $0.1$.

    \vspace{8pt}
    \noindent
    Nella realtà però non sappiamo quali chiavi verranno inserite né con quale frequenza compariranno, quindi \textbf{non è possibile costruire una funzione hash perfettamente uniforme}.
    In sostanza la distribuzione esatta $P(k)$ non può essere nota e si va ad utilizzare tecniche \textbf{euristiche}.
\end{tcolorbox}
\noindent
Le tecniche euristiche sono delle funzioni hash che usano \textbf{formule matematiche} per distribuire bene le chiavi anche se non si conosce $P(k)$, sperando che nella pratica funzionino bene.

\subsection{Come realizzare una funzione hash}
Dal momento che per utilizzare le tecniche euristiche \textbf{si ha bisogno di numeri}, si presenta la necessità di \textbf{codificare le chiavi} in numeri naturali. Dunque, se la chiave non è un numero (ad esempio una stringa "ciao") bisogna prima convertirla.
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Assunzione
    ]
    Si assume che le chiavi possano essere tradotte in valori \textbf{numerici non negativi}, eventualmente interpretando la loro rappresentazione in memoria come un numero.
\end{tcolorbox}
\noindent
\textbf{\textit{Esempio: trasformazione di stringhe}}\\
Consideriamo una chiave $k$ costituita da una stringa di caratteri, la trasformazione in intero avviene seguendo dei passaggi logici:
\begin{enumerate}[leftmargin=1.3em]
    \item $ord(c) \rightarrow$ \textbf{Codifica dei caratteri}: Si prende il valore ordinale binario del carattere $c$ secondo una codifica standard (ad esempio ASCII);
    \item $bin(k) \rightarrow$ \textbf{Rappresentazione binaria}: si concatenano i valori binari dei singoli caratteri che compongono la chiave $k$.
    \item $int(b) \rightarrow$ \textbf{Interpretazione intera}: la sequenza di bit risultante viene interpretata come un unico grande numero intero.
\end{enumerate}
\begin{lstlisting}[style=mystyle, language=C, , escapeinside={(*@}{@*)}]
Utilizzando una codifica ASCII a 8 bit, e concatenando i risultati di
ogni lettera, si ottiene un numero a 24 bit
bin("DOG") = ord("D")  ord("O")  ord("G")
           = 01000100  01001111  01000111
int("DOG") =  (*@$68\cdot256^2$@*)  +  (*@$79\cdot256$@*) +   (*@$71$@*)    = (*@$ 4.476.743$@*) 
\end{lstlisting}
Come detto alla fine del capitolo \ref{par:ch_1.2}, le chiavi vanno ben distribuite proprio perché si ha il problema che il numero ottenuto è solitamente molto grande (nell'esempio precedente $> 4$ milioni), e la tabella hash non ha 4 milioni di righe, magari solo $m=100$.

\vspace{8pt}
\noindent
I metodi che seguiranno sono esattamente quelle tecniche euristiche che utilizzano formule matematiche progettate per \textbf{distribuire} (o \textit{"sparpagliare"}) uniformemente questi grandi numeri all'interno delle poche celle disponibili.

\subsubsection{Metodo dell'estrazione}
\label{par:Metodo dell'estrazione}
Il metodo dell'estrazione è uno dei più semplici ed efficienti per definire una funzione hash su chiavi binarie.
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Come funziona?
    ]
    \begin{itemize}[leftmargin=1em]
        \item Si assume che la \textbf{dimensione della tabella} sia una \textbf{potenza di due}, ovvero $m=2^p$;
        \item Si seleziona un \textbf{blocco di $p$ bit} dalla rappresentazione binaria della chiave;
        \item L'indice hash è ottenuto \textbf{convertendo questi bit in un numero} intero.
    \end{itemize}
\end{tcolorbox}
\noindent
\textbf{\textit{Esempi di utilizzo}}\\
Si sceglie una tabella con $m=2^p=2^{16}=65536$ celle.\\ Per indirizzarle tutte, \textbf{necessiteranno} di $p=16$ bit estratti dalla chiave, ad esempio:
\begin{itemize}[leftmargin=1em]
    \item Si può scegliere il \textbf{blocco dei $16$ meno significatvi}
\end{itemize}
\begin{lstlisting}[style=mystyle, language=C, , escapeinside={(*@}{@*)}]
bin("Alberto") =  01000001 01101100 01100010 01100101 01110010 (*@\textcolor{red}{01110100}@*)
                  (*@\textcolor{red}{01101111}@*)
bin("Roberto") =  01010010 01101111 01100010 01100101 01110010 (*@\textcolor{red}{01110100}@*)
                  (*@\textcolor{red}{01101111}@*)
H("Alberto") = int(01110100 01101111) = 29.807
H("Roberto") = int(01110100 01101111) = 29.807
\end{lstlisting}
\begin{itemize}[leftmargin=1em]
    \item Oppure si prendono $16$ bit partendo da una \textbf{posizione casuale interna}
\end{itemize}
\begin{lstlisting}[style=mystyle, language=C, , escapeinside={(*@}{@*)}]
bin("Alberto") =  0100(*@\textcolor{red}{0001 01101100 0110}@*)0010 01100101 01110010 01110100
                  01101111
bin("Alessio") =  0100(*@\textcolor{red}{0001 01101100 0110}@*)0101 01110011 01110011 01101001
                  01101111
H("Alberto") = int(00010110 11000110) = 5.830
H("Alessio") = int(00010110 11000110) = 5.830
\end{lstlisting}

\vspace{8pt}
\noindent
Come si può vedere dagli esempi, nonostante questa metodologia sia semplice ed efficiente, è \textbf{estremamente sensibile} alla scelta dei \textbf{bit selezionati per la chiave}, infatti, variazioni minime delle chiavi come anagrammi o suffissi simili produrranno \textbf{collisioni frequenti}.\\
Anche selezionare bit da altre parti della chiave può risultare inefficace, specialmente se le chiavi condividono prefissi o segmenti centrali comuni.\\
Proprio per questo motivo, \textbf{se non si conosce la distribuzione dei dati, questo approccio è sconsigliato}, in quanto scarta completamente l'informazione contenuta nei bit non selezionati.

\subsubsection{Metodo dello XOR}
\label{par:Metodo dello XOR}
Il metodo dello XOR nasce per risolvere il difetto del metodo dell'estrazione, nel quale, se prendi solo alcuni bit, \textbf{ignori completamente i primi}.\\
Quindi, se cambia un bit all'inzio della chiave, l'hash non cambia, mentre con lo XOR si vuole che \textbf{tutti i bit partecipino al calcolo dell'indice}.
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Come funziona?
    ]
    \begin{itemize}[leftmargin=1em]
        \item Anche in questo caso si assume che la \textbf{dimensione della tabella} sia una \textbf{potenza di due}, ovvero $m=2^p$;
        \item Si suddivide la rappresentazione binaria della chiave $k$ in $q$ sotto-blocchi, ciascuno di lunghezza pari a $p$ bit (la dimensione dell'indirizzo della tabella);
        \item L'indice hash $h(k)$ è ottenuto effettuando lo XOR progressivo tra tutti i blocchi e \textbf{convertendo la somma finale in un numero} intero.
    \end{itemize}
\end{tcolorbox}
\noindent
\textbf{\textit{Esempio}}: si immagini che la chiave sia una striscia di carta lunga (tanti bit) e che la si voglia ridurre a un quadratino piccolo (l'indice $p$).
Invece di tagliare un pezzo e buttare il resto (estrazione), si piega la striscia su se stessa sovrapponendo i bit.


\vspace{8pt}
\noindent
\textbf{\textit{Esempio di utilizzo}}\\
Utilizziamo sempre una tabella con $m=2^p=2^{16}=65536$ celle, $16$ bit di indirizzamento.\\
In questo caso, dovendo dividere la chiave in sotto-blocchi da $16$ bit, risultano 5 gruppi, uno dei quali viene riempito con $8$ zeri di \textit{"padding"}. Utilizzando il metodo XOR è come se facessimo tante addizioni in colonna per le quali non si considera il riporto.

\vspace{-5pt}
\noindent
\begin{minipage}[t]{0.487\textwidth}
    \begin{lstlisting}[style=mystyle, language=C]
bin("montresor") =
01101101 01101111 (*@$\bigoplus$@*)
01101110 01110100 (*@$\bigoplus$@*)
01110010 01100101 (*@$\bigoplus$@*)
01110011 01101111 (*@$\bigoplus$@*)
01110010 (*@\textcolor{blue}{00000000}@*)

H("montresor") =
int(01110000 00010001) = 28.689
    \end{lstlisting}
\end{minipage}%
\hspace{6pt} % Spazio tra immagine e testo
\begin{minipage}[t]{0.487\textwidth}
    \begin{lstlisting}[style=mystyle, language=C]
bin("sontremor") =
01110011 01101111 (*@$\bigoplus$@*)
01101110 01110100 (*@$\bigoplus$@*)
01110010 01100101 (*@$\bigoplus$@*)
01101101 01101111 (*@$\bigoplus$@*)
01110010 (*@\textcolor{blue}{00000000}@*)

H("sontremor") =
int(01110000 00010001) = 28.689
    \end{lstlisting}
\end{minipage}

\vspace{8pt}
\noindent
Nonostante questo approccio permetta di utilizzare ogni singolo bit della chiave per influenzare il risultato finale, presenta alcune problematiche:
\begin{itemize}[leftmargin=1em]
    \item \textbf{Vulnerabilità agli anagrammi}: due chiavi composte dagli stessi caratteri in ordine diverso (come nell'esempio sopra illustrato) possono generare lo stesso indice hash, e di conseguenza collisioni;
    \item L'\textbf{efficacia} dipende fortemente dalla suddivisione in blocchi e dall'eventuale padding applicato.
\end{itemize}

\subsubsection{Metodo della divisione}
\label{par:Metodo della divisione}
I metodi basati sulla manipolazione dei bit visti ai capitoli \ref{par:Metodo dell'estrazione} e \ref{par:Metodo dello XOR} soffrono di problemi legati alla regolarità dei dati (ad esempio, suffissi identici) o alla commutatività (anagrammi).\\
Questo perché, caratteri uguali in chiavi differenti, vengono rappresentati con la stessa codifica ASCII a $8$ bit.\\
Il \textbf{metodo della divisione} cambia approccio, utilizzando una \textbf{logica aritmetica} al posto di una logica basata sui bit. Viene infatti utilizzato un sistema posizionale (come le unità, decine e centinaia), dove i caratteri più a sinistra valgono di più, ad esempio:
\begin{lstlisting}[style=mystyle, language=C, , escapeinside={(*@}{@*)}]
"AB"=ord("A")(*@$\cdot256^1$@*) + ord("B")(*@$\cdot256^0$@*)
"BA"=ord("B")(*@$\cdot256^1$@*) + ord("A")(*@$\cdot256^0$@*)

\end{lstlisting}
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Come funziona?
    ]
    Utilizzando la logica aritmetica si converte quindi la chiave in un \textbf{intero}, che grazie al sistema posizionale è \textbf{sempre diverso} (evitando così anagrammi), di cui si calcola il \textbf{resto della divisione per $m$}: il resto della divisione per $m$ è \textbf{sempre un numero compreso tra $0$ e $m-1$}.\\
    In questo modo è possibile indirizzare correttamente tutte le celle della tabella hash senza \textbf{\textit{"uscire dai bordi"}}.
\end{tcolorbox}
\begin{tcolorbox}
    [
        colback=green!10,  % Sfondo verde chiaro
        colframe=green!60!black,  % Bordo verde più acceso
        coltitle=black,  % Colore del testo del titolo
        fonttitle=\bfseries,  % Testo del titolo in grassetto
        title={\centering \textbf{\textit{La scelta del numero di celle (m)}}},  % Titolo centrato 
        enhanced,  % Miglioramenti grafici
        attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
        boxed title style={colback=white, colframe=green!60!black, rounded corners},
        breakable
    ]
    La scelta di $m$ determina la \textbf{qualità della distribuzione}: è necessario che sia \textbf{un numero dispari}, preferibilmente un \textbf{numero primo} non troppo vicino a una potenza di due.

    \vspace{8pt}
    \noindent
    Le chiavi reali spesso presentano dei pattern o regolarità (ad esempio, indirizzi di memoria che sono multipli di 4 o 8).
    Se $m$ avesse un divisore in comune con il "passo" o il pattern delle chiavi, la funzione hash mapperebbe le chiavi solo su un sottoinsieme delle celle disponibili, lasciandone molte vuote e causando collisioni.
    Un numero primo non possiede divisori (a parte 1 e se stesso), minimizzando la probabilità di interazione con i pattern dei dati e garantendo una distribuzione più uniforme ("sparpagliamento") su tutta la tabella.
\end{tcolorbox}
\noindent
\textbf{\textit{Esempio di utilizzo}}\\
Si sceglie un numero di celle secondo le specifiche descritte prima, ad esempio $m=383$
\begin{lstlisting}[style=mystyle, language=C, , escapeinside={(*@}{@*)}]
H("Alberto")  = 18.415.043.350.787.183    mod 383 = 221
H("Alessio")  = 18.415.056.470.632.815    mod 383 = 77
H("Cristian") = 4.860.062.892.481.405.294 mod 383 = 130
\end{lstlisting}
Dunque, il metodo della divisione è facile da imlementare ed efficace \textbf{solo se $m$ viene scelto con cura}, altrimenti possono verificarsi le seguenti problematiche:
\begin{itemize}[leftmargin=1em]
    \item Se si sceglie un numero di celle per la tabella hash pari a $m=2^p$, l'operazione modulo della chiave considera solo gli ultimi $p$ bit per la creazione dell'indice.\\
          In questo modo viene buttata via parte dell'informazione della chiave che poteva essere utilizzata per la creazione del suo indice all'interno della tabella hash, "regredendo" così al metodo dell'estrazione (capitolo \ref{par:Metodo dell'estrazione});
    \item Se invece si sceglie un numero di celle pari a $m=2^p-1$, bisogna fare attenzione che la \textbf{base di rappresentazione dei dati} (es. $256$) divisa per $m$ \textbf{non dia resto 1}. Questo perché verrebbe a mancare il peso conferito a ciascun carattere tramite il sistema posizionale, facendo diventare la funzione hash una semplice somma, incapace di distinguere gli anagrammi.

          \vspace{8pt}
          \noindent
          \textbf{\textit{Esempio pratico (in base 10)}}\\
          Immaginamo che $m = 9$, con due numeri anagrammi: 12 e 21.\\
          Calcoliamo l'indice della tabella hash (il resto della divisione per 9):
          \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{1}\rule{0.6ex}{0.6ex}}]
              \item $H(12)$: Normalmente è $1 \cdot 10 + 2$, ma col modulo $9$, il $10$ diventa un $1$.
                    Dunque: $1 \cdot 1 + 2 = 3$.
              \item $H(21)$: Normalmente è $2 \cdot 10 + 1$, ma col modulo $9$, il $10$ diventa un $1$.
                    Dunque: $2 \cdot 1 + 1 = 3$.
          \end{itemize}
          Come si può vedere, entrambe le chiavi vengono mappate con indice $3$, creando collisione.
\end{itemize}

\subsubsection{Metodo della moltiplicazione (Knuth)}
A differenza del metodo della divisione (capitolo \ref{par:Metodo della divisione}), nel quale ci si affidava alla scelta di un $m$ primo per "rompere" i pattern delle chiavi, \textbf{il metodo della moltiplicazione} utilizza una costante $C$ per mescolare i bit. Questo permette di ottenere indici ben distribuiti pur scegliendo un valore di $m$ comodo per il calcolatore (ad esempio una potenza di $2$).
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Come funziona?
    ]
    Il processo avviene in \textbf{due passaggi}:
    \begin{itemize}[leftmargin=1em]
        \item \textbf{\textit{Mescolamento}}: si moltiplica il valore numerico associato alla chiave $k$ per una costante $C$ (spesso \textbf{irrazionale}) compresa tra $0$ e $1$, e si estrae la parte frazionaria (decimale) del risultato. Questa operazione "distrugge" i pattern della chiave originale;
        \item \textbf{\textit{Mappatura}}: Si moltiplica questa parte frazionaria per $m$ (il numero di celle) così da ottenere un indice valido tra $0$ ed $m-1$.
    \end{itemize}
\end{tcolorbox}
\noindent
La formula che esprime questi passaggi è la seguente: $ h(k) = \lfloor m (k C \mod 1) \rfloor $
\begin{tcolorbox}
    [
        colback=green!10,  % Sfondo verde chiaro
        colframe=green!60!black,  % Bordo verde più acceso
        coltitle=black,  % Colore del testo del titolo
        fonttitle=\bfseries,  % Testo del titolo in grassetto
        title={\centering \textbf{\textit{Perché conviene che $C$ sia irrazionale?}}},  % Titolo centrato 
        enhanced,  % Miglioramenti grafici
        attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
        boxed title style={colback=white, colframe=green!60!black, rounded corners},
        breakable
    ]
    Un numero razionale semplice (come ad esempio $0.5 = 1/2$) ha una rappresentazione binaria finita e regolare. Moltiplicare per esso equivale spesso a un semplice scorrimento di bit (shift), con il rischio di estrarre nuovamente pattern prevedibili.\\
    Dunque è preferibile che $C$ sia un \textbf{numero irrazionale}, cioè un numero non esprimibile tramite un rapporto di due numeri interi che ha una \textbf{rappresentazione decimale illimitata} (dopo la virgola le cifre continuano all'infinito) e \textbf{non periodica} (non formano una sequenza ripetitiva).

    \vspace{8pt}
    \noindent
    Nello specifico \textit{Knuth} suggerì il valore $C = (\sqrt{5}-1)/2$, poiché presenta delle caratteristiche matematiche interessanti che permettono una distribuzione più uniforme ("spapagliata"), minimizzando le collisioni.
\end{tcolorbox}
\noindent
\textbf{\textit{Esempio di utilizzo}}\\
Sia $m= 2^{16}=65536$ celle e $C = (\sqrt{5}-1)/2 \thickapprox 0.6180339887$.\\
Se moltiplico $C\cdot k$, dove $k$ è il valore numerico associato a ciascuna chiave dopo la codifica ASCII e la trasformazione in intero utilizzando il sistema posizionale, e estraggo la parte decimale, ottengo una parte decimale che risulterà distribuita in modo \textbf{pseudo-casuale}.\\
Dopodiché moltiplico la parte decimale per $m$ ottenendo un indice valido tra $0$ e $m-1$.
\begin{lstlisting}[style=mystyle, language=C, , escapeinside={(*@}{@*)}]
H("Alberto")  = 65.536 (*@$\cdot$@*) 0.78732161432 = 51.598
H("Alessio")  = 65.536 (*@$\cdot$@*) 0.51516739168 = 33.762
H("Cristian") = 65.536 (*@$\cdot$@*) 0.72143641000 = 47.280
\end{lstlisting}
A questo punto è possibile effettuare alcune osservazioni:
\begin{itemize}[leftmargin=1em]
    \item il metodo della moltiplicazione funziona per qualsiasi valore di $m$, ma è \textbf{particolarmente efficiente} se $m=2^p$;
    \item Il \textbf{risultato dipende fortemente dal valore di $C$}, infatti come detto prima valori irrazionali sono preferibili per garantire una buona distribuzione;
    \item È \textbf{indipendente da particolarità delle chiavi} (prefisi, suffissi).
\end{itemize}

\vspace{16pt}
\noindent
A differenza di come è stato spiegato a livello teorico, a \textbf{livello pratico} per un computer fare calcoli con la virgola rappresenta un \textbf{problema} che causa \textbf{lentezza} e \textbf{minor precisione}.\\
Dunque, per utilizzare questo metodo, un calcolatore ha la necessità di eseguire lo stesso calcolo utilizzando \textbf{solo aritmetica intera}, e per farlo in modo performante sfrutta la \textbf{dimensione delle parole del processore}.

\vspace{8pt}
\noindent
Una CPU ha dei contenitori fissi (i registri) la cui dimensione può essere espressa con $w$, che solitamente nei calcolatori moderni equivale a $64$ bit. Usando un $w$ più piccolo ($<64$) spreche-\\
\begin{minipage}[t]{0.613\textwidth}
    \includegraphics[width=\textwidth]{hashing/img4.png}
\end{minipage}%
\hspace{5pt} % Spazio tra immagine e testo
\raisebox{106pt}{
    \begin{minipage}[t]{0.364\textwidth}
        remmo spazio nei contenitori (bit inutilizzati), mentre utilizzando un $w$ più grande ($>64$) avremmo bisogno di due contenitori e di calcoli più complessi.

        \vspace{8pt}
        Lavorando in questo modo, l'idea è quella di sostituire la costante
    \end{minipage}
}

\vspace{-3pt}
\noindent
reale $C$ con una \textbf{costante intera} $S$, che contiene la moltiplicazione tra $C$ ($0.618..$) e $2^{64}$ in modo tale da spostare la virgola di $64$ posizioni verso destra, ma siccome il registro del computer ha solo 64 posti tutto quello che "avanza" ancora dopo la virgola cade nel vuoto e viene perso. In questo modo la parte decimale (dopo la virgola) sparisce e all'interno di $S$ rimane solo un numero intero gigantesco che "riempie" perfettamente la parola in memoria.

\vspace{8pt}
\noindent
Come fatto prima a livello teorico, ora è necessario moltiplicare la costante $S$ (intero) per $k$ (anch'esso un intero rappresentativo del valore della chiave di grandezza $w=64$ bit) in modo da ottenere il numero con la parte \textbf{decimale pseudo-casuale}.\\
Quando la CPU moltiplica due numeri interi a $w$ bit viene prodotto un risultato \textbf{sempre grande il doppio} ($2w$ bit), e il processore salva il risultato in due registri separati automaticamente:
\begin{itemize}[leftmargin=1em]
    \item Registro Alto ($r_1$): che contiene i primi $w$ bit, che rappresentano la parte intera;
    \item Registro Basso ($r_0$): che contiene gli ultimi $w$ bit, che rappresentano la parte frazionaria.
\end{itemize}

\vspace{8pt}
\noindent
Di queste due parti ci interessa solo il registro basso ($r_0$), che rappresenta la \textbf{parte frazionaria pseudo-casuale}. Per ottenere l'indice finale tra $0$ e $m-1$ (assumendo $m=2^p$), non serve eseguire un'altra moltiplicazione: è sufficiente estrarre i $p$ bit più significativi di $r_0$. Questo equivale matematicamente a moltiplicare per $m$ e troncare, ma a livello hardware è un semplice spostamento di bit (shift), istantaneo per la CPU.

\subsection{Gestione delle collisioni}
Come abbiamo già detto al capitolo \ref{par:Funzioni hash perfette}, quando due chiavi vengono mappate dalla funzione hash nella stessa posizione della tabella, si verifica una \textbf{collisione}.
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Idea generale per la gestione delle collisioni
    ]
    \begin{itemize}[leftmargin=1em]
        \item \textbf{\textit{Inserimento}}: se la posizione calcolata tramite la funzione hash risulta già occupata, è necessario trovare una \textbf{posizione alternativa} in cui memorizzare la chiave.
        \item \textbf{\textit{Ricerca}}: se durante la ricerca di una chiave, essa non si trova nella posizione attesa, bisogna \textbf{cercarla nelle posizoni alternative}, secondo la \textbf{strategia adottata} in fase di \textbf{inserimento}.
    \end{itemize}
\end{tcolorbox}
\noindent
\textbf{\textit{Esempio con analogia}}
\begin{itemize}[leftmargin=1em]
    \item \textbf{Inserimento}: ho il biglietto per il posto auto numero $5$, ma arrivo ed è occupato. Seguendo la regola del parcheggio, provo il posto successivo finché non ne trovo uno libero, ad esempio, $6$ occupato e $7$ libero;
    \item \textbf{Ricerca}: quando torno a riprendere l'auto il biglietto dice ancora $5$, ma a quel parcheggio non c'è la mia auto. Allora devo agire \textbf{analogamente} all'inserimento, quindi se so che il $5$ era occupato controllo prima il $6$ e poi il $7$.
\end{itemize}

\vspace{8pt}
\noindent
Dato che le collisioni sono inevitabili, soprattutto quando l'universo delle chiavi è molto più ampio della dimensione della tabella, è fondamentale disporre di un \textbf{meccanismo per gestirle in modo efficiente}.\\
Le posizioni alternative possono essere trovate all'\textbf{interno della tabella} o all'\textbf{esterno della tabella}, ciò evidenzia \textbf{due possibili approcci} per la gestione delle collisoni:
\begin{itemize}[leftmargin=1em]
    \item Le posizioni alternative \textbf{esterne} alla tabella prendono il nome di \textbf{liste di trabocco};
    \item Le posizioni alternative \textbf{interne} alla tabella prendono il nome di \textbf{indirizzamento aperto};
\end{itemize}

\vspace{8pt}
\noindent
A volte può succedere che quando si va a cercare una chiave la quale non si trova nel posto giusto, poi la si va a cercare in posti alternativi, e se non si trova, la si cerca ancora in altri posti alternativi finché:
\begin{itemize}[leftmargin=1em]
    \item Si trova la chiave;
    \item Si trova una \textbf{cella vuota}. Se si trova un buco significa che la chiave non c'é (perché se ci fosse stata sarebbe dovuta essere li o dopo).
\end{itemize}
In una tabella hash ben progettata, dove le chiavi sono ben "sparpagliate", si calcola l'hash, si va alla cella e si trova il dato. Ci si trova quindi nel caso medio, dove il costo è rappresentato da $O(1)$ e non importa se gli elementi sono $10$ o $10$ milioni, proprio perché l'accesso al dato è immediato.\\
Invece, in alcuni casi, ad esempio in presenza di molte collisioni o di una funzione hash mal progettata, nel caso medio il tempo può degradare fino a $O(n)$.

\subsubsection{Liste di trabocco (concatenamento o chaining)}
\label{par:liste_trabocco}
Le \textbf{liste di trabocco} rappresentano un approccio per la gestione delle collisioni che si basa sull'utilizzo di \textbf{liste monodirezionali}.
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Idea generale
    ]
    Ogni indice (slot) della tabella hash non contiene direttamente una chiave, ma un \textbf{puntatore alla testa di una struttura dinamica} (lista monodirezionale-vettore dinamico), in cui vengono memorizzate tutte le chiavi che \textbf{condividono lo stesso indice hash}.
\end{tcolorbox}
\noindent
Come struttura dinamica da utilizzare sono sufficienti le liste monodirezionali poiché o si trova o non si trova la chiave durante le operazioni di \texttt{insert()}, \texttt{lookup()}, \texttt{remove()}.\\ Facendo riferimento alla figura \ref{fig:chaining}, nel momento in cui vengono inserite due chiavi nell'indice $2$, tre nell'indice $5$, e altre due nell'indice $7$, esse sono aggiunte ad una lista (in corrispondenza dell'indice) che cresce in modo arbitrario.\\
Dunque, le operazioni effettuate sulle liste utilizzano la seguente logica:\\
\begin{minipage}[H]{0.463\textwidth}

    \vspace{-10pt}
    \begin{figure}[H]
        \centering
        \addtocounter{figure}{2}
        \caption{liste di trabocco}
        \label{fig:chaining}
    \end{figure}

    \vspace{-20pt}
    \includegraphics[width=\textwidth]{hashing/img5.png}
\end{minipage}%
\hspace{5pt} % Spazio tra immagine e testo
\raisebox{104pt}{
    \begin{minipage}[t]{0.514\textwidth}
        \begin{itemize}[leftmargin=1em]
            \item \textbf{\texttt{insert()} in coda}: viene utilizzato se devo inserire una chiave e verificare che questa non sia già stata inserita, devo scorrere tutta la lista. Se la chiave che sto inserendo è già presente mi fermo e sovrascrivo il valore, altrimenti arrivo in fondo, aggiungo l'elemento alla lista e lo memorizzo;

                  \vspace{3pt}
            \item \textbf{\texttt{insert()} in testa}: viene utilizzato quando la lista è vuota per inserire una chiave senza preoccuparsi che questa sia già presente;

                  \vspace{3pt}
            \item \textbf{\texttt{lookup()}, \texttt{remove()}}: in entrambi i casi bisogna scorrere tutta la lista per cercare la chiave e restituire il valore corrispondente/rimuovere la coppia chiave-valore nella lista.
        \end{itemize}
    \end{minipage}
}

\vspace{8pt}
\noindent
\subsubsection{Liste di trabocco: analisi della complessità}
\label{par:trabocco_analisi_comp}
A questo punto si vuole fare un'\textbf{analisi della complessità} di questo meccanismo in particolare, e per fare ciò bisogna definire alcuni parametri:
\begin{itemize}[leftmargin=1em]
    \item $n$ $\rightarrow$ numero di chiavi memorizzate in tabella hash;
    \item $m$ $\rightarrow$ capacità della tabella hash;
    \item $\alpha=n/m$ $\rightarrow$ si riferisce al \textbf{fattore di carico} che nel caso delle liste di trabocco può essere:
          \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{2}\rule{0.6ex}{0.6ex}}]
              \item $\alpha=0$ se la tabella è vuota;
              \item $0<\alpha<1$ se la tabella non è completamente occupata;
              \item $\alpha>1$ se la tabella contiene tanti elementi, non esiste un limite superiore.
          \end{itemize}
\end{itemize}
Partendo da questi parametri, si ottengono poi due informazioni importanti:
\begin{itemize}[leftmargin=1em]
    \item $I(\alpha) \rightarrow$ numero medio di accessi alla tabella per la ricerca di una chiave non presente all'interno di essa (\textbf{ricerca con insuccesso});
    \item $S(\alpha) \rightarrow$ numero medio di accessi alla tabella per la ricerca di una chiave presente all'interno di essa (\textbf{ricerca con successo}).
\end{itemize}

\vspace{8pt}
\noindent
\textbf{\textit{Analisi del caso pessimo}}\\
Il caso peggiore, si presenta nel momento in cui ci si ritrova ad avere dei \textbf{costi} che sono i \textbf{più elevati possibili}: questo avviene quando tutte le chiavi hanno lo \textbf{stesso hash}, ovvero tutte le chiavi vengono \textbf{collocate nella stessa lista}.
Possiamo quindi dire che una struttura dati efficiente come le tabelle hash \textbf{si trasformano in una lista non ordinata}.
\begin{itemize}[leftmargin=1em]
    \item \texttt{insert()} ha costo $\theta(1)$ se non si controlla (inserimento in testa), mentre ha costo $\theta(n)$ nel caso in cui si debba controllare che la chiave sia già stata inserita.
    \item \texttt{lookup()} e \texttt{remove()} hanno entrambi costo $\theta(n)$ poiché in entrambi i casi bisognerà scorrere la lista.
\end{itemize}

\vspace{8pt}
\noindent
\textbf{\textit{Analisi del caso medio}}\\
Per quanto riguarda il caso medio, è necessario fare prima alcune assunzioni:
\begin{itemize}[leftmargin=1em]
    \item Dipende da come le chiavi vengono distribuite;
    \item Si assume che la funzione hash implementata abbia un hashing uniforme semplice, e che sia possibile calcolarla in $\theta(1)$.
\end{itemize}

\vspace{8pt}
\noindent
\begin{minipage}[H]{0.465\textwidth}
    \includegraphics[width=\textwidth]{hashing/img6.png}
\end{minipage}%
\hspace{5pt} % Spazio tra immagine e testo
\raisebox{44pt}{
    \begin{minipage}[t]{0.512\textwidth}
        Dopodiché, per lo studio del caso medio, bisogna \textbf{prendere in considerazione} la \textbf{lunghezza delle liste/vettori}. L'idea generale è la seguente:\\
        Se ho $n=1000$ chiavi e $100$ celle nel vettore avrò un {fattore carico} di $\alpha=n/m=1000/100=10$, ciò significa che il numero atteso di elementi in una lista (se come detto prima la distribuzione è
    \end{minipage}
}

\vspace{4pt}
\noindent
uniforme) è $10$. In sostanza, se il fattore di carico è tenuto abbastanza piccolo ($2,3$ oppure $4$), allora le \textbf{operazioni avranno un costo che deriva da $\alpha$}, ad esempio:
\begin{itemize}[leftmargin=1em]
    \item \textbf{Ricerca senza successo}: se sto effettuando un tipo di ricerca \textbf{senza succeso} dovrò guardare tutta la lista di lunghezza $\alpha$, qundi pago il costo della funzione hash $\theta(1)$ + il costo di analizzare in media l'intera lista di lunghezza $\alpha$;
    \item \textbf{Ricerca con successo}: se invece effettuo una ricerca con successo dove potrei trovare la chiave al primo elemento oppure all'ultimo, \textbf{in media la troverò a metà} e quindi il costo atteso risulta la somma tra il costo della funzione hash $\theta(1)$ + la metà della lunghezza della lista $\alpha/2$.
\end{itemize}

\vspace{8pt}
\noindent
Dunque, mantenendo un valore di $\alpha$ abbastanza \textbf{piccolo} si garantisce il fatto che i \textbf{costi rimarranno costanti}, propriò perché il fattore di carico ($\alpha$) \textbf{influenza il costo computazionale delle operazioni sulle tabelle hash}.

\subsubsection{Indirizzamento aperto (memorizzazione interna)}
\label{par:ch_1.4.3}
Utilizzando un approccio a \textbf{indirizzamento aperto} viene evitato l'utilizzo strutture dati complesse per le quali si utilizzano liste e puntatori (capitolo \ref{par:liste_trabocco}), ma ci si limita a memorizzare tutte le chiavi direttamente nel vettore che costituisce la tabella hash.
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Idea generale
    ]
    In questo caso l'idea generale è molto semplice: ogni indice (slot) della tabella hash conterrà o una chiave, o un puntatore \texttt{null}.
\end{tcolorbox}
\noindent
\begin{itemize}[leftmargin=1em]
    \item \textbf{Inserimento}: Se durante l'inserimento lo slot prescelto dalla funzione hash $H$ è già occupato, cerco uno slot alternativo;
    \item \textbf{Ricerca}: dopo l'inserimento, vado a ricercare nello slot prescelto, ma, se anch'esso è occupato  da una chiave che non è quella che sto cercando, cerco negli slot alternativi, uno dopo l'altro, fino a quando non trovo la chiave che sto cercando oppure trovo \texttt{null} a significare che ho trovato una casella veramente vuota e che quindi non posso più andare avanti.
\end{itemize}

\vspace{8pt}
\noindent
Per verificare che all'interno di uno slot sia presente una chiave oppure \texttt{null} ci si basa sul concetto di \textbf{ispezione}, ovvero l'\textbf{esame di uno slot} durante la ricerca.\\
Per descrivere questa strategia, la funzione hash viene estesa aggiungendo un secondo parametro, quindi non prende più in ingresso solo l'insieme universo $U$ delle chiavi, ma anche un indice (\textbf{indice di sipezione}) compreso fra $0$ e $(m-1)$.

    {\large
        \[
            H : \mathcal{U} \times \overbrace{[0 \dots m-1]}^{\text{Numero ispezione}} \to \overbrace{[0 \dots m-1]}^{\text{Indice vettore}}
        \]
    }
\noindent
La funzione $H(k,i)$ rappresenta la posizione esaminata quando si cerca nella tabella hash la chiave $k$ (una di quelle dell'insieme $U$) alla $i$-esima ispezione, cioè dopo $i$ tentativi falliti:
\begin{itemize}[leftmargin=1em]
    \item Durante un inserimento, $i$ conta quante volte si è trovata una cella occupata;
    \item Durante una ricerca, quante volte si è trovata una cella occupata da una chiave diversa da k.
\end{itemize}
Ad esempio, si prenda in considerazione la seguente \textbf{sequenza di ispezione} generata.
\begin{figure}[H]
    \centering
    \vspace{-10pt}  % Riduce lo spazio sopra
    \addtocounter{figure}{1}
    \includegraphics[width=0.75\textwidth]{hashing/img7.png}
    \vspace{-8pt}
    \caption{esempio di una sequenza di ispezione composta da $6$ passi}
    \label{fig:sequenza_ispezione}
    \vspace{-5pt}  % Riduce lo spazio sopra 
\end{figure}
\begin{tcolorbox}
    [
        colback=green!10,  % Sfondo verde chiaro
        colframe=green!60!black,  % Bordo verde più acceso
        coltitle=black,  % Colore del testo del titolo
        fonttitle=\bfseries,  % Testo del titolo in grassetto
        title={\centering \textbf{\textit{Sequenza di ispezione}}},  % Titolo centrato 
        enhanced,  % Miglioramenti grafici
        attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
        boxed title style={colback=white, colframe=green!60!black, rounded corners},
        breakable
    ]
    Una \textbf{sequenza di ispezione} $[H(k,0), H(k,1), ..., H(k,m-1)]$ è una permutazione degli indici $[0, ..., m-1]$, corrispondente all'ordine in cui vengono esaminati gli slot.
    \begin{itemize}[leftmargin=1em]
        \item Non si vuole esaminare lo stesso slot più di una volta;
        \item Potrebbe essere necessario esaminare tutti gli slot nella tabella.
    \end{itemize}
\end{tcolorbox}
\noindent
In figura \ref{fig:sequenza_ispezione} si vede come, cercando $k_6$, al crescere dell'indice di ispezione si viene portati in posizioni differenti della tabella hash, poiché ad un determinato indice corrisponde una chiave.
All'\textbf{ultima operazione} della sequenza di ispezione, se la \textbf{cella è vuota}:
\begin{itemize}[leftmargin=1em]
    \item \textbf{Inserimento}: la chiave viene inserita;
    \item \textbf{Ricerca}: posso dire che $k_n$ cercato non c'è.
\end{itemize}
Se invece la \textbf{cella è piena}:
\begin{itemize}[leftmargin=1em]
    \item \textbf{Inserimento}: se la chiave nella cella è uguale a quella da inserire, decido se aggiornarla o dare errore (duplicato). Se è diversa (considerando che stimao parlando dell'ultima operazione della sequenza) la tabella è piena (Overflow/Errore).
    \item \textbf{Ricerca}: si deve controllare se la chiave in quella cella è quella che si cerca: se sì la chiava è stata trovata, altrimenti la chiave non esiste nella tabella.
\end{itemize}

\subsubsection{Indirizzamento aperto: analisi della complessità}
In un approccio ad indirizzamento aperto, il \textbf{fattore di carico} è un valore per tutta la tabella che varia da $0$ a $1$, il quale \textbf{indica quanto è satura}, ovvero la percentuale di \textbf{riempimento globale} della tabella hash.
A differenza di come è stato visto al capitolo \ref{par:trabocco_analisi_comp} il significato di $\alpha$ cambia, perché cambia la capienza fisica delle celle:
\begin{itemize}[leftmargin=1em]
    \item \textbf{Liste di trabocco}: ogni cella è un puntatore ad una lista che può allungarsi all'infinito, quindi se $m=10$, $n=20$, avrò $\alpha=2$ a significare che \textbf{\textit{in media, ogni lista contiene 2 elementi}}.
    \item \textbf{Indirizzamento aperto}: invece, in questo caso, ogni cella può contenere al massimo 1 elemento, quindi $n$ (elementi) non potrà mai superare $m$ celle, di conseguenza $0\leqslant\alpha\leqslant1$. Se $\alpha=1$ la tabella è totalmente piena e si entra in \textbf{overflow}, facendo schizzare il costo delle operazioni a $O(n)$.

          \vspace{8pt}
          \noindent
          \textbf{\textit{Esempio pratico}}: ipotizziamo dover trovare posto auto all'interno di un parcheggio.
          \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{3}\rule{0.6ex}{0.6ex}}]
              \item \textbf{Scenario A} ($\alpha=0.1$): il parcheggio ha $100$ posti e solo $10$ macchine al suo interno. La probabilità che il posto assegnato con la funzione hash $h(k)$ sia occupato è bassissima ($10\%$). Dunque, quasi sicuramente si troverà il posto auto al primo colpo, indicando ciò con $O(1)$.
              \item \textbf{Scenario B} ($\alpha=0.9$): il parcheggio ha sempre $100$ posti ma questa volta $90$ macchine al suo interno. La funzione hash $h(k)$, molto probabilmente, calcolerà una posizione già occupata, per più volte, prima di trovare un posto auto libero all'interno del parcheggio. Ciò significa che bisogna girare tanto prima di trovare il $10\%$ dei posti rimanenti.
          \end{itemize}

          In modo analogo all'esempio, il costo tende a $O(n)$ (cioè bisogna scorrere tutta la tabella) quando $\alpha$ si avvicina ad 1. Le collisioni diventano la norma, non l'eccezione, e le sequenze di ispezione si allungano a dismisura.
\end{itemize}

\vspace{8pt}
\noindent
In un \textbf{contesto ideale}, per fare in modo che non si debba scorrere tutta la tabella e che quindi il costo non salga a $O(n)$, quello che si ricerca è una situazione di \textbf{hashing uniforme}.
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Hashing uniforme ideale
    ]
    Utilizando un \textbf{hashing uniforme} ogni chiave ($k_n$) dell'insieme $U$ ha la stessa probabilità di avere come sequenza di ispezione $H(k_n, 0), H(k_n, 1), ...,H(k_n, m-1)$ una qualsiasi delle $m!$ permutazioni di [0,...,m-1].\\
    Dunque la funzione hash non dà solo il punto di partenza, ma consegna l'intera lista delle celle da visitare, in ordine secondo una qualsiasi permutazione.
\end{tcolorbox}
\noindent
\textbf{\textit{Esempio pratico}}\\
Prendiamo in considerazione due chiavi $A$ e $B$, le quali per casualità, su una tabella da $5$ posizioni partono dalla cella $2$.
\begin{itemize}[leftmargin=1em]
    \item Se si utilizzasse una regola fissa, ad esempio \textbf{\textit{"vai al successivo finché non trovi una cella vuota"}}, si creerebbe un "muro" (clustering) prima di poter inserire la chiave nell'indice:
          \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{4}\rule{0.6ex}{0.6ex}}]
              \item $A$: $2 \rightarrow 3 \rightarrow 4 \rightarrow ...$
              \item $B$: $2 \rightarrow 3 \rightarrow 4 \rightarrow ...$
          \end{itemize}
          Questo fino a che una delle due trova per prima la cella vuota e subito dopo la rimanente va $+1$ avanti per essere inserita (\textbf{primary clustering - capitolo} \ref{par:ch_1.4.5}).
    \item Se usiamo l'\textbf{Hashing uniforme}, il sistema assegna due itinerari completi totalmente diversi, pescati a caso tra tutte le combinazioni possibili ($m!$), in modo tale da non creare dei "muri".\\
          In questo modo ogni chiave può essere inserita il prima possibile.
          \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{5}\rule{0.6ex}{0.6ex}}]
              \item $A$: $2 \rightarrow 0 \rightarrow 4 \rightarrow 1 \rightarrow 3$
              \item $B$: $2 \rightarrow 3 \rightarrow 1 \rightarrow 0 \rightarrow 4$
          \end{itemize}
\end{itemize}
Nella pratica, implementare un vero hashing uniforme è difficile.\\
Non possiamo garantire che il percorso di ricerca sia perfettamente casuale per ogni chiave (troppo costoso per il processore), ma \textbf{bisogna obbligatoriamente garantire} che il percorso non entri in un "ciclo vizioso". La funzione di ispezione deve essere progettata matematicamente affinché, al variare di $i$ da $0$ a $m-1$, vengano generati tutti gli indici della tabella esattamente una volta: dunque viene utilizzata \textbf{una singola permutazione}.\\
Per fare ciò vengono utilizzate tre tecniche principali:
\begin{itemize}[leftmargin=1em]
    \item Ispezione lineare;
    \item Ispezione quadratica;
    \item Doppio hashing
\end{itemize}

\subsubsection{Indirizzamento aperto: ispezione lineare}
\label{par:ch_1.4.5}
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Metodologia utilizzata
    ]
    In questo metodo, si utilizza un parametro $\delta$ che rappresenta la distanza tra due posizioni successive
    esaminate durante l’ispezione: $H(k,i) = (H_1(k)+\delta\cdot i)\; mod \; m$
\end{tcolorbox}
\noindent
Dunque, si prende la posizione di partenza e poi si va avanti per un numero fisso di caselle $\delta$.\\
Quindi, quando vado a fare l'ispezione \textit{"zeresima"}, con $i=0$, vado a guardare nella funzione $H_1(k)$, con $i=1$ vado a guardare nella funzione $H_1(k) + \delta$, con $i=2$ nella funzione $H_1(k) + 2 \cdot \delta$, e così via.\\ Dividere per il modulo di $m$ garantisce di ottenere sempre un indice interno alla tabella, in modo tale che quando si supera l'ultima posizione della tabella, l’ispezione riprenda dall’inizio, rendendo il processo circolare.

\vspace{8pt}
\noindent
Questo metodo è semplice, ma presenta un limite importante, quello dell'\textbf{agglomerazione primaria} (primary clustering): quando si vuole inserire una chiave all'interno di un determinato\\
\begin{minipage}[H]{0.455\textwidth}
    \includegraphics[width=\textwidth]{hashing/img8.png}
\end{minipage}%
\hspace{5pt} % Spazio tra immagine e testo
\raisebox{97pt}{
    \begin{minipage}[t]{0.523\textwidth}
        indice all'interno della tabella hash, essa collide con l'elemento già presente, e prosegue la sua ricerca fino a trovare la prima cella libera.\\
        Dato che si sta utilizzando una metodologia a \textbf{\textit{"ispezione lineare"}} (quindi si va avanti di una dimensione fissa), se la posizione iniziale della chiave cade all'interno di una sequenza di celle occupate, tutte queste verranno trovate già piene e la chiave finirà inevitabilmente per essere inserita immediatamente dopo la sequenza, allungando ulteriormente la
        quest'ultima.

        \vspace{8pt}
        Questo fenomeno porta alla formazione di sequenze sempre più lunghe di posizioni a distanza
    \end{minipage}
}

\vspace{4pt}
\noindent
$\delta$ l'una dall'altra, il che rallenta le operazioni e i \textbf{tempi medi} di inserimento e cancellazione crescono. Dunque,  uno slot vuoto che si trova dopo i slot
già occupati nella stessa sequenza viene riempito
con probabilità $(i+1)/m$. L'ispezione lineare è quella "colpevole" dei muri, e il doppio hashing, come si vedrà al capitolo \ref{par:ch_1.4.7}, è la "soluzione reale" al problema.

\subsubsection{Indirizzamento aperto: ispezione quadratica}
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Metodologia utilizzata
    ]
    L'unica differenza rispetto all'utilizzo di un ispezione lineare è che  \textbf{la distanza} (offset) tra due posizioni successive nella sequenza di ispezione non è costante, ma \textbf{cresce quadraticamente} con $i$: $H(k,i) = (H_1(k)+\delta\cdot i^2)\; mod \; m$.
\end{tcolorbox}
\noindent
\begin{itemize}[leftmargin=1em]
    \item con $\delta=1$ e $i=0$ si esamina prima la posizione $(H_1(k)+0)$;
    \item con $\delta=1$ e $i=1$ si esamina la posizione $(H_1(k)+\delta\cdot)$;
    \item con $\delta=1$ e $i=2$ si esamina la posizone $(H_1(k)+\delta\cdot4)$;
    \item con $\delta=1$ e $i=3$ si esamina la posizone $(H_1(k)+\delta\cdot9)$, e così via;
\end{itemize}
Questa variazione di indice riduce l'effetto dell'\textbf{agglomerazione primaria}, tipico dell'ispezione lineare, poiché due chiavi con indirizzi iniziali differenti ($H_1(k) \neq H_1(k')$) tendono a generare sequenze di
ispezione che divergono più rapidamente.\\
Tuttavia, se due chiavi condividono lo stesso indirizzo iniziale ($H_1(k) = H_1(k')$) le sequenze di ispezione coincidono completamente, e il problema si ripresenta in questo caso prendendo il nome di \textbf{agglomerazione secondaria}.\\
Un ulteriore limite, è che \textbf{la sequenza di ispezione} generata \textbf{non è una permutazione} dell'insieme $\{0,...,m-1\}$: può quindi accadere che alcune posizioni libere non vengano mai raggiunte, impedendo l’inserimento di nuove chiavi anche se la tabella non è piena.


\subsubsection{Indirizzamento aperto: doppio hashing}
\label{par:ch_1.4.7}
Il \textbf{doppio hashing} è il metodo che viene utilizzato maggiormente per risovere il problema dell'agglomerazione.
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Metodologia utilizzata
    ]
    Vengono utilizzate \textbf{due funzioni hash}, la prima indica la posizione iniziale e la seconda indica l'offset, che quindi cambia per ogni chiave: $H(k,i) = (H_1(k)+i\cdot H_2(k))\; mod \; m$.
\end{tcolorbox}
\noindent
In questo modo, anche se due chiavi $k$ e $k'$ hanno lo stesso indirizzo iniziale $H_1(k) = H_1(k')$, non è detto che abbiano lo stesso valore in $H_2$ (anzi, la probabilità è relativamente bassa), dunque tendono ad essere sparse in maniera più \textit{"uniforme"} riducendo drasticamente la formazione di \textbf{agglomerati primari} e \textbf{secondari}.

\vspace{8pt}
\noindent
Utilizzando questa metodologia si hanno al massimo $m^2$ sequenze di ispezione distinte:
\begin{itemize}[leftmargin=1em]
    \item $m$ scelte possibili per decidere da dove partire (cella $0,1,...,m-1$);
    \item $m$ scelte possibili per decidere quanto lunghi fare i passi (offset di $1$, $2$, $3$, ...)
\end{itemize}
Il numero totale di combinazioni unice (coppie partenza-passo) è quindi $m\cdot m=m^2$.\\
Però non basta avere tanti percorsi diversi ($m^2$), bisogna essere sicuri che \textbf{ogni percorso sia valido}, ovvero che continuando a saltare, \textbf{si debbano toccare tutte le celle della tabella} prima di ritornare al \textbf{punto di partenza}. Per garantire ciò si usano principalmente due metodi:
\begin{enumerate}[leftmargin=1.3em]
    \item \textbf{\textit{Metodo della potenza di $2$}}
          \begin{itemize}[leftmargin=1em]
              \item Si sceglie $m=2^p$ (ad esempio, $16$, $32$, $64$, ...), in modo tale che l'unico divisore di $m$ sia $2$;
              \item Ci si assicura che $H_2(k)$ dia sempre un \textbf{numero dispari}.
          \end{itemize}
          Funziona perché un numero dispari non è mai diivisibile per $2$, quindi sono per forza primi tra loro.
    \item \textbf{\textit{Metodo del numero primo}}:
          \begin{itemize}[leftmargin=1em]
              \item Si sceglie $m$ come numero primo ($11$, $13$, $17$, ...);
              \item Ci si assicura che $H_2(k)$, dia un numero positivo minore di $m$ ($0<H_2<m$);
          \end{itemize}
          Funziona perché un numero primo non  divisibile per nulla tranne che per se stesso.
\end{enumerate}

\subsubsection{Indirizzamento aperto: cancellazione}
\label{par:ch_1.4.8}
Durante la gestione delle collisioni, utlizzando un approccio ad indirizzamento aperto, se si vuole cancellare un elemento dalla tabella hash \textbf{non è possibile} semplicemente sostituire la chiave che si vuole cancellare con un valore \texttt{null}.\\
Questo perché si potrebbe \textbf{\textit{"rompere"} una sequenza di ispezione}: infatti, come si può vedere in figura \ref{fig:rottura_sequenza_ispezione}, durante la ricerca di una chiave $k_n$, il raggiungimento di una cella \texttt{"null"} non garantisce che $k_n$ non sia presente altrove nella tabella hash, poiché potrebbe essere semplicemente in una posizione differente sempre all'interno della stessa. Contrassegnare la cella come \texttt{"null"} \textbf{arresterebbe l'algoritmo} di ricerca, \textbf{spezzando il collegamento verso le chiavi successive} nella sequenza di ispezione.
\begin{figure}[H]
    \centering
    \addtocounter{figure}{1}
    \vspace{-8pt}
    \includegraphics[width=0.70\textwidth]{hashing/img9.png}
    \vspace{-5pt}
    \caption{interruzione sequenza di ispezione}
    \label{fig:rottura_sequenza_ispezione}
\end{figure}

\vspace{-10pt}
\noindent
Proprio per questo motivo è necessario introdurre un \textbf{marcatore speciale} che indichi esplicitamente che la cella era occupata in passato ma è stata svuotata. L'elemento in questione è \textbf{\textit{deleted (del)}} che permette di continuare l'ispezione fino a raggiungere la chiave ricercata (nel caso in cui sia effettivamente presente all'interno della tabella hash):
\begin{itemize} [leftmargin=1em]
    \item Durante una \textbf{ricerca} il \textit{deleted} viene trattato come uno slot pieno.
    \item Durante un \textbf{inserimento} il \textit{deleted} viene trattato come uno slot vuoto, perché non ci interessa che sia stato cancellato in precedenza.
\end{itemize}

\vspace{8pt}
\noindent
Tuttavia, aggiungere il marcatore \textit{deleted} comporta lo svantaggio di aumentare i tempi di ricerca, che non dipendono più solamente dal fattore di carico $\alpha$ ($I(\alpha), S(\alpha)$ - capitolo \ref{par:trabocco_analisi_comp}), ma anche da quanti elementi sono stati cancellati.

\subsection{Implementazione dell'hashing doppio}
L'hashing doppo è indubbiamente la \textbf{tecnica migliore} da implementare \textbf{utilizzando} una gestione delle collisioni ad \textbf{indirizzamento aperto}, poiché permette di ridurre drasticamente clustering primari e secondari.

\subsubsection{Definizione delle variabili}
La tabella hash viene \textbf{memorizzata mediante due vettori paralleli}, a cui in seguito verrà assegnata la dimensione $m$ (valore che detta la dimensione della tabella):
\begin{itemize}[leftmargin=1em]
    \item $key$ il quale memorizza le chiavi;
    \item $values$ che memorizza i valori ad esse associati.
\end{itemize}
\begin{figure}[H]
    \centering
    \vspace{-8pt}
    \addtocounter{figure}{1}
    \includegraphics[width=\textwidth]{hashing/img10.png}
\end{figure}
\noindent
Ovviamente, come spiegato al capitolo \ref{par:ch_1.4.3} e \ref{par:ch_1.4.8}, l'implementazione dell'indirizzamento aperto prevede che ogni cella di del vettore $key$ contenga una chiave valida oppure uno dei due valori speciali \textit{null} o \textit{deleted}, che indicano rispettivamente una posizione mai utilizzata e una posizione occupata in passato ma che è stata cancellata.

\subsubsection{La funzione \texttt{hash}}
Questa funzione prende in ingresso un parametro \texttt{"dim"} ad indicare la dimensione della tabella hash. Inizialmente viene definita la dimensione della tabella, dando un valore alla variabile \texttt{"m"} tramite il parametro \texttt{"dim"} che la funzione prende in ingresso.\\
Successivamente ci si occupa di inizializzare tutte le chiavi e i valori (in particolare solo le chiavi poiché i valori al momento non interessano) con il valore \texttt{null}.
\begin{figure}[H]
    \addtocounter{figure}{1}
    \vspace{-12pt}
    \includegraphics[width=0.95\textwidth]{hashing/img11.png}
\end{figure}

\subsubsection{La funzione \texttt{scan}}
La funzione \texttt{scan} non fa parte dell'API della tabella hash, infatti non è un operazione del dizionario come \texttt{lookup(), insert()} e \texttt{remove}, ma serve solo per essere richiamata all'interno di esse.
La funzione \texttt{scan} prende in input la chiave $k$ che si vuole ricercare all'interno della tabella hash, e un valore booleano $insert$ che indica se si tratta di un operazione di inserimento oppure no, mentre \textbf{ritorna un indice intero} che \textbf{indica la posizione della chiave}, e non il valore associato ad essa.
\begin{figure}[H]
    \addtocounter{figure}{1}
    \vspace{-6pt}
    \includegraphics[width=0.95\textwidth]{hashing/img12.png}
    \vspace{-15pt}
\end{figure}
\begin{itemize}[leftmargin=1em]
    \item La variabile \textit{fistDeleted} è un "trucco" molto intelligente per \textbf{ottimizzare le prestazioni} della tabella hash durante l'inserimento. Viene utilizzata per ricordare \textbf{la posizione della prima cella} \textbf{\textit{deleted}}.

          \vspace{8pt}
          \noindent
          Durante una scansione per inserimento, dobbiamo obbligatoriamente arrivare fino in fondo (al \texttt{null}) per assicurarci che la chiave non esista già. Tuttavia, se lungo il percorso incontriamo delle celle \textit{deleted}, la variabile \textit{firstDeleted}, che inizialmente viene inizializzata a $-1$ (ad indicare \textit{"per ora non ho visto celle cancellate"}), memorizza l'indice della prima di queste celle.
          Se alla fine della scansione la chiave non è stata trovata, l'algoritmo preferisce inserire il nuovo elemento nella posizione \textit{firstDeleted} (riciclando lo spazio) piuttosto che in fondo alla sequenza (\texttt{null}). Questo mantiene la \textbf{tabella compatta} e \textbf{riduce i tempi di ricerca futuri}.
    \item La variabile $i$ è l'indice del numero di ispezione (ispezione zeresima, ispezione uno, ispezione due, e così via...);
    \item  La variabile $j$ indica la posizione attualmente analizzata: viene inizializzata con il valore $H(k)$ dove $H$ è la funzione hash di base, quella che ci dice il punto di partenza dove andare a cercare e $k$ ovviamente è la chiave che stiamo cercando.
\end{itemize}

\vspace{8pt}
\noindent
A questo punto inizia un ciclo che terminerà qualora:
\begin{itemize}[leftmargin=1em]
    \item trovo la chiave che sto cercando;
    \item trovo una posizione \texttt{null} a significare che non è più possibile andare avanti, perché la chiave cercata non è stata trovata;
    \item Oppure, nessuna delle due condizioni precedenti si è verificata e il numero di ispezioni raggiunge $m$ ($i=m$) a significare sostanzialmente che ho ispezionato tutta la tabella senza trovare quello che si stava cercando.
\end{itemize}
Invece, le due righe all'interno del ciclo while sono quelle che permettono di andare avanti:
\begin{itemize}[leftmargin=1em]
    \item $i=i+1$ somma $+1$ all'indice delle ispezioni;
    \item Per calcolare la prossima cella si utilizza una seconda funzione $H'(k)$ che è l'offest che si va a sommare alla posizione che si stava cercando, come prevede il doppio hashing (capitolo \ref{par:ch_1.4.7}).
\end{itemize}

\vspace{8pt}
\noindent
Terminato il ciclo while si presentano due possibilità:
\begin{itemize}[leftmargin=1em]
    \item Se sono in \textbf{condizione di inserimento} e non ho trovato una chiave da sovrascrivere e \textbf{\textit{firstDeleted}} non è più inizializzato con il valore iniziale (-1), a significare che ho riempito la prima cella \textit{deleted}, allora restituisco proprio \textbf{\textit{firstDeleted}}, poiché l'inserimento è avvenuto lì dentro;
    \item Altrimenti, sono in \textbf{condizione di ricerca} e restituisco $j$, che rappresenta l'ultimo indice guardato e se la chiave non è stata trovata, può essere un valore fittizzio.
\end{itemize}

\subsubsection{Le funzioni \texttt{lookup} e  \texttt{insert}}
Nel caso della funzione \texttt{lookup} viene richiamata la funzione \texttt{scan} passando il valore \textit{false} ad indicare che non si tratta di un operazione di inserimento ma solo di ricerca.\\
Nel caso della funzione \texttt{insert} viene richiamata la funzione \texttt{scan} passando il valore \textit{true} ad indicare che si tratta di un operazione di inserimento.
\begin{figure}[h]
    \centering
    \vspace{-18pt}  % Riduce lo spazio sopra
    \subfloat[]{%
        \addtocounter{figure}{1}
        \includegraphics[width=0.31\textwidth]{hashing/img13}%
    }
    \hspace{2cm}
    \subfloat[]{%
        \addtocounter{figure}{1}
        \includegraphics[width=0.53\textwidth]{hashing/img14}%
    }
    \vspace{-10pt}  % Riduce lo spazio sotto 
\end{figure}
\\
\\
In entrambi i casi ottengo un indice che viene restituito dalla funzione \texttt{scan}:
\begin{itemize}[leftmargin=1em]
    \item Nel caso della \texttt{lookup} (a) si hanno due possibilità:
          \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{6}\rule{0.6ex}{0.6ex}}]
              \item si ha trovato quello che si cercava e questo è rappresnetato dal fatto che la chiave nell'indice $i$ è uguale alla chiave $k$ che si sta cercando, e allora viene restituito il valore associato a quella chiave;
              \item Altrimenti ritorno \texttt{null} a significare che l'oggetto non è stato trovato.
          \end{itemize}

          \vspace{8pt}
    \item Allo stesso modo, nel caso dell'\texttt{insert} (b), le possibilità sono:
          \begin{itemize}[leftmargin=1em, label=\raisebox{0.4ex}{\phantom{6}\rule{0.6ex}{0.6ex}}]
              \item se si ha trovato una \textbf{casella vuota} oppure una casella \textbf{\textit{deleted}} oppure una casella che \textbf{già contiene la chiave $k$}, in tutti questi casi si va a sovrascrivere il valore $k$ e il valore $v$ sulle rispettive posizioni $i$-esime;
              \item Altrimenti, la tabella hash è piena poiché non si sono trovate caselle a disposizione dove andare a scrivere il  valore $k$  e quindi bisognerà ritornare un qualche tipo di errore.\\
                    Questo potrebbe essere anche verificato prima di fare una ricerca del genere se si mantenessero informazioni riguardanti il numero di chiavi effettivamente registrate nella tabella, allora a quel punto se il numero di chiavi ha raggiunto $m$ si può subito ritornare che è impossibile effettuare un inseriemnto.
          \end{itemize}
\end{itemize}

\subsubsection{La funzione \texttt{remove}}
Nuovamente la funzione \texttt{scan} viene passata con il valore \textit{false}, poiché non si tratta di un operazione di inserimento.\\
In questo caso la condizione è ancora più semplice:
\begin{itemize}[leftmargin=1em]
    \item Trovo l'elemento e lo cancello, segnando la chiave come \textbf{\textit{deleted}} (per non rompere la sequenza di ispezione) mentre il valore associato a quella determinata chiave; viene impostato a \textbf{\textit{null}};
    \item Non trovo l'elemento e non devo fare assolutamente nulla;
\end{itemize}
\begin{figure}[H]
    \addtocounter{figure}{1}
    \vspace{-10pt}
    \includegraphics[width=0.95\textwidth]{hashing/img15.png}
\end{figure}

\subsection{Complessità}
\begin{figure}[H]
    \vspace{-10pt}
    \centering
    \includegraphics[width=0.85\textwidth]{hashing/img16.png}
    \caption{Tabella riassuntiva complessità delle tecniche di gestione delle collisioni}
    \label{fig: resume_table}
\end{figure}
\noindent
La complessità viene misurata in base ad $\alpha$ (fattore di carico - capitolo \ref{par:trabocco_analisi_comp}).\\
Ricordiamo che per quanto riguarda le tecniche ad indirizzamento aperto il valore di $\alpha$ deve essere compreso tra $0$ e $1$, mentre per le liste di trabocco il valore di $\alpha$ deve essere maggiore o uguale a $0$.\\
Le formule della compelssità della ricerca con successo e della ricerca con insuccesso, per quanto riguarda le tecniche ad indirizzamento aperto, sono di difficile derivazione, mentre ricordiamo che il $+1$ nelle liste di trabocco indica l'accesso che devo fare alla memoria per iniziare a guardare la lista che stiamo scorrendo.

\vspace{8pt}
\noindent
L'ispezione quadratica ha prestazioni molto vicine a quelle dell'Hashing Doppio (e quindi dell'hashing uniforme), poiché elimina il clustering primario. Tuttavia, a causa del clustering secondario, le sue prestazioni sono leggermente inferiori rispetto al doppio hashing puro, ma drasticamente superiori all'ispezione lineare.\\
Nella tabella in figura \ref{fig: resume_table}  viene omessa perché le sue formule di costo non sono semplici o perché viene considerata un'approssimazione del caso uniforme. Si preferisce mostrare gli estremi dell'indirizzamento aperto:
\begin{itemize}[leftmargin=1em]
    \item \textbf{Il caso pessimo (per il clustering)}: ispezione lineare;
    \item \textbf{Il caso ottimo (quasi casuale)}: doppio hashing.
\end{itemize}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{hashing/img17.png}
    \vspace{-10pt}
    \caption{grafico dell'andamento delle compelssità}
\end{figure}

\vspace{-10pt}
\noindent
Dal grafico si può notare come la regione che sta a sinistra dell'$1$ vale sia per le tecniche ad indirizzamento aperto che per le liste di trabocco, mentre la parte a destra dell'$1$ si riferisce esclusivamente alle liste di trabocco.

\subsubsection{Ristrutturazione}
Utilizzando dei metodi di ispezione (indirizzamento aperto) , è opportuno evitare che la tabella raggiunga un fattore di carico
troppo elevato, poiché il tempo medio di ricerca cresce rapidamente all'aumentare di $\alpha$:
\begin{itemize}[leftmargin=1em]
    \item Se $\alpha$ è basso (es. 0.2, tabella vuota all'80\%), è velocissimo;
    \item Se $\alpha$ supera una certa soglia (es. 0.5 o 50\%), le collisioni aumentano esponenzialmente e la tabella diventa lenta.
\end{itemize}
La \textbf{soluzione} non è aspettare che si blocchi, \textbf{ma intervenire prima}.

\vspace{8pt}
\noindent
Dunque, quando il numero di elementi supera la soglia prefissata (ad esempio $\alpha > 0.5/0.75$), scatta l'\textbf{operazione di ristrutturazione}, che avviene in tre passaggi:
\begin{enumerate}[leftmargin=1.3em]
    \item \textbf{\textit{Nuova Memoria}}: si alloca una nuova tabella di dimensione doppia ($2m$) rispetto a quella vecchia;
    \item \textbf{\textit{Re-inserimento (Rehashing)}}: si prendono tutte le chiavi attive (non quelle DELETED) dalla vecchia tabella e si reinseriscono nella nuova utilizzando una nuova funzione hash (quindi rimappandone la posizione), poiché $m$ è cambiato;
    \item \textbf{\textit{Pulizia}}: la vecchia tabella viene buttata via.
\end{enumerate}
In questo modo il fattore di carico risulta al più dimezzato (non superiore a metà della soglia impostata precedentemente, ad esempio 0.25) e tutte le posizioni sono o libere o occupate: eventuali celle marcate come cancellate vengono eliminate.

\vspace{8pt}
\noindent
Il costo di quest'operazione vale O(m) nel caso pessimo, ma c'è da considerare che accade molto raramente. Quindi, se la maggior parte delle volte, come accade per le operazioni di \texttt{lookup, insert} e \texttt{remove} il costo è $O(1)$, allora è come se stessimo \textit{"spalmando"} quel costo raro su tutti gli inserimenti veloci fatti prima.\\ 
In termini tecnici, si dice che il \textbf{costo ammortizzato} rimane costante $O(1)$.

\vspace{8pt}
\noindent
Ovviamente il discorso vale anche al contrario. 
Se si cancellano tantissimi elementi e la tabella diventa vuota (ad esempio, $\alpha < 0.25$), si spreca memoria.
In quel caso, si fa una ristrutturazione per dimezzare la tabella, mantenendo l'efficienza dello spazio. 



\end{document}