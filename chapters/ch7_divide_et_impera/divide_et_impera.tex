\documentclass[../../main_document/main.tex]{subfiles}

\begin{document}
\section{Divide-et-impera}

\subsection{Risoluzione problemi}
Dato un problema, non si hanno metodi generali per risolverlo in modo efficiente, tuttavia è possibile evidenziare 4 fasi:
\begin{enumerate}[leftmargin=1em]
    \item Classificazione del problema;
    \item Caratterizzazione della soluzione;
    \item Tecnica di progetto;
    \item Utilizzo di strutture dati.
\end{enumerate}
\noindent Queste fasi non sono necessariamente sequenziali.

\subsubsection{Classificazione dei problemi}
\paragraph{Problemi decisionali}
Il dato in ingresso soddisfa una certa proprietà? \textbf{Soluzione}: risposta si/no. Un problema di esempio può essere stabilire se un grafo è connesso.

\subsubsection*{Problemi di ricerca}
Problemi in cui si ha:
\begin{itemize}[leftmargin=1em]
    \item \textbf{Spazio di ricerca:} insieme di "soluzioni" possibili;
    \item \textbf{Soluzione ammissibile:} soluzione che rispetta certi vincoli;
\end{itemize}
Ad esempio la posizione di una sotto-stringa in una stringa.

\subsubsection*{Problemi di ottimizzazione}
Problemi in cui ogni soluzione è associata ad una funzione di costo e si vuole la soluzione di costo minimo. ad esempio il cammino più breve tra due nodi (grafi pesati).

\subsubsection{Definizione matematica del problema}
Una cosa fondamentale da fare è definire bene il problema in modo formale. Spesso la formulazione è banale, ma può suggerire una prima idea di soluzione. Ad esempio, data una sequenza di \textit{n} elementi, una permutazione ordinata è data dal minimo seguito da una permutazione ordinata degli \textit{n - 1} elementi (Selection Sort).
La definizione matematica del problema può suggerire una possibile tecnica di soluzione.\\
\textbf{Sottostruttura ottima} $\rightarrow$ Programmazione dinamica;\\
\textbf{Proprietà greedy} $\rightarrow$ Tecnica greedy;

\subsubsection{Tecnica di soluzione dei problemi}
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Divide-et-impera
    ]
    Un problema viene suddiviso in sotto-problemi indipendenti, che vengono risolti ricorsivamente (top-down).\\
    Ambito: problemi di decisione, ricerca.
\end{tcolorbox}
\begin{tcolorbox}
    [
        colback=green!10,  % Sfondo verde chiaro
        colframe=green!60!black,  % Bordo verde più acceso
        coltitle=black,  % Colore del testo del titolo
        fonttitle=\bfseries,  % Testo del titolo in grassetto
        title={\centering \textbf{Top-down}},  % Titolo centrato 
        enhanced,  % Miglioramenti grafici
        attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
        boxed title style={colback=white, colframe=green!60!black, rounded corners}
    ]
    La strategia top-down è una strategia in cui un problema viene diviso in parti sempre più piccole fino a che non si ottengono componenti semplici da implementare.\\
    Top-down è diverso da divide-et-impera, dato che quest'ultimo fa uso di top-down, che è una strategia di progettazione, mentre divide-et-impera è una tecnica algoritmica specifica con una struttura ben definita.
\end{tcolorbox}
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Programmazione dinamica
    ]
    La soluzione viene costituita (bottom-up) a partire da un insieme di sotto-problemi potenzialmente ripetuti.\\
    Ambito: problemi di ottimizzazione.
\end{tcolorbox}
\begin{tcolorbox}
    [
        colback=green!10,  % Sfondo verde chiaro
        colframe=green!60!black,  % Bordo verde più acceso
        coltitle=black,  % Colore del testo del titolo
        fonttitle=\bfseries,  % Testo del titolo in grassetto
        title={\centering \textbf{Bottom-up}},  % Titolo centrato 
        enhanced,  % Miglioramenti grafici
        attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
        boxed title style={colback=white, colframe=green!60!black, rounded corners}
    ]
    Bottom-up, al contrario di top-down, parte da componenti più piccole e riutilizzabili e le combina per ottenere funzionalità più complesse fino ad ottenere un intero sistema.\\
    Come funziona:
    \begin{enumerate}
        \item Si implementano piccole parti indipendenti;
        \item Le si mettono insieme per formare parti più grandi;
        \item Si continuano a comporre finché non si ottiene l'algoritmo/programma completo.
    \end{enumerate}
\end{tcolorbox}
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Memoization (o annotazione)
    ]
    Versione top-down della programmazione dinamica.
\end{tcolorbox}
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Memoization (o annotazione)
    ]
    Versione top-down della programmazione dinamica.
\end{tcolorbox}
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Tecnica greedy
    ]
    Approccio "ingordo": si fa sempre la scelta localmente ottima.
\end{tcolorbox}
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Backtrack
    ]
    Si procede per "tentativi" e si torna di tanto in tanto sui propri passi.
\end{tcolorbox}
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Ricerca locale
    ]
    La soluzione ottima viene trovata "migliorando" via via soluzioni esistenti.
\end{tcolorbox}
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Algoritmi probabilistici
    ]
    Meglio scegliere con giudizio (in maniera costosa) o scegliere a caso "gratuitamente".
\end{tcolorbox}

\subsection{Divide-et-impera}
Questa tecnica, applicata alla risoluzione di un problema computazionale, consiste nel partizionare il problema in sotto-problemi più piccoli dello stesso tipo e indipendenti, risolverli ricorsivamente, e successivamente ricombinare, con poco sforzo, le soluzioni parziali per ottenere la soluzione del problema originale.\\
Lo "schema" di una procedura ricorsiva \texttt{divideEtImpera()} per risolvere un problema di \textit{P} di dimensione \textit{n} è il seguente, dove \textit{k} è una costante intera prefissata:


\begin{algorithm}
    \caption{divideEtImpera(\textit{P}, \textbf{integer} \textit{n})}
    \begin{algorithmic}
        \If{$n \le k$}
        \State risolvi $P$ direttamente
        \Else
        \State dividi $P$ in $h$ sottoproblemi $P_1,...,P_h$ di dimensione $n_1,...,n_h$
        \State \textbf{for} i $\leftarrow$ 1 \textbf{to} $h$ \textbf{do} divideEtImpera($P_i$,$n_i$)
        \State combina i risultati di $P_1,...,P_h$ per ottenere quello di $P$
        \EndIf
    \end{algorithmic}
\end{algorithm}

\noindent La tecnica \textit{divide-et-impera} permette di provare agevolmente la correttezza dell'algoritmo usando il principio di induzione e di impostarne facilmente le relazioni ricorrenti della funzione \textit{T(n)} di complessità:

\[
    T(n)=
    \begin{aligned}
        \begin{cases}
            c, \qquad n\le k \\
            D(n)+C(n)+\sum_{i=1}^{h}T(n_i),\quad n>k
        \end{cases}
    \end{aligned}
\]

\noindent dove c è una costante, \textit{D(n)} è il numero di operazioni per dividere il problema e \textit{C(n)} è il numero di operazioni per combinare i risultati.
\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Nota
    ]
    Se i dati sono partizionati in maniera bilanciata, cioè tutti gli $n_i$ sono all'incirca uguali, allora l'algoritmo può risultare molto efficiente.
\end{tcolorbox}

\subsection{Minimo: Divide-et-impera}
Si applichi ora il metodo divide-et-impera a un problema di ricerca del valore minimo in un array \textit{A}:
\begin{algorithm}
    \caption{\textbf{int} minrec(\textbf{int}[] A, \textbf{int} i, \textbf{int} j)}
    \begin{algorithmic}
        \If{$i  == j$}
        \State \textbf{return} A[i]
        \Else
        \State m=$\lfloor(i+j)/2\rfloor$
        \State \textbf{return} min(minrec(A,i,m), minrec(A, m+1, j)
        \EndIf
    \end{algorithmic}
\end{algorithm}

\begin{tcolorbox}
    [
        colback=green!10,  % Sfondo verde chiaro
        colframe=green!60!black,  % Bordo verde più acceso
        coltitle=black,  % Colore del testo del titolo
        fonttitle=\bfseries,  % Testo del titolo in grassetto
        title={parte intera inferiore e parte intera superiore},  % Titolo centrato 
        enhanced,  % Miglioramenti grafici
        attach boxed title to top center={yshift=-2mm},  % Posiziona il titolo centrato in alto
        boxed title style={colback=white, colframe=green!60!black, rounded corners}
    ]
    $\lfloor{x}\rfloor$ rappresenta la parte intera inferiore, spesso chiamata "floor", ovvero se si ha un numero reale esso, se seguito da virgola, viene approssimato per difetto, ad esempio: $\lfloor{3,9}\rfloor=3$.\\
    Mentre, al contrario $\lceil{x}\rceil$ rappresenta la parte intera superiore, detta "ceiling", e si approssima per eccesso, ad esempio: $\lfloor{3,1}\rfloor=4$.
\end{tcolorbox}

\noindent Nell'algoritmo avviene che viene preso un valore medio della posizione dell'array \textit{A}, con \textit{i} che indica l'inizio di \textit{A} e \textit{j} che ne indica la fine, \textit{m} è quindi l'indice che indica la metà dell'array.
Ogni volta viene richiamata la funzione fino a quando non si arriva ad avere un singolo elemento nell'array, ovvero la condizione dell'"if".\\
L'array viene quindi diviso in tanti piccoli pezzi per trovare il minimo avendo una complessità:
\[
    T(n)=
    \begin{aligned}
        \begin{cases}
            2T(n/2)+1, \quad n>1 \\
            1,\quad n=1
        \end{cases}
    \end{aligned}
\]

\noindent Analizzando la complessità dell'algoritmo, quindi, si ha un caso base, quando l'array contiene un solo elemento e quindi il costo risulta costante, perché basta restituire quell'elemento, ma nel caso ricorsivo con \textit{n} elementi il costo è dato da $2T(n/2)$, ovvero due chiamate ricorsive, ciascuna su metà dell'input $(n/2)$ e $+1$ che rappresenta il costo costante delle operazioni di divisione (ovvero il calcolo di \textit{m}) e di combinazione (confronto finale tra i due minimi).\\
Risulta che l'algoritmo divide-et-impera non è conveniente.

\newpage

\subsection{Esempio binary search}
\begin{algorithm}
    \caption{\textbf{int} binarySearch(\textbf{int}[] $S$, \textbf{int} $v$, \textbf{int} $i$, \textbf{int} $j$)}
    \begin{algorithmic}
        \If{$i > j$}
        \State \textbf{return} 0
        \Else
        \State $m = \lfloor(i+j)/2\rfloor$
        \If{$S[m] == v$}
        \State \textbf{return} $m$
        \ElsIf{$S[m] < v$}  % Nota l'uso di \ElsIf per allineare correttamente
        \State \textbf{return} binarySearch($S, v, m+1, j$)
        \Else
        \State \textbf{return} binarySearch($S, v, i, m-1$)
        \EndIf
        \EndIf
    \end{algorithmic}
\end{algorithm}

\noindent La procedura binary search è un particolare tipo di divide-et-impera. Il problema viene suddiviso in 2 sottoproblemi (h=2) approssimativamente uguali, mentre i costi $C(n)$ e $D(n)$ sono costanti. La particolarità sta nel fatto che la chiamata ricorsiva avviene in solo uno dei due sottoproblemi, invece che su entrambi.\\
Si può considerare un esempio "semplificato" di divide-et-impera, ma permette di enunciare una regola importante in questi casi: \textbf{se non tutti i sottoproblemi devono essere analizzati, è buona norma affrontare ricorsivamente i problemi più piccoli possibili}.\\
La complessità della ricerca può essere ulteriormente abbassata tenendo conto dei valori delle chiavi memorizzate nel vettore e della loro \textbf{distribuzione di probabilità}.

\subsubsection*{Esempio di ricerca: Dizionario}
Se si vuole cercare la parola "casa" nel dizionario, non lo si apre a metà ma a circa $\frac{1}{4}$ del numero di pagine.\\
Si consideri una rappresentazione a vettore, con $n$ chiavi numeriche e distribuite uniformemente nell'intervallo [$k_{min}$, $k_{max}$]. Dovendo cercare le chiavi $k$ in $S[1...n]$, si tenta la ricerca in una posizione "ragionevolmente" vicina (non al centro), data da: $n*\frac{k-k_{min}}{k_{max}-k_{min}}$.\\
Il numeratore fornisce lo scarto tra i valori della chiave da cercare e quella più piccola, mentre il denominatore fornisce lo scarto tra i valori della chiave più grande e quella più piccola. Il loro rapporto indica quanto $k$ si discosta dagli estremi.\\
Se $k=k_{min}$, allora il rapporto è 0 e conviene quindi cercare nella prima posizione del vettore, se $k=k_{max}$, il rapporto è 1 e allora conviene cercare nell'ultima posizione del vettore. La ricerca binaria "ignora" k, assume che il rapporto sia pari a $\frac{1}{2}$ e tenta in posizione centrale. Il metodo di ricerca risultante è detto di \textbf{interpolazione}.\\
La procedura di ricerca binaria \texttt{binarySearch()} può essere trasformata in una di interpolazione semplicemente sostituendo l'istruzione:
\begin{itemize}[leftmargin=1em]
    \item $m \quad \leftarrow \quad \lfloor(i+j)/2\rfloor$\\
          con
    \item $m \quad \leftarrow \quad i+\lfloor(k-A[i])*(j-i)/(A[j]-A[i])\rfloor$
\end{itemize}

\noindent Infatti la ricerca viene effettuata in generale sulla porzione $A[i...j]$ del vettore, che contiene la più piccola chiave in $A[i]$ e la più grande in $A[j]$. La formula per $m$ si ricava da quella ricerca binaria, che era $i+\lfloor(j-i)/2\rfloor$, sostituendo $(k-A[i])*(j-i)/(A[j]-A[i])$ ad $\frac{1}{2}$.\\

\begin{tcolorbox}[
        colback=yellow!20,
        colframe=darkgray,
        title=Complessità
    ]
    Con distribuzione uniforme delle chiavi, è possibile dimostrare che la complessità è $O(log\,log\,n)$. La funzione $log\,log\,n$ cresce molto lentamente, ma è paragonabile a $log\,n$ per $n$ piccolo. Pertanto, se ci sono poche chiavi, oppure se le chiavi non sono uniformemente distribuite, è più conveniente usare la ricerca binaria. Al contrario, conviene usare l'interpolazione se ci sono tante chiavi oppure se sono uniformemente distribuite.
\end{tcolorbox}

\subsection{Quicksort (Hoare, 1961)}
L'algoritmo di QuickSort è l'algoritmo praticamente più efficiente per ordinare gli elementi di un vettore.\\
Questo è basato sulla tecnica \textit{divide-et-impera}, ma differisce dal "MergeSort" nel modo in cui divide il problema e combina i risultati. \\
Questo algoritmo ha un caso medio: $O(n\,log\,n)$ e un caso pessimo: $O(n^2)$ che però viene evitato grazie a tecniche "euristiche" (ovvero, in generale, tecniche che non garantiscono di trovare la soluzione ottimale o perfetta, ma progettate per trovare una soluzione soddisfacente in un tempo ragionevole) e spesso è preferito ad altri algoritmi a causa di costanti moltiplicative più basse. Nella scelta, spesso si valuta anche la "stabilità" dell'ordinamento.\\
Si consideri un vettore $A[1,\,...,\,n]$ con indici $lo$, $hi$ tali che $1\le lo \le hi \le n$:\\
\vspace{6pt}
\noindent
\hspace{5pt}
\begin{minipage}[t]{0.6\textwidth}
    \includegraphics[width=\linewidth]{divide-et-impera/VettoreEsempio.pdf}
\end{minipage}
\hspace{5pt}\\
\noindent
La parte evidenziata in blu rappresenta la parte del vettore che si vuole ordinare.\\
Essendo un algoritmo di "divide-et-impera" si deve prima dividere, che è la parte più complessa, quindi si identifica un valore $p\in A[lo,\, ...,\,hi]$ detto perno (\textit{pivot}).\\
L'operazione di "divide" sposta tutti gli elementi del sottovettore a cui si fa riferimento in modo che il valore del perno sia poi posizionato in un certo punto del vettore e questo punto si indica con "j".\\
\vspace{6pt}
\noindent
\hspace{5pt}
\begin{minipage}[t]{0.7\textwidth}
    \includegraphics[width=\linewidth]{divide-et-impera/QS1.pdf}
\end{minipage}
\hspace{5pt}\\
\noindent
Tutti gli elementi più piccoli del valore del perno devono essere collocati prima del perno stesso e tutti gli elementi più grandi devono essere collocati dopo. I valori collocati prima e dopo non devono essere interamente ordinati perché si è ancora nella fase di "divide", ovvero si porta il perno al centro in cui appunto la parte prima contiene solo valori minori di esso.\\
A questo punto "impera" ordina i due sottovettori $A[lo,\,...,\,j-1]$ e $A[j+1,\,...,\,hi]$, richiamando ricorsivamente il \textit{QuickSort}. Queste due parti potrebbero avere dimensione 0 nel caso "j-1" sia più piccolo di "lo".\\
La parte del "combina" non fa nulla, questo perché:\\
\vspace{1pt}
\noindent
\begin{minipage}[t]{0.60\textwidth}
    \includegraphics[width=\linewidth]{divide-et-impera/Pivot.pdf}
\end{minipage}%
\hspace{5pt} % Spazio tra immagine e testo
\raisebox{135pt}{
    \begin{minipage}[t]{0.37\textwidth}
        Tutti gli elementi più piccoli del perno stanno prima dello stesso, mentre tutti gli elementi più grandi stanno dopo ed entrambe le parti vengono riordinate tramite chiamate ricorsive sulle stesse parti. Alla fine tutti gli elementi sono ordinati nei sottovettori.
    \end{minipage}
}
\subsection{Pivot}
\begin{algorithm}
    \caption{\textbf{int} pivot(\textbf{ITEM}[] A, \textbf{int} lo, \textbf{int} hi)}
    \begin{algorithmic}
        \State ITEM pivot = A[lo]
        \textbf{int} j=lo
        \For i=lo+1 \textbf{to} hi \textbf{do}
        \qquad \If{$A[i]<pivot$}
        j=j+1
        \textbf{swap}(A, i, j)
        \EndIf
        \EndFor
        \State A[lo]=A[j]
        \State A[j]=pivot
        \State \textbf{return} j
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}
    \caption{\textbf{swap}(\textbf{ITEM}[] A, \textbf{int} i, \textbf{int} j)}
    \begin{algorithmic}
        \State ITEM temp = A[i]
        \State A[i] = A[j]
        \State A[j] = temp
    \end{algorithmic}
\end{algorithm}
\noindent Questa versione del \textit{pivot} sceglie come valore del pivot, appunto, quello che si trova in prima posizione.
Il ciclo va dalla seconda casella fino ad arrivare all'ultima per poi uscire e cerca di capire cosa fare del valore in $i$.
La parte del ciclo sposta i valori in modo che tutti quelli più grandi si trovano dopo e quelli piccoli prima, confrontando ogni valore A[i] col pivot. Se trova un valore più piccolo del pivot esso va prima del perno.\\
La parte dopo il ciclo mette il perno al centro.\\
\vspace{8pt}
\noindent
\begin{minipage}[t]{0.50\textwidth}
    \includegraphics[width=\linewidth]{divide-et-impera/pivot1.pdf}
\end{minipage}%
\hspace{5pt} % Spazio tra immagine e testo
\begin{minipage}[t]{0.50\textwidth}
    \includegraphics[width=\linewidth]{divide-et-impera/pivot2.pdf}
\end{minipage}

Il costo di \textit{pivot()} è: $\theta(n)$.

\subsection{Quicksort: procedura principale}
\begin{algorithm}
    \caption{QuickSort(\textbf{ITEM}[] A, \textbf{int} lo, \textbf{int} hi)}
    \begin{algorithmic}
        \If{lo<hi}
        \State \textbf{int} j=pivot(A, lo, hi)
        \State QuickSort(A, lo, j-1)
        \State QuickSort(A, j+1, hi)
        \EndIf
    \end{algorithmic}
\end{algorithm}

Svolgimento ricorsione:\\
\vspace{6pt}
\noindent
\hspace{5pt}
\begin{minipage}[t]{0.5\textwidth}
    \includegraphics[width=\linewidth]{divide-et-impera/SvolgimentoRicorsione.pdf}
\end{minipage}
\hspace{5pt}

\subsubsection{Caso pessimo}
Nel caso pessimo il vettore è già ordinato, o in maniera crescente o in maniera decrescente, e si ottiene un costo pari a:
$T(n)=T(n-1)+T(0)+\theta(n)=T(n-1)+\theta(n)=\theta(n^2)$

\subsubsection{caso ottimo}
Se il perno è sempre i valore mediano, ovvero quello che ha un numero di valori più piccoli e più grandi pari, allora la scelta del perno permette di dividere il vettore in due sottoparti più o meno uguali. In questo caso, il vettore con n elementi, viene sempre diviso in due sottoproblemi di dimensione $n/2\rightarrow T(n)=2T(n/2)+\theta(n)=\theta(n\,log\,n)$.
\\
Il problema è che il vettore non è sempre ben diviso in due parti. Il partizionamento nel caso medio di \textit{QuickSort} è molto più vicino al caso ottimo che al caso peggiore (perché non ha senso ordinare un vettore già ordinato, quindi se si vuole effettuare un ordinamento ci saranno degli elementi sparsi nel vettore).\\
Nella realtà il caso medio dipende dall'ordine degli elementi e non dai loro valori, si devono considerare tutte le possibili permutazioni e può risultare difficile dal punto di vista analitico, ma si può arrivare a un'intuizione ovvero che alcuni partizionamenti saranno parzialmente bilanciati, mentre altri saranno pessimi e in media questi si alternano nella sequenza di partizionamento. I partizionamenti parzialmente bilanciati dominano quelli pessimi, ovvero dividono man mano il vettore in parti sempre più piccole.\\
Se si fa un'analisi probabilistica su tutte le possibili permutazioni si vede che, nel caso medio, il costo è $\theta(n\,log\,n)$, quindi nel caso medio l'algoritmo ha lo stesso costo computazionale del \textit{MergeSort}.\\
I fattori moltiplicativi, anche considerando le partizioni più sfavorevli, sono comunque in favore del \textit{QuickSort}.

\subsection{Moltiplicazione di matrici}
Siano A e B due matrici rispettivamente di dimensione $n_i*n_k$ e $n_k*n_j$, con $n_k$ comune, e sia C il prodotto tra A e B, per calcolare $c_{i,j}=\sum_{k=1}^{n_k}a_{i,k}*b_{k,j}$:
\begin{algorithm}
    \caption{matrixProduct(\textbf{ITEM}[][] A, B, C, \textbf{int} $n_i$, $n_k$, $n_j$)}
    \begin{algorithmic}
        \For i=1 \textbf{to} $n_i$ \textbf{do}
        \For j=1 \textbf{to} $n_j$ \textbf{do}
        \State C[i,j]=0
        \For k=1 \textbf{to} $n_k$ \textbf{do}
        \State C[i,j]= C[i,j]+A[i,k]*B[k,j]
        \EndFor
        \EndFor
        \EndFor
    \end{algorithmic}
\end{algorithm}
Per ogni $i\in [1,\,...\,n_i]$ e per ogni $j\in [1,\,...\,n_j]$ si deve tradurre la sommatoria in codice e diventa un ulteriore ciclo che va da 1 a $n_k$ in cui si va ad accumulare la sommatoria.\\
Avendo un ciclo su $n_i$, un ciclo su $n_j$ e un ciclo su $n_k$, la complessità sarà: $T(n)=\theta(n_i*n_k*n_j)$ e se le matrici hanno tutte le stesse dimensioni viene fuori una complessità pari a $\theta(n^3)$.

\subsubsection{Algoritmo di Strassen}
Le matrici $n*n$ (quindi quadrate, ma si può fare anche con matrici rettangolari, aggiungendo degli zeri per renderle delle stesse dimensioni) vengono suddivise in quattro matrici $n/2*n/2$.
\[
    A = \begin{bmatrix}
        A_{1,1} & A_{1,2} \\
        A_{2,1} & A_{2,2}
    \end{bmatrix}
    \qquad
    B=\begin{bmatrix}
        B_{1,1} & B_{1,2} \\
        B_{2,1} & B_{2,2}
    \end{bmatrix}
\]
\noindent Si può calcolare la matrice come:
\[
    C = \begin{bmatrix}
        A_{1,1}B_{1,1}+A_{1,2}B_{2,1} & A_{1,1}B_{1,2}+A_{1,2}B_{2,2} \\
        A_{2,1}B_{1,1}+A_{2,2}B_{2,1} & A_{2,1}B_{1,2}+A_{2,2}B_{2,2}
    \end{bmatrix}
\]
Ma ci sono 8 moltiplicazioni matriciali, avendo come equazione di ricorrenza: $8T(n/2)+n^2$ con $n>1$ e si ha sempre una complessità pari a $\theta(n^3)$.\\
Strassen ha trovato un modo per ridurre la complessità dividendo in ulteriori 7 sottomatrici:
\[
    \begin{cases}
        X_1=(A_{11}+A_{22})*(B_{11}+B_{22}) \\
        X_2=(A_{21}+A_{22})*B_{11}          \\
        X_3=A_{11}*(B_{12}-B_{22})          \\
        X_4=A_{22}*(B_{21}-B_{11})          \\
        X_5=(A_{11}+A_{12})*B_{22}          \\
        X_6=(A_{21}-A_{1})*(B_{11}+B_{12})  \\
        X_7=(A_{12}-A_{22})*(B_{21}+B_{22})
    \end{cases}
\]
Si trova un'equazione di ricorrenza:
\begin{align}
    T(n)=
    \begin{cases}
        7T(n/2)+n^2,\quad n>1 \\
        1, \quad n=1
    \end{cases}
    \rightarrow T(n)=\theta(n^{log_27})\approx \theta(n^{2.81})
\end{align}
riducendo la complessità e avendo come calcolo finale:
\[
    C=\begin{bmatrix}
        X_1+X_4-X_5+X_7 & X_3+X_5         \\
        X_2+X_4         & X_1+X_3-X_2+X_6
    \end{bmatrix}
\]
Strassen è stato il primo a scoprire che era possibile moltiplicare in meno di $n^3$ moltiplicazioni scalari.

\subsection{Conclusioni}
\subsubsection*{Quando applicare \textit{divide-et-impera}?}
Quando i costi risultano essere migliori del corrispondente algoritmo iterativo.
\subsubsection*{Ulteriori vantaggi}
È facile parallelizzare e c'è un utilizzo ottimale della cache.
\end{document}